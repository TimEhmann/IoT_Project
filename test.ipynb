{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\t-ehm\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\stpyvista\\__init__.py:18: UserWarning: Using Panel interactively in VSCode notebooks requires the jupyter_bokeh package to be installed. You can install it with:\n",
      "\n",
      "   pip install jupyter_bokeh\n",
      "\n",
      "or:\n",
      "    conda install jupyter_bokeh\n",
      "\n",
      "and try again.\n",
      "  pn.extension(\"vtk\", sizing_mode=\"stretch_both\")\n"
     ]
    },
    {
     "data": {
      "application/javascript": "(function(root) {\n  function now() {\n    return new Date();\n  }\n\n  var force = true;\n  var py_version = '3.4.1'.replace('rc', '-rc.').replace('.dev', '-dev.');\n  var reloading = false;\n  var Bokeh = root.Bokeh;\n\n  if (typeof (root._bokeh_timeout) === \"undefined\" || force) {\n    root._bokeh_timeout = Date.now() + 5000;\n    root._bokeh_failed_load = false;\n  }\n\n  function run_callbacks() {\n    try {\n      root._bokeh_onload_callbacks.forEach(function(callback) {\n        if (callback != null)\n          callback();\n      });\n    } finally {\n      delete root._bokeh_onload_callbacks;\n    }\n    console.debug(\"Bokeh: all callbacks have finished\");\n  }\n\n  function load_libs(css_urls, js_urls, js_modules, js_exports, callback) {\n    if (css_urls == null) css_urls = [];\n    if (js_urls == null) js_urls = [];\n    if (js_modules == null) js_modules = [];\n    if (js_exports == null) js_exports = {};\n\n    root._bokeh_onload_callbacks.push(callback);\n\n    if (root._bokeh_is_loading > 0) {\n      console.debug(\"Bokeh: BokehJS is being loaded, scheduling callback at\", now());\n      return null;\n    }\n    if (js_urls.length === 0 && js_modules.length === 0 && Object.keys(js_exports).length === 0) {\n      run_callbacks();\n      return null;\n    }\n    if (!reloading) {\n      console.debug(\"Bokeh: BokehJS not loaded, scheduling load and callback at\", now());\n    }\n\n    function on_load() {\n      root._bokeh_is_loading--;\n      if (root._bokeh_is_loading === 0) {\n        console.debug(\"Bokeh: all BokehJS libraries/stylesheets loaded\");\n        run_callbacks()\n      }\n    }\n    window._bokeh_on_load = on_load\n\n    function on_error() {\n      console.error(\"failed to load \" + url);\n    }\n\n    var skip = [];\n    if (window.requirejs) {\n      window.requirejs.config({'packages': {}, 'paths': {'vtk': 'https://cdn.jsdelivr.net/npm/vtk.js@30.1.0/vtk'}, 'shim': {'vtk': {'exports': 'vtk'}}});\n      require([\"vtk\"], function() {\n\ton_load()\n      })\n      root._bokeh_is_loading = css_urls.length + 1;\n    } else {\n      root._bokeh_is_loading = css_urls.length + js_urls.length + js_modules.length + Object.keys(js_exports).length;\n    }\n\n    var existing_stylesheets = []\n    var links = document.getElementsByTagName('link')\n    for (var i = 0; i < links.length; i++) {\n      var link = links[i]\n      if (link.href != null) {\n\texisting_stylesheets.push(link.href)\n      }\n    }\n    for (var i = 0; i < css_urls.length; i++) {\n      var url = css_urls[i];\n      if (existing_stylesheets.indexOf(url) !== -1) {\n\ton_load()\n\tcontinue;\n      }\n      const element = document.createElement(\"link\");\n      element.onload = on_load;\n      element.onerror = on_error;\n      element.rel = \"stylesheet\";\n      element.type = \"text/css\";\n      element.href = url;\n      console.debug(\"Bokeh: injecting link tag for BokehJS stylesheet: \", url);\n      document.body.appendChild(element);\n    }    if (((window.vtk !== undefined) && (!(window.vtk instanceof HTMLElement))) || window.requirejs) {\n      var urls = ['https://cdn.holoviz.org/panel/1.4.4/dist/bundled/abstractvtkplot/vtk.js@30.1.0/vtk.js'];\n      for (var i = 0; i < urls.length; i++) {\n        skip.push(urls[i])\n      }\n    }    var existing_scripts = []\n    var scripts = document.getElementsByTagName('script')\n    for (var i = 0; i < scripts.length; i++) {\n      var script = scripts[i]\n      if (script.src != null) {\n\texisting_scripts.push(script.src)\n      }\n    }\n    for (var i = 0; i < js_urls.length; i++) {\n      var url = js_urls[i];\n      if (skip.indexOf(url) !== -1 || existing_scripts.indexOf(url) !== -1) {\n\tif (!window.requirejs) {\n\t  on_load();\n\t}\n\tcontinue;\n      }\n      var element = document.createElement('script');\n      element.onload = on_load;\n      element.onerror = on_error;\n      element.async = false;\n      element.src = url;\n      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n      document.head.appendChild(element);\n    }\n    for (var i = 0; i < js_modules.length; i++) {\n      var url = js_modules[i];\n      if (skip.indexOf(url) !== -1 || existing_scripts.indexOf(url) !== -1) {\n\tif (!window.requirejs) {\n\t  on_load();\n\t}\n\tcontinue;\n      }\n      var element = document.createElement('script');\n      element.onload = on_load;\n      element.onerror = on_error;\n      element.async = false;\n      element.src = url;\n      element.type = \"module\";\n      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n      document.head.appendChild(element);\n    }\n    for (const name in js_exports) {\n      var url = js_exports[name];\n      if (skip.indexOf(url) >= 0 || root[name] != null) {\n\tif (!window.requirejs) {\n\t  on_load();\n\t}\n\tcontinue;\n      }\n      var element = document.createElement('script');\n      element.onerror = on_error;\n      element.async = false;\n      element.type = \"module\";\n      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n      element.textContent = `\n      import ${name} from \"${url}\"\n      window.${name} = ${name}\n      window._bokeh_on_load()\n      `\n      document.head.appendChild(element);\n    }\n    if (!js_urls.length && !js_modules.length) {\n      on_load()\n    }\n  };\n\n  function inject_raw_css(css) {\n    const element = document.createElement(\"style\");\n    element.appendChild(document.createTextNode(css));\n    document.body.appendChild(element);\n  }\n\n  var js_urls = [\"https://cdn.holoviz.org/panel/1.4.4/dist/bundled/abstractvtkplot/vtk.js@30.1.0/vtk.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-3.4.1.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-gl-3.4.1.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-widgets-3.4.1.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-tables-3.4.1.min.js\", \"https://cdn.holoviz.org/panel/1.4.4/dist/panel.min.js\"];\n  var js_modules = [];\n  var js_exports = {};\n  var css_urls = [];\n  var inline_js = [    function(Bokeh) {\n      Bokeh.set_log_level(\"info\");\n    },\nfunction(Bokeh) {} // ensure no trailing comma for IE\n  ];\n\n  function run_inline_js() {\n    if ((root.Bokeh !== undefined) || (force === true)) {\n      for (var i = 0; i < inline_js.length; i++) {\n\ttry {\n          inline_js[i].call(root, root.Bokeh);\n\t} catch(e) {\n\t  if (!reloading) {\n\t    throw e;\n\t  }\n\t}\n      }\n      // Cache old bokeh versions\n      if (Bokeh != undefined && !reloading) {\n\tvar NewBokeh = root.Bokeh;\n\tif (Bokeh.versions === undefined) {\n\t  Bokeh.versions = new Map();\n\t}\n\tif (NewBokeh.version !== Bokeh.version) {\n\t  Bokeh.versions.set(NewBokeh.version, NewBokeh)\n\t}\n\troot.Bokeh = Bokeh;\n      }} else if (Date.now() < root._bokeh_timeout) {\n      setTimeout(run_inline_js, 100);\n    } else if (!root._bokeh_failed_load) {\n      console.log(\"Bokeh: BokehJS failed to load within specified timeout.\");\n      root._bokeh_failed_load = true;\n    }\n    root._bokeh_is_initializing = false\n  }\n\n  function load_or_wait() {\n    // Implement a backoff loop that tries to ensure we do not load multiple\n    // versions of Bokeh and its dependencies at the same time.\n    // In recent versions we use the root._bokeh_is_initializing flag\n    // to determine whether there is an ongoing attempt to initialize\n    // bokeh, however for backward compatibility we also try to ensure\n    // that we do not start loading a newer (Panel>=1.0 and Bokeh>3) version\n    // before older versions are fully initialized.\n    if (root._bokeh_is_initializing && Date.now() > root._bokeh_timeout) {\n      root._bokeh_is_initializing = false;\n      root._bokeh_onload_callbacks = undefined;\n      console.log(\"Bokeh: BokehJS was loaded multiple times but one version failed to initialize.\");\n      load_or_wait();\n    } else if (root._bokeh_is_initializing || (typeof root._bokeh_is_initializing === \"undefined\" && root._bokeh_onload_callbacks !== undefined)) {\n      setTimeout(load_or_wait, 100);\n    } else {\n      root._bokeh_is_initializing = true\n      root._bokeh_onload_callbacks = []\n      var bokeh_loaded = Bokeh != null && (Bokeh.version === py_version || (Bokeh.versions !== undefined && Bokeh.versions.has(py_version)));\n      if (!reloading && !bokeh_loaded) {\n\troot.Bokeh = undefined;\n      }\n      load_libs(css_urls, js_urls, js_modules, js_exports, function() {\n\tconsole.debug(\"Bokeh: BokehJS plotting callback run at\", now());\n\trun_inline_js();\n      });\n    }\n  }\n  // Give older versions of the autoload script a head-start to ensure\n  // they initialize before we start loading newer version.\n  setTimeout(load_or_wait, 100)\n}(window));",
      "application/vnd.holoviews_load.v0+json": ""
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": "\nif ((window.PyViz === undefined) || (window.PyViz instanceof HTMLElement)) {\n  window.PyViz = {comms: {}, comm_status:{}, kernels:{}, receivers: {}, plot_index: []}\n}\n\n\n    function JupyterCommManager() {\n    }\n\n    JupyterCommManager.prototype.register_target = function(plot_id, comm_id, msg_handler) {\n      if (window.comm_manager || ((window.Jupyter !== undefined) && (Jupyter.notebook.kernel != null))) {\n        var comm_manager = window.comm_manager || Jupyter.notebook.kernel.comm_manager;\n        comm_manager.register_target(comm_id, function(comm) {\n          comm.on_msg(msg_handler);\n        });\n      } else if ((plot_id in window.PyViz.kernels) && (window.PyViz.kernels[plot_id])) {\n        window.PyViz.kernels[plot_id].registerCommTarget(comm_id, function(comm) {\n          comm.onMsg = msg_handler;\n        });\n      } else if (typeof google != 'undefined' && google.colab.kernel != null) {\n        google.colab.kernel.comms.registerTarget(comm_id, (comm) => {\n          var messages = comm.messages[Symbol.asyncIterator]();\n          function processIteratorResult(result) {\n            var message = result.value;\n            console.log(message)\n            var content = {data: message.data, comm_id};\n            var buffers = []\n            for (var buffer of message.buffers || []) {\n              buffers.push(new DataView(buffer))\n            }\n            var metadata = message.metadata || {};\n            var msg = {content, buffers, metadata}\n            msg_handler(msg);\n            return messages.next().then(processIteratorResult);\n          }\n          return messages.next().then(processIteratorResult);\n        })\n      }\n    }\n\n    JupyterCommManager.prototype.get_client_comm = function(plot_id, comm_id, msg_handler) {\n      if (comm_id in window.PyViz.comms) {\n        return window.PyViz.comms[comm_id];\n      } else if (window.comm_manager || ((window.Jupyter !== undefined) && (Jupyter.notebook.kernel != null))) {\n        var comm_manager = window.comm_manager || Jupyter.notebook.kernel.comm_manager;\n        var comm = comm_manager.new_comm(comm_id, {}, {}, {}, comm_id);\n        if (msg_handler) {\n          comm.on_msg(msg_handler);\n        }\n      } else if ((plot_id in window.PyViz.kernels) && (window.PyViz.kernels[plot_id])) {\n        var comm = window.PyViz.kernels[plot_id].connectToComm(comm_id);\n        comm.open();\n        if (msg_handler) {\n          comm.onMsg = msg_handler;\n        }\n      } else if (typeof google != 'undefined' && google.colab.kernel != null) {\n        var comm_promise = google.colab.kernel.comms.open(comm_id)\n        comm_promise.then((comm) => {\n          window.PyViz.comms[comm_id] = comm;\n          if (msg_handler) {\n            var messages = comm.messages[Symbol.asyncIterator]();\n            function processIteratorResult(result) {\n              var message = result.value;\n              var content = {data: message.data};\n              var metadata = message.metadata || {comm_id};\n              var msg = {content, metadata}\n              msg_handler(msg);\n              return messages.next().then(processIteratorResult);\n            }\n            return messages.next().then(processIteratorResult);\n          }\n        }) \n        var sendClosure = (data, metadata, buffers, disposeOnDone) => {\n          return comm_promise.then((comm) => {\n            comm.send(data, metadata, buffers, disposeOnDone);\n          });\n        };\n        var comm = {\n          send: sendClosure\n        };\n      }\n      window.PyViz.comms[comm_id] = comm;\n      return comm;\n    }\n    window.PyViz.comm_manager = new JupyterCommManager();\n    \n\n\nvar JS_MIME_TYPE = 'application/javascript';\nvar HTML_MIME_TYPE = 'text/html';\nvar EXEC_MIME_TYPE = 'application/vnd.holoviews_exec.v0+json';\nvar CLASS_NAME = 'output';\n\n/**\n * Render data to the DOM node\n */\nfunction render(props, node) {\n  var div = document.createElement(\"div\");\n  var script = document.createElement(\"script\");\n  node.appendChild(div);\n  node.appendChild(script);\n}\n\n/**\n * Handle when a new output is added\n */\nfunction handle_add_output(event, handle) {\n  var output_area = handle.output_area;\n  var output = handle.output;\n  if ((output.data == undefined) || (!output.data.hasOwnProperty(EXEC_MIME_TYPE))) {\n    return\n  }\n  var id = output.metadata[EXEC_MIME_TYPE][\"id\"];\n  var toinsert = output_area.element.find(\".\" + CLASS_NAME.split(' ')[0]);\n  if (id !== undefined) {\n    var nchildren = toinsert.length;\n    var html_node = toinsert[nchildren-1].children[0];\n    html_node.innerHTML = output.data[HTML_MIME_TYPE];\n    var scripts = [];\n    var nodelist = html_node.querySelectorAll(\"script\");\n    for (var i in nodelist) {\n      if (nodelist.hasOwnProperty(i)) {\n        scripts.push(nodelist[i])\n      }\n    }\n\n    scripts.forEach( function (oldScript) {\n      var newScript = document.createElement(\"script\");\n      var attrs = [];\n      var nodemap = oldScript.attributes;\n      for (var j in nodemap) {\n        if (nodemap.hasOwnProperty(j)) {\n          attrs.push(nodemap[j])\n        }\n      }\n      attrs.forEach(function(attr) { newScript.setAttribute(attr.name, attr.value) });\n      newScript.appendChild(document.createTextNode(oldScript.innerHTML));\n      oldScript.parentNode.replaceChild(newScript, oldScript);\n    });\n    if (JS_MIME_TYPE in output.data) {\n      toinsert[nchildren-1].children[1].textContent = output.data[JS_MIME_TYPE];\n    }\n    output_area._hv_plot_id = id;\n    if ((window.Bokeh !== undefined) && (id in Bokeh.index)) {\n      window.PyViz.plot_index[id] = Bokeh.index[id];\n    } else {\n      window.PyViz.plot_index[id] = null;\n    }\n  } else if (output.metadata[EXEC_MIME_TYPE][\"server_id\"] !== undefined) {\n    var bk_div = document.createElement(\"div\");\n    bk_div.innerHTML = output.data[HTML_MIME_TYPE];\n    var script_attrs = bk_div.children[0].attributes;\n    for (var i = 0; i < script_attrs.length; i++) {\n      toinsert[toinsert.length - 1].childNodes[1].setAttribute(script_attrs[i].name, script_attrs[i].value);\n    }\n    // store reference to server id on output_area\n    output_area._bokeh_server_id = output.metadata[EXEC_MIME_TYPE][\"server_id\"];\n  }\n}\n\n/**\n * Handle when an output is cleared or removed\n */\nfunction handle_clear_output(event, handle) {\n  var id = handle.cell.output_area._hv_plot_id;\n  var server_id = handle.cell.output_area._bokeh_server_id;\n  if (((id === undefined) || !(id in PyViz.plot_index)) && (server_id !== undefined)) { return; }\n  var comm = window.PyViz.comm_manager.get_client_comm(\"hv-extension-comm\", \"hv-extension-comm\", function () {});\n  if (server_id !== null) {\n    comm.send({event_type: 'server_delete', 'id': server_id});\n    return;\n  } else if (comm !== null) {\n    comm.send({event_type: 'delete', 'id': id});\n  }\n  delete PyViz.plot_index[id];\n  if ((window.Bokeh !== undefined) & (id in window.Bokeh.index)) {\n    var doc = window.Bokeh.index[id].model.document\n    doc.clear();\n    const i = window.Bokeh.documents.indexOf(doc);\n    if (i > -1) {\n      window.Bokeh.documents.splice(i, 1);\n    }\n  }\n}\n\n/**\n * Handle kernel restart event\n */\nfunction handle_kernel_cleanup(event, handle) {\n  delete PyViz.comms[\"hv-extension-comm\"];\n  window.PyViz.plot_index = {}\n}\n\n/**\n * Handle update_display_data messages\n */\nfunction handle_update_output(event, handle) {\n  handle_clear_output(event, {cell: {output_area: handle.output_area}})\n  handle_add_output(event, handle)\n}\n\nfunction register_renderer(events, OutputArea) {\n  function append_mime(data, metadata, element) {\n    // create a DOM node to render to\n    var toinsert = this.create_output_subarea(\n    metadata,\n    CLASS_NAME,\n    EXEC_MIME_TYPE\n    );\n    this.keyboard_manager.register_events(toinsert);\n    // Render to node\n    var props = {data: data, metadata: metadata[EXEC_MIME_TYPE]};\n    render(props, toinsert[0]);\n    element.append(toinsert);\n    return toinsert\n  }\n\n  events.on('output_added.OutputArea', handle_add_output);\n  events.on('output_updated.OutputArea', handle_update_output);\n  events.on('clear_output.CodeCell', handle_clear_output);\n  events.on('delete.Cell', handle_clear_output);\n  events.on('kernel_ready.Kernel', handle_kernel_cleanup);\n\n  OutputArea.prototype.register_mime_type(EXEC_MIME_TYPE, append_mime, {\n    safe: true,\n    index: 0\n  });\n}\n\nif (window.Jupyter !== undefined) {\n  try {\n    var events = require('base/js/events');\n    var OutputArea = require('notebook/js/outputarea').OutputArea;\n    if (OutputArea.prototype.mime_types().indexOf(EXEC_MIME_TYPE) == -1) {\n      register_renderer(events, OutputArea);\n    }\n  } catch(err) {\n  }\n}\n",
      "application/vnd.holoviews_load.v0+json": ""
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>*[data-root-id],\n",
       "*[data-root-id] > * {\n",
       "  box-sizing: border-box;\n",
       "  font-family: var(--jp-ui-font-family);\n",
       "  font-size: var(--jp-ui-font-size1);\n",
       "  color: var(--vscode-editor-foreground, var(--jp-ui-font-color1));\n",
       "}\n",
       "\n",
       "/* Override VSCode background color */\n",
       ".cell-output-ipywidget-background:has(\n",
       "    > .cell-output-ipywidget-background > .lm-Widget > *[data-root-id]\n",
       "  ),\n",
       ".cell-output-ipywidget-background:has(> .lm-Widget > *[data-root-id]) {\n",
       "  background-color: transparent !important;\n",
       "}\n",
       "</style>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.holoviews_exec.v0+json": "",
      "text/html": [
       "<div id='6672e72b-8f9e-4045-ad1f-c6cb73129edf'>\n",
       "  <div id=\"bc3ca081-d4f7-4712-8ab5-53fea5428325\" data-root-id=\"6672e72b-8f9e-4045-ad1f-c6cb73129edf\" style=\"display: contents;\"></div>\n",
       "</div>\n",
       "<script type=\"application/javascript\">(function(root) {\n",
       "  var docs_json = {\"3911b91f-52e2-4b04-bb1d-a384ba85ee0a\":{\"version\":\"3.4.1\",\"title\":\"Bokeh Application\",\"roots\":[{\"type\":\"object\",\"name\":\"panel.models.browser.BrowserInfo\",\"id\":\"6672e72b-8f9e-4045-ad1f-c6cb73129edf\"},{\"type\":\"object\",\"name\":\"panel.models.comm_manager.CommManager\",\"id\":\"f5101ecf-ead8-4e77-b58b-2efad61d341a\",\"attributes\":{\"plot_id\":\"6672e72b-8f9e-4045-ad1f-c6cb73129edf\",\"comm_id\":\"32ce61097d2046ae83563a27225f46b0\",\"client_comm_id\":\"f7f89c965776420a83e5c82b5b8061de\"}}],\"defs\":[{\"type\":\"model\",\"name\":\"ReactiveHTML1\"},{\"type\":\"model\",\"name\":\"FlexBox1\",\"properties\":[{\"name\":\"align_content\",\"kind\":\"Any\",\"default\":\"flex-start\"},{\"name\":\"align_items\",\"kind\":\"Any\",\"default\":\"flex-start\"},{\"name\":\"flex_direction\",\"kind\":\"Any\",\"default\":\"row\"},{\"name\":\"flex_wrap\",\"kind\":\"Any\",\"default\":\"wrap\"},{\"name\":\"gap\",\"kind\":\"Any\",\"default\":\"\"},{\"name\":\"justify_content\",\"kind\":\"Any\",\"default\":\"flex-start\"}]},{\"type\":\"model\",\"name\":\"FloatPanel1\",\"properties\":[{\"name\":\"config\",\"kind\":\"Any\",\"default\":{\"type\":\"map\"}},{\"name\":\"contained\",\"kind\":\"Any\",\"default\":true},{\"name\":\"position\",\"kind\":\"Any\",\"default\":\"right-top\"},{\"name\":\"offsetx\",\"kind\":\"Any\",\"default\":null},{\"name\":\"offsety\",\"kind\":\"Any\",\"default\":null},{\"name\":\"theme\",\"kind\":\"Any\",\"default\":\"primary\"},{\"name\":\"status\",\"kind\":\"Any\",\"default\":\"normalized\"}]},{\"type\":\"model\",\"name\":\"GridStack1\",\"properties\":[{\"name\":\"mode\",\"kind\":\"Any\",\"default\":\"warn\"},{\"name\":\"ncols\",\"kind\":\"Any\",\"default\":null},{\"name\":\"nrows\",\"kind\":\"Any\",\"default\":null},{\"name\":\"allow_resize\",\"kind\":\"Any\",\"default\":true},{\"name\":\"allow_drag\",\"kind\":\"Any\",\"default\":true},{\"name\":\"state\",\"kind\":\"Any\",\"default\":[]}]},{\"type\":\"model\",\"name\":\"drag1\",\"properties\":[{\"name\":\"slider_width\",\"kind\":\"Any\",\"default\":5},{\"name\":\"slider_color\",\"kind\":\"Any\",\"default\":\"black\"},{\"name\":\"value\",\"kind\":\"Any\",\"default\":50}]},{\"type\":\"model\",\"name\":\"click1\",\"properties\":[{\"name\":\"terminal_output\",\"kind\":\"Any\",\"default\":\"\"},{\"name\":\"debug_name\",\"kind\":\"Any\",\"default\":\"\"},{\"name\":\"clears\",\"kind\":\"Any\",\"default\":0}]},{\"type\":\"model\",\"name\":\"FastWrapper1\",\"properties\":[{\"name\":\"object\",\"kind\":\"Any\",\"default\":null},{\"name\":\"style\",\"kind\":\"Any\",\"default\":null}]},{\"type\":\"model\",\"name\":\"NotificationAreaBase1\",\"properties\":[{\"name\":\"js_events\",\"kind\":\"Any\",\"default\":{\"type\":\"map\"}},{\"name\":\"position\",\"kind\":\"Any\",\"default\":\"bottom-right\"},{\"name\":\"_clear\",\"kind\":\"Any\",\"default\":0}]},{\"type\":\"model\",\"name\":\"NotificationArea1\",\"properties\":[{\"name\":\"js_events\",\"kind\":\"Any\",\"default\":{\"type\":\"map\"}},{\"name\":\"notifications\",\"kind\":\"Any\",\"default\":[]},{\"name\":\"position\",\"kind\":\"Any\",\"default\":\"bottom-right\"},{\"name\":\"_clear\",\"kind\":\"Any\",\"default\":0},{\"name\":\"types\",\"kind\":\"Any\",\"default\":[{\"type\":\"map\",\"entries\":[[\"type\",\"warning\"],[\"background\",\"#ffc107\"],[\"icon\",{\"type\":\"map\",\"entries\":[[\"className\",\"fas fa-exclamation-triangle\"],[\"tagName\",\"i\"],[\"color\",\"white\"]]}]]},{\"type\":\"map\",\"entries\":[[\"type\",\"info\"],[\"background\",\"#007bff\"],[\"icon\",{\"type\":\"map\",\"entries\":[[\"className\",\"fas fa-info-circle\"],[\"tagName\",\"i\"],[\"color\",\"white\"]]}]]}]}]},{\"type\":\"model\",\"name\":\"Notification\",\"properties\":[{\"name\":\"background\",\"kind\":\"Any\",\"default\":null},{\"name\":\"duration\",\"kind\":\"Any\",\"default\":3000},{\"name\":\"icon\",\"kind\":\"Any\",\"default\":null},{\"name\":\"message\",\"kind\":\"Any\",\"default\":\"\"},{\"name\":\"notification_type\",\"kind\":\"Any\",\"default\":null},{\"name\":\"_destroyed\",\"kind\":\"Any\",\"default\":false}]},{\"type\":\"model\",\"name\":\"TemplateActions1\",\"properties\":[{\"name\":\"open_modal\",\"kind\":\"Any\",\"default\":0},{\"name\":\"close_modal\",\"kind\":\"Any\",\"default\":0}]},{\"type\":\"model\",\"name\":\"BootstrapTemplateActions1\",\"properties\":[{\"name\":\"open_modal\",\"kind\":\"Any\",\"default\":0},{\"name\":\"close_modal\",\"kind\":\"Any\",\"default\":0}]},{\"type\":\"model\",\"name\":\"TemplateEditor1\",\"properties\":[{\"name\":\"layout\",\"kind\":\"Any\",\"default\":[]}]},{\"type\":\"model\",\"name\":\"MaterialTemplateActions1\",\"properties\":[{\"name\":\"open_modal\",\"kind\":\"Any\",\"default\":0},{\"name\":\"close_modal\",\"kind\":\"Any\",\"default\":0}]},{\"type\":\"model\",\"name\":\"copy_to_clipboard1\",\"properties\":[{\"name\":\"fill\",\"kind\":\"Any\",\"default\":\"none\"},{\"name\":\"value\",\"kind\":\"Any\",\"default\":null}]}]}};\n",
       "  var render_items = [{\"docid\":\"3911b91f-52e2-4b04-bb1d-a384ba85ee0a\",\"roots\":{\"6672e72b-8f9e-4045-ad1f-c6cb73129edf\":\"bc3ca081-d4f7-4712-8ab5-53fea5428325\"},\"root_ids\":[\"6672e72b-8f9e-4045-ad1f-c6cb73129edf\"]}];\n",
       "  var docs = Object.values(docs_json)\n",
       "  if (!docs) {\n",
       "    return\n",
       "  }\n",
       "  const py_version = docs[0].version.replace('rc', '-rc.').replace('.dev', '-dev.')\n",
       "  async function embed_document(root) {\n",
       "    var Bokeh = get_bokeh(root)\n",
       "    await Bokeh.embed.embed_items_notebook(docs_json, render_items);\n",
       "    for (const render_item of render_items) {\n",
       "      for (const root_id of render_item.root_ids) {\n",
       "\tconst id_el = document.getElementById(root_id)\n",
       "\tif (id_el.children.length && id_el.children[0].hasAttribute('data-root-id')) {\n",
       "\t  const root_el = id_el.children[0]\n",
       "\t  root_el.id = root_el.id + '-rendered'\n",
       "\t  for (const child of root_el.children) {\n",
       "            // Ensure JupyterLab does not capture keyboard shortcuts\n",
       "            // see: https://jupyterlab.readthedocs.io/en/4.1.x/extension/notebook.html#keyboard-interaction-model\n",
       "\t    child.setAttribute('data-lm-suppress-shortcuts', 'true')\n",
       "\t  }\n",
       "\t}\n",
       "      }\n",
       "    }\n",
       "  }\n",
       "  function get_bokeh(root) {\n",
       "    if (root.Bokeh === undefined) {\n",
       "      return null\n",
       "    } else if (root.Bokeh.version !== py_version) {\n",
       "      if (root.Bokeh.versions === undefined || !root.Bokeh.versions.has(py_version)) {\n",
       "\treturn null\n",
       "      }\n",
       "      return root.Bokeh.versions.get(py_version);\n",
       "    } else if (root.Bokeh.version === py_version) {\n",
       "      return root.Bokeh\n",
       "    }\n",
       "    return null\n",
       "  }\n",
       "  function is_loaded(root) {\n",
       "    var Bokeh = get_bokeh(root)\n",
       "    return (Bokeh != null && Bokeh.Panel !== undefined && ( root.vtk !== undefined) && ( root.vtk !== undefined))\n",
       "  }\n",
       "  if (is_loaded(root)) {\n",
       "    embed_document(root);\n",
       "  } else {\n",
       "    var attempts = 0;\n",
       "    var timer = setInterval(function(root) {\n",
       "      if (is_loaded(root)) {\n",
       "        clearInterval(timer);\n",
       "        embed_document(root);\n",
       "      } else if (document.readyState == \"complete\") {\n",
       "        attempts++;\n",
       "        if (attempts > 200) {\n",
       "          clearInterval(timer);\n",
       "\t  var Bokeh = get_bokeh(root)\n",
       "\t  if (Bokeh == null || Bokeh.Panel == null) {\n",
       "            console.warn(\"Panel: ERROR: Unable to run Panel code because Bokeh or Panel library is missing\");\n",
       "\t  } else {\n",
       "\t    console.warn(\"Panel: WARNING: Attempting to render but not all required libraries could be resolved.\")\n",
       "\t    embed_document(root)\n",
       "\t  }\n",
       "        }\n",
       "      }\n",
       "    }, 25, root)\n",
       "  }\n",
       "})(window);</script>"
      ]
     },
     "metadata": {
      "application/vnd.holoviews_exec.v0+json": {
       "id": "6672e72b-8f9e-4045-ad1f-c6cb73129edf"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import streamlit as st\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pyvista as pv\n",
    "import os\n",
    "import utils\n",
    "from stpyvista import stpyvista\n",
    "from datetime import datetime\n",
    "import importlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(608036, 18)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.concat([pd.read_csv('hka-aqm-am/' + f.removeprefix('._'), skiprows=1, sep=';', engine='python') for f in os.listdir('hka-aqm-am/')])\n",
    "df.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training data cutoff:  2023-07-15 02:45:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Studium\\Semester_6\\IoT_Project\\utils.py:1036: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_train[columns_to_scale] = scaler.fit_transform(df_train[columns_to_scale])\n",
      "c:\\Studium\\Semester_6\\IoT_Project\\utils.py:1037: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_test[columns_to_scale] = scaler.transform(df_test[columns_to_scale])\n",
      "c:\\Studium\\Semester_6\\IoT_Project\\utils.py:1041: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_train.drop(['date_time_rounded'], axis=1, inplace=True)\n",
      "c:\\Studium\\Semester_6\\IoT_Project\\utils.py:1042: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_test.drop(['date_time_rounded'], axis=1, inplace=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device_id              int8\n",
      "tmp                 float64\n",
      "hum                 float64\n",
      "CO2                 float64\n",
      "VOC                 float64\n",
      "vis                 float64\n",
      "IR                  float64\n",
      "WIFI                float64\n",
      "BLE                 float64\n",
      "rssi                float64\n",
      "channel_rssi        float64\n",
      "channel_index       float64\n",
      "spreading_factor    float64\n",
      "bandwidth           float64\n",
      "f_cnt               float64\n",
      "isHoliday           float64\n",
      "isExamTime          float64\n",
      "weekday             float64\n",
      "month               float64\n",
      "hour_sin            float64\n",
      "semester_SS23       float64\n",
      "semester_WS22/23    float64\n",
      "semester_WS23/24    float64\n",
      "group                 int32\n",
      "dtype: object\n",
      "Training data shape: torch.Size([244176, 20, 22]) torch.Size([244176]) torch.Size([244176, 1])\n",
      "Testing data shape: torch.Size([62745, 20, 22]) torch.Size([62745]) torch.Size([62745, 1])\n",
      "Shuffled Training data shape: torch.Size([245536, 20, 22]) torch.Size([245536]) torch.Size([245536, 1])\n",
      "Shuffled Testing data shape: torch.Size([61385, 20, 22]) torch.Size([61385]) torch.Size([61385, 1])\n",
      "23\n",
      "same columns\n",
      "same dtypes\n",
      "0  rows differ from the last saved dataframe.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\t-ehm\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\transformer.py:286: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
      "c:\\Users\\t-ehm\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\optim\\lr_scheduler.py:28: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\"The verbose parameter is deprecated. Please use get_last_lr() \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          actual   predicted\n",
      "0     484.000000  481.173129\n",
      "1     444.000001  437.261614\n",
      "2     398.999996  418.653904\n",
      "3     392.999999  412.243304\n",
      "4     431.800001  438.165256\n",
      "...          ...         ...\n",
      "1019  860.000011  646.743423\n",
      "1020  509.999999  483.710021\n",
      "1021  410.999999  430.045980\n",
      "1022  436.000002  435.739474\n",
      "1023  351.999999  402.860421\n",
      "\n",
      "[1024 rows x 2 columns]\n",
      "Epoch 1/25, Training Loss: 0.2807\n",
      "Epoch 1/25, Validation Loss: 0.2417\n",
      "          actual   predicted\n",
      "0     484.000000  495.082365\n",
      "1     444.000001  434.960756\n",
      "2     398.999996  429.274586\n",
      "3     392.999999  408.102637\n",
      "4     431.800001  448.479905\n",
      "...          ...         ...\n",
      "1019  860.000011  620.003233\n",
      "1020  509.999999  503.824992\n",
      "1021  410.999999  421.133949\n",
      "1022  436.000002  433.584959\n",
      "1023  351.999999  386.292366\n",
      "\n",
      "[1024 rows x 2 columns]\n",
      "Epoch 2/25, Training Loss: 0.1781\n",
      "Epoch 2/25, Validation Loss: 0.1290\n",
      "          actual   predicted\n",
      "0     484.000000  493.263653\n",
      "1     444.000001  418.765236\n",
      "2     398.999996  391.763952\n",
      "3     392.999999  390.464579\n",
      "4     431.800001  417.045689\n",
      "...          ...         ...\n",
      "1019  860.000011  650.520521\n",
      "1020  509.999999  532.488211\n",
      "1021  410.999999  400.940076\n",
      "1022  436.000002  423.013127\n",
      "1023  351.999999  374.992367\n",
      "\n",
      "[1024 rows x 2 columns]\n",
      "Epoch 3/25, Training Loss: 0.1580\n",
      "Epoch 3/25, Validation Loss: 0.1221\n",
      "          actual   predicted\n",
      "0     484.000000  508.559152\n",
      "1     444.000001  433.632523\n",
      "2     398.999996  408.802432\n",
      "3     392.999999  394.882718\n",
      "4     431.800001  426.983874\n",
      "...          ...         ...\n",
      "1019  860.000011  666.279714\n",
      "1020  509.999999  525.157746\n",
      "1021  410.999999  415.572139\n",
      "1022  436.000002  431.115078\n",
      "1023  351.999999  385.787267\n",
      "\n",
      "[1024 rows x 2 columns]\n",
      "Epoch 4/25, Training Loss: 0.1399\n",
      "Epoch 4/25, Validation Loss: 0.0998\n",
      "          actual   predicted\n",
      "0     484.000000  500.841282\n",
      "1     444.000001  438.640273\n",
      "2     398.999996  418.655939\n",
      "3     392.999999  411.984623\n",
      "4     431.800001  441.416152\n",
      "...          ...         ...\n",
      "1019  860.000011  689.220160\n",
      "1020  509.999999  510.728423\n",
      "1021  410.999999  422.289393\n",
      "1022  436.000002  430.726303\n",
      "1023  351.999999  391.660281\n",
      "\n",
      "[1024 rows x 2 columns]\n",
      "Epoch 5/25, Training Loss: 0.1329\n",
      "Epoch 5/25, Validation Loss: 0.1327\n",
      "          actual   predicted\n",
      "0     484.000000  479.762683\n",
      "1     444.000001  429.226191\n",
      "2     398.999996  398.608102\n",
      "3     392.999999  388.547637\n",
      "4     431.800001  423.311627\n",
      "...          ...         ...\n",
      "1019  860.000011  627.664804\n",
      "1020  509.999999  503.804280\n",
      "1021  410.999999  400.518646\n",
      "1022  436.000002  422.175922\n",
      "1023  351.999999  368.353781\n",
      "\n",
      "[1024 rows x 2 columns]\n",
      "Epoch 6/25, Training Loss: 0.1430\n",
      "Epoch 6/25, Validation Loss: 0.5196\n",
      "          actual   predicted\n",
      "0     484.000000  503.794762\n",
      "1     444.000001  439.918267\n",
      "2     398.999996  407.139683\n",
      "3     392.999999  402.989532\n",
      "4     431.800001  432.759952\n",
      "...          ...         ...\n",
      "1019  860.000011  653.246884\n",
      "1020  509.999999  510.489505\n",
      "1021  410.999999  412.138924\n",
      "1022  436.000002  432.965067\n",
      "1023  351.999999  376.489247\n",
      "\n",
      "[1024 rows x 2 columns]\n",
      "Epoch 7/25, Training Loss: 0.1252\n",
      "Epoch 7/25, Validation Loss: 0.0698\n",
      "          actual   predicted\n",
      "0     484.000000  498.790116\n",
      "1     444.000001  432.709656\n",
      "2     398.999996  404.006194\n",
      "3     392.999999  398.572119\n",
      "4     431.800001  433.045282\n",
      "...          ...         ...\n",
      "1019  860.000011  630.933567\n",
      "1020  509.999999  505.426379\n",
      "1021  410.999999  411.208583\n",
      "1022  436.000002  428.032645\n",
      "1023  351.999999  378.400442\n",
      "\n",
      "[1024 rows x 2 columns]\n",
      "Epoch 8/25, Training Loss: 0.1236\n",
      "Epoch 8/25, Validation Loss: 0.0618\n",
      "          actual   predicted\n",
      "0     484.000000  510.846215\n",
      "1     444.000001  444.518850\n",
      "2     398.999996  410.178859\n",
      "3     392.999999  399.657644\n",
      "4     431.800001  442.525483\n",
      "...          ...         ...\n",
      "1019  860.000011  633.941823\n",
      "1020  509.999999  511.029075\n",
      "1021  410.999999  415.504735\n",
      "1022  436.000002  434.721594\n",
      "1023  351.999999  372.406692\n",
      "\n",
      "[1024 rows x 2 columns]\n",
      "Epoch 9/25, Training Loss: 0.0990\n",
      "Epoch 9/25, Validation Loss: 0.0773\n",
      "          actual   predicted\n",
      "0     484.000000  478.836408\n",
      "1     444.000001  429.893456\n",
      "2     398.999996  397.929818\n",
      "3     392.999999  394.025645\n",
      "4     431.800001  421.482286\n",
      "...          ...         ...\n",
      "1019  860.000011  573.539588\n",
      "1020  509.999999  490.087233\n",
      "1021  410.999999  402.315311\n",
      "1022  436.000002  420.249600\n",
      "1023  351.999999  365.738929\n",
      "\n",
      "[1024 rows x 2 columns]\n",
      "Epoch 10/25, Training Loss: 0.1044\n",
      "Epoch 10/25, Validation Loss: 0.1027\n",
      "          actual   predicted\n",
      "0     484.000000  499.339816\n",
      "1     444.000001  440.639449\n",
      "2     398.999996  407.413885\n",
      "3     392.999999  401.015454\n",
      "4     431.800001  435.764272\n",
      "...          ...         ...\n",
      "1019  860.000011  622.923767\n",
      "1020  509.999999  518.018695\n",
      "1021  410.999999  410.918124\n",
      "1022  436.000002  431.141677\n",
      "1023  351.999999  376.714805\n",
      "\n",
      "[1024 rows x 2 columns]\n",
      "Epoch 11/25, Training Loss: 0.0986\n",
      "Epoch 11/25, Validation Loss: 0.0666\n",
      "          actual   predicted\n",
      "0     484.000000  490.232852\n",
      "1     444.000001  439.327694\n",
      "2     398.999996  403.507076\n",
      "3     392.999999  398.950109\n",
      "4     431.800001  435.037210\n",
      "...          ...         ...\n",
      "1019  860.000011  640.264484\n",
      "1020  509.999999  501.204044\n",
      "1021  410.999999  411.486981\n",
      "1022  436.000002  432.233104\n",
      "1023  351.999999  360.867172\n",
      "\n",
      "[1024 rows x 2 columns]\n",
      "Epoch 12/25, Training Loss: 0.1005\n",
      "Epoch 12/25, Validation Loss: 0.0544\n",
      "          actual   predicted\n",
      "0     484.000000  497.220017\n",
      "1     444.000001  430.215607\n",
      "2     398.999996  397.141100\n",
      "3     392.999999  389.074856\n",
      "4     431.800001  420.569962\n",
      "...          ...         ...\n",
      "1019  860.000011  632.241956\n",
      "1020  509.999999  507.914971\n",
      "1021  410.999999  406.048076\n",
      "1022  436.000002  422.041518\n",
      "1023  351.999999  351.330874\n",
      "\n",
      "[1024 rows x 2 columns]\n",
      "Epoch 13/25, Training Loss: 0.1219\n",
      "Epoch 13/25, Validation Loss: 0.0984\n",
      "          actual   predicted\n",
      "0     484.000000  502.583006\n",
      "1     444.000001  435.912930\n",
      "2     398.999996  395.346587\n",
      "3     392.999999  385.185479\n",
      "4     431.800001  427.955741\n",
      "...          ...         ...\n",
      "1019  860.000011  604.607334\n",
      "1020  509.999999  509.359546\n",
      "1021  410.999999  409.738720\n",
      "1022  436.000002  428.679270\n",
      "1023  351.999999  339.622481\n",
      "\n",
      "[1024 rows x 2 columns]\n",
      "Epoch 14/25, Training Loss: 0.1014\n",
      "Epoch 14/25, Validation Loss: 0.0557\n",
      "          actual   predicted\n",
      "0     484.000000  488.998882\n",
      "1     444.000001  435.816115\n",
      "2     398.999996  397.102923\n",
      "3     392.999999  390.291586\n",
      "4     431.800001  429.140942\n",
      "...          ...         ...\n",
      "1019  860.000011  622.876323\n",
      "1020  509.999999  493.095774\n",
      "1021  410.999999  405.079942\n",
      "1022  436.000002  424.910809\n",
      "1023  351.999999  332.518717\n",
      "\n",
      "[1024 rows x 2 columns]\n",
      "Epoch 15/25, Training Loss: 0.0946\n",
      "Epoch 15/25, Validation Loss: 0.0739\n",
      "          actual   predicted\n",
      "0     484.000000  497.777668\n",
      "1     444.000001  433.812460\n",
      "2     398.999996  397.376158\n",
      "3     392.999999  395.457231\n",
      "4     431.800001  430.651713\n",
      "...          ...         ...\n",
      "1019  860.000011  631.514752\n",
      "1020  509.999999  513.379706\n",
      "1021  410.999999  406.653426\n",
      "1022  436.000002  424.895249\n",
      "1023  351.999999  353.547208\n",
      "\n",
      "[1024 rows x 2 columns]\n",
      "Epoch 16/25, Training Loss: 0.1027\n",
      "Epoch 16/25, Validation Loss: 0.0691\n",
      "          actual   predicted\n",
      "0     484.000000  499.362306\n",
      "1     444.000001  438.965018\n",
      "2     398.999996  399.585386\n",
      "3     392.999999  395.257071\n",
      "4     431.800001  434.046476\n",
      "...          ...         ...\n",
      "1019  860.000011  614.978744\n",
      "1020  509.999999  506.489405\n",
      "1021  410.999999  414.077369\n",
      "1022  436.000002  430.677178\n",
      "1023  351.999999  351.685984\n",
      "\n",
      "[1024 rows x 2 columns]\n",
      "Epoch 17/25, Training Loss: 0.0836\n",
      "Epoch 17/25, Validation Loss: 0.0520\n",
      "          actual   predicted\n",
      "0     484.000000  500.986428\n",
      "1     444.000001  439.615038\n",
      "2     398.999996  394.527607\n",
      "3     392.999999  382.457115\n",
      "4     431.800001  431.036835\n",
      "...          ...         ...\n",
      "1019  860.000011  638.076701\n",
      "1020  509.999999  513.599632\n",
      "1021  410.999999  408.991256\n",
      "1022  436.000002  430.528754\n",
      "1023  351.999999  330.070677\n",
      "\n",
      "[1024 rows x 2 columns]\n",
      "Epoch 18/25, Training Loss: 0.0887\n",
      "Epoch 18/25, Validation Loss: 0.0567\n",
      "          actual   predicted\n",
      "0     484.000000  494.667297\n",
      "1     444.000001  433.753080\n",
      "2     398.999996  398.337544\n",
      "3     392.999999  394.421234\n",
      "4     431.800001  429.323256\n",
      "...          ...         ...\n",
      "1019  860.000011  620.079704\n",
      "1020  509.999999  507.536900\n",
      "1021  410.999999  407.503334\n",
      "1022  436.000002  425.826703\n",
      "1023  351.999999  356.807363\n",
      "\n",
      "[1024 rows x 2 columns]\n",
      "Epoch 19/25, Training Loss: 0.0819\n",
      "Epoch 19/25, Validation Loss: 0.0587\n",
      "          actual   predicted\n",
      "0     484.000000  495.234511\n",
      "1     444.000001  437.541944\n",
      "2     398.999996  398.206315\n",
      "3     392.999999  395.284205\n",
      "4     431.800001  432.965922\n",
      "...          ...         ...\n",
      "1019  860.000011  635.729587\n",
      "1020  509.999999  503.911317\n",
      "1021  410.999999  410.528106\n",
      "1022  436.000002  429.700361\n",
      "1023  351.999999  350.646993\n",
      "\n",
      "[1024 rows x 2 columns]\n",
      "Epoch 20/25, Training Loss: 0.0792\n",
      "Epoch 20/25, Validation Loss: 0.0542\n",
      "          actual   predicted\n",
      "0     484.000000  500.260298\n",
      "1     444.000001  436.041611\n",
      "2     398.999996  395.482646\n",
      "3     392.999999  390.576140\n",
      "4     431.800001  427.033386\n",
      "...          ...         ...\n",
      "1019  860.000011  631.479720\n",
      "1020  509.999999  509.028677\n",
      "1021  410.999999  408.018843\n",
      "1022  436.000002  426.104147\n",
      "1023  351.999999  345.469387\n",
      "\n",
      "[1024 rows x 2 columns]\n",
      "Epoch 21/25, Training Loss: 0.0909\n",
      "Epoch 21/25, Validation Loss: 0.0561\n",
      "          actual   predicted\n",
      "0     484.000000  495.462868\n",
      "1     444.000001  439.136059\n",
      "2     398.999996  398.899529\n",
      "3     392.999999  393.032880\n",
      "4     431.800001  433.822056\n",
      "...          ...         ...\n",
      "1019  860.000011  619.758633\n",
      "1020  509.999999  504.683143\n",
      "1021  410.999999  411.237059\n",
      "1022  436.000002  428.644872\n",
      "1023  351.999999  348.266115\n",
      "\n",
      "[1024 rows x 2 columns]\n",
      "Early stopping!\n",
      "           actual   predicted\n",
      "0      484.000000  495.462868\n",
      "1      444.000001  439.136059\n",
      "2      398.999996  398.899529\n",
      "3      392.999999  393.032880\n",
      "4      431.800001  433.822056\n",
      "...           ...         ...\n",
      "61380  398.999996  400.886010\n",
      "61381  408.000001  404.812020\n",
      "61382  667.249992  696.776391\n",
      "61383  511.000000  544.764031\n",
      "61384  621.999999  614.458431\n",
      "\n",
      "[61385 rows x 2 columns]\n",
      "Score (RMSE): 32.4524\n",
      "Score (MAE): 9.7019\n",
      "Score (ME): 2.0366\n",
      "Score (MAPE): 1.7338%\n",
      "training data cutoff:  2023-07-15 02:45:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Studium\\Semester_6\\IoT_Project\\utils.py:1036: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_train[columns_to_scale] = scaler.fit_transform(df_train[columns_to_scale])\n",
      "c:\\Studium\\Semester_6\\IoT_Project\\utils.py:1037: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_test[columns_to_scale] = scaler.transform(df_test[columns_to_scale])\n",
      "c:\\Studium\\Semester_6\\IoT_Project\\utils.py:1041: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_train.drop(['date_time_rounded'], axis=1, inplace=True)\n",
      "c:\\Studium\\Semester_6\\IoT_Project\\utils.py:1042: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_test.drop(['date_time_rounded'], axis=1, inplace=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device_id              int8\n",
      "tmp                 float64\n",
      "hum                 float64\n",
      "CO2                 float64\n",
      "VOC                 float64\n",
      "vis                 float64\n",
      "IR                  float64\n",
      "WIFI                float64\n",
      "BLE                 float64\n",
      "rssi                float64\n",
      "channel_rssi        float64\n",
      "channel_index       float64\n",
      "spreading_factor    float64\n",
      "bandwidth           float64\n",
      "f_cnt               float64\n",
      "isHoliday           float64\n",
      "isExamTime          float64\n",
      "weekday             float64\n",
      "month               float64\n",
      "hour_sin            float64\n",
      "semester_SS23       float64\n",
      "semester_WS22/23    float64\n",
      "semester_WS23/24    float64\n",
      "group                 int32\n",
      "dtype: object\n",
      "Training data shape: torch.Size([244176, 20, 22]) torch.Size([244176]) torch.Size([244176, 1])\n",
      "Testing data shape: torch.Size([62745, 20, 22]) torch.Size([62745]) torch.Size([62745, 1])\n",
      "Shuffled Training data shape: torch.Size([245536, 20, 22]) torch.Size([245536]) torch.Size([245536, 1])\n",
      "Shuffled Testing data shape: torch.Size([61385, 20, 22]) torch.Size([61385]) torch.Size([61385, 1])\n",
      "23\n",
      "same columns\n",
      "same dtypes\n",
      "0  rows differ from the last saved dataframe.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\t-ehm\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\transformer.py:286: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
      "c:\\Users\\t-ehm\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\optim\\lr_scheduler.py:28: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\"The verbose parameter is deprecated. Please use get_last_lr() \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           actual    predicted\n",
      "0     1102.999997  1137.518914\n",
      "1      619.571430   623.477678\n",
      "2      583.999994   591.621546\n",
      "3      620.000001   630.597856\n",
      "4      588.999997   598.839014\n",
      "...           ...          ...\n",
      "1019   718.041668   655.375065\n",
      "1020   680.000003   629.295874\n",
      "1021   678.999997   630.354835\n",
      "1022   681.999998   632.579770\n",
      "1023   626.000002   618.657509\n",
      "\n",
      "[1024 rows x 2 columns]\n",
      "Epoch 1/25, Training Loss: 0.1642\n",
      "Epoch 1/25, Validation Loss: 0.0783\n",
      "           actual    predicted\n",
      "0     1102.999997  1115.365099\n",
      "1      619.571430   593.850402\n",
      "2      583.999994   561.892916\n",
      "3      620.000001   602.749786\n",
      "4      588.999997   566.654477\n",
      "...           ...          ...\n",
      "1019   718.041668   656.567274\n",
      "1020   680.000003   607.894883\n",
      "1021   678.999997   613.183564\n",
      "1022   681.999998   624.461280\n",
      "1023   626.000002   610.792652\n",
      "\n",
      "[1024 rows x 2 columns]\n",
      "Epoch 2/25, Training Loss: 0.0729\n",
      "Epoch 2/25, Validation Loss: 0.0586\n",
      "           actual    predicted\n",
      "0     1102.999997  1065.848299\n",
      "1      619.571430   623.042436\n",
      "2      583.999994   572.593722\n",
      "3      620.000001   620.766700\n",
      "4      588.999997   573.561709\n",
      "...           ...          ...\n",
      "1019   718.041668   666.849473\n",
      "1020   680.000003   612.685118\n",
      "1021   678.999997   624.890844\n",
      "1022   681.999998   635.569718\n",
      "1023   626.000002   619.839329\n",
      "\n",
      "[1024 rows x 2 columns]\n",
      "Epoch 3/25, Training Loss: 0.0664\n",
      "Epoch 3/25, Validation Loss: 0.0468\n",
      "           actual    predicted\n",
      "0     1102.999997  1071.138595\n",
      "1      619.571430   615.891170\n",
      "2      583.999994   560.886017\n",
      "3      620.000001   629.549844\n",
      "4      588.999997   567.472811\n",
      "...           ...          ...\n",
      "1019   718.041668   692.207309\n",
      "1020   680.000003   643.537624\n",
      "1021   678.999997   643.526977\n",
      "1022   681.999998   658.795509\n",
      "1023   626.000002   635.974884\n",
      "\n",
      "[1024 rows x 2 columns]\n",
      "Epoch 4/25, Training Loss: 0.0631\n",
      "Epoch 4/25, Validation Loss: 0.0495\n",
      "           actual    predicted\n",
      "0     1102.999997  1091.680263\n",
      "1      619.571430   605.184207\n",
      "2      583.999994   552.614343\n",
      "3      620.000001   627.457900\n",
      "4      588.999997   558.426453\n",
      "...           ...          ...\n",
      "1019   718.041668   664.194805\n",
      "1020   680.000003   625.784785\n",
      "1021   678.999997   628.759350\n",
      "1022   681.999998   644.623218\n",
      "1023   626.000002   628.358229\n",
      "\n",
      "[1024 rows x 2 columns]\n",
      "Epoch 5/25, Training Loss: 0.0589\n",
      "Epoch 5/25, Validation Loss: 0.0496\n",
      "           actual    predicted\n",
      "0     1102.999997  1077.290679\n",
      "1      619.571430   603.049021\n",
      "2      583.999994   559.851631\n",
      "3      620.000001   621.223643\n",
      "4      588.999997   569.918463\n",
      "...           ...          ...\n",
      "1019   718.041668   718.241802\n",
      "1020   680.000003   644.740098\n",
      "1021   678.999997   654.717588\n",
      "1022   681.999998   664.584374\n",
      "1023   626.000002   636.935987\n",
      "\n",
      "[1024 rows x 2 columns]\n",
      "Epoch 6/25, Training Loss: 0.0587\n",
      "Epoch 6/25, Validation Loss: 0.0471\n",
      "           actual    predicted\n",
      "0     1102.999997  1128.677127\n",
      "1      619.571430   584.379803\n",
      "2      583.999994   547.328821\n",
      "3      620.000001   600.824068\n",
      "4      588.999997   563.124011\n",
      "...           ...          ...\n",
      "1019   718.041668   691.346610\n",
      "1020   680.000003   615.229160\n",
      "1021   678.999997   623.401201\n",
      "1022   681.999998   644.006287\n",
      "1023   626.000002   617.854523\n",
      "\n",
      "[1024 rows x 2 columns]\n",
      "Epoch 7/25, Training Loss: 0.0571\n",
      "Epoch 7/25, Validation Loss: 0.0526\n",
      "           actual    predicted\n",
      "0     1102.999997  1064.589134\n",
      "1      619.571430   610.307922\n",
      "2      583.999994   564.236399\n",
      "3      620.000001   623.148243\n",
      "4      588.999997   569.889540\n",
      "...           ...          ...\n",
      "1019   718.041668   703.693135\n",
      "1020   680.000003   645.032492\n",
      "1021   678.999997   646.639750\n",
      "1022   681.999998   659.789659\n",
      "1023   626.000002   633.606205\n",
      "\n",
      "[1024 rows x 2 columns]\n",
      "Early stopping!\n",
      "            actual    predicted\n",
      "0      1102.999997  1064.589134\n",
      "1       619.571430   610.307922\n",
      "2       583.999994   564.236399\n",
      "3       620.000001   623.148243\n",
      "4       588.999997   569.889540\n",
      "...            ...          ...\n",
      "61380   840.000000   828.005933\n",
      "61381   512.999995   554.748251\n",
      "61382   594.999999   570.208790\n",
      "61383   561.777776   572.203266\n",
      "61384   732.000002   713.135228\n",
      "\n",
      "[61385 rows x 2 columns]\n",
      "Score (RMSE): 65.0565\n",
      "Score (MAE): 32.4288\n",
      "Score (ME): 2.8252\n",
      "Score (MAPE): 3.9428%\n",
      "training data cutoff:  2023-07-15 02:45:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Studium\\Semester_6\\IoT_Project\\utils.py:1036: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_train[columns_to_scale] = scaler.fit_transform(df_train[columns_to_scale])\n",
      "c:\\Studium\\Semester_6\\IoT_Project\\utils.py:1037: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_test[columns_to_scale] = scaler.transform(df_test[columns_to_scale])\n",
      "c:\\Studium\\Semester_6\\IoT_Project\\utils.py:1041: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_train.drop(['date_time_rounded'], axis=1, inplace=True)\n",
      "c:\\Studium\\Semester_6\\IoT_Project\\utils.py:1042: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_test.drop(['date_time_rounded'], axis=1, inplace=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device_id              int8\n",
      "tmp                 float64\n",
      "hum                 float64\n",
      "CO2                 float64\n",
      "VOC                 float64\n",
      "vis                 float64\n",
      "IR                  float64\n",
      "WIFI                float64\n",
      "BLE                 float64\n",
      "rssi                float64\n",
      "channel_rssi        float64\n",
      "channel_index       float64\n",
      "spreading_factor    float64\n",
      "bandwidth           float64\n",
      "f_cnt               float64\n",
      "isHoliday           float64\n",
      "isExamTime          float64\n",
      "weekday             float64\n",
      "month               float64\n",
      "hour_sin            float64\n",
      "semester_SS23       float64\n",
      "semester_WS22/23    float64\n",
      "semester_WS23/24    float64\n",
      "group                 int32\n",
      "dtype: object\n",
      "Training data shape: torch.Size([244176, 20, 22]) torch.Size([244176]) torch.Size([244176, 1])\n",
      "Testing data shape: torch.Size([62745, 20, 22]) torch.Size([62745]) torch.Size([62745, 1])\n",
      "Shuffled Training data shape: torch.Size([245536, 20, 22]) torch.Size([245536]) torch.Size([245536, 1])\n",
      "Shuffled Testing data shape: torch.Size([61385, 20, 22]) torch.Size([61385]) torch.Size([61385, 1])\n",
      "23\n",
      "same columns\n",
      "same dtypes\n",
      "0  rows differ from the last saved dataframe.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\t-ehm\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\transformer.py:286: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
      "c:\\Users\\t-ehm\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\optim\\lr_scheduler.py:28: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\"The verbose parameter is deprecated. Please use get_last_lr() \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      actual  predicted\n",
      "0      47.52  48.781171\n",
      "1      39.10  38.932798\n",
      "2      55.07  56.262995\n",
      "3      53.28  54.598736\n",
      "4      24.16  21.831852\n",
      "...      ...        ...\n",
      "1019   33.92  33.641870\n",
      "1020   40.61  40.974028\n",
      "1021   31.91  33.181630\n",
      "1022   26.76  26.166381\n",
      "1023   30.16  28.878660\n",
      "\n",
      "[1024 rows x 2 columns]\n",
      "Epoch 1/25, Training Loss: 0.0857\n",
      "Epoch 1/25, Validation Loss: 0.0094\n",
      "      actual  predicted\n",
      "0      47.52  47.760968\n",
      "1      39.10  38.673453\n",
      "2      55.07  57.512022\n",
      "3      53.28  55.837834\n",
      "4      24.16  22.599099\n",
      "...      ...        ...\n",
      "1019   33.92  33.747443\n",
      "1020   40.61  41.057524\n",
      "1021   31.91  32.696736\n",
      "1022   26.76  26.074801\n",
      "1023   30.16  30.100132\n",
      "\n",
      "[1024 rows x 2 columns]\n",
      "Epoch 2/25, Training Loss: 0.0277\n",
      "Epoch 2/25, Validation Loss: 0.0131\n",
      "      actual  predicted\n",
      "0      47.52  48.138817\n",
      "1      39.10  38.680496\n",
      "2      55.07  57.047408\n",
      "3      53.28  55.577100\n",
      "4      24.16  22.624908\n",
      "...      ...        ...\n",
      "1019   33.92  33.519809\n",
      "1020   40.61  40.582872\n",
      "1021   31.91  32.409350\n",
      "1022   26.76  26.166595\n",
      "1023   30.16  30.020857\n",
      "\n",
      "[1024 rows x 2 columns]\n",
      "Epoch 3/25, Training Loss: 0.0205\n",
      "Epoch 3/25, Validation Loss: 0.0082\n",
      "      actual  predicted\n",
      "0      47.52  47.929233\n",
      "1      39.10  39.234736\n",
      "2      55.07  56.519711\n",
      "3      53.28  55.566751\n",
      "4      24.16  23.223260\n",
      "...      ...        ...\n",
      "1019   33.92  34.085328\n",
      "1020   40.61  41.035336\n",
      "1021   31.91  32.932720\n",
      "1022   26.76  26.368960\n",
      "1023   30.16  30.244512\n",
      "\n",
      "[1024 rows x 2 columns]\n",
      "Epoch 4/25, Training Loss: 0.0168\n",
      "Epoch 4/25, Validation Loss: 0.0058\n",
      "      actual  predicted\n",
      "0      47.52  48.601955\n",
      "1      39.10  39.317176\n",
      "2      55.07  57.919028\n",
      "3      53.28  56.685765\n",
      "4      24.16  23.109162\n",
      "...      ...        ...\n",
      "1019   33.92  34.219232\n",
      "1020   40.61  41.080354\n",
      "1021   31.91  33.039243\n",
      "1022   26.76  26.431884\n",
      "1023   30.16  30.438752\n",
      "\n",
      "[1024 rows x 2 columns]\n",
      "Epoch 5/25, Training Loss: 0.0144\n",
      "Epoch 5/25, Validation Loss: 0.0111\n",
      "      actual  predicted\n",
      "0      47.52  48.603783\n",
      "1      39.10  39.200174\n",
      "2      55.07  57.219917\n",
      "3      53.28  55.553624\n",
      "4      24.16  23.203256\n",
      "...      ...        ...\n",
      "1019   33.92  33.541396\n",
      "1020   40.61  41.031378\n",
      "1021   31.91  32.435034\n",
      "1022   26.76  26.300330\n",
      "1023   30.16  30.284221\n",
      "\n",
      "[1024 rows x 2 columns]\n",
      "Epoch 6/25, Training Loss: 0.0127\n",
      "Epoch 6/25, Validation Loss: 0.0066\n",
      "      actual  predicted\n",
      "0      47.52  47.901949\n",
      "1      39.10  38.858410\n",
      "2      55.07  56.412958\n",
      "3      53.28  55.476121\n",
      "4      24.16  23.049041\n",
      "...      ...        ...\n",
      "1019   33.92  33.656424\n",
      "1020   40.61  40.945557\n",
      "1021   31.91  32.302897\n",
      "1022   26.76  26.156934\n",
      "1023   30.16  29.799751\n",
      "\n",
      "[1024 rows x 2 columns]\n",
      "Epoch 7/25, Training Loss: 0.0115\n",
      "Epoch 7/25, Validation Loss: 0.0073\n",
      "      actual  predicted\n",
      "0      47.52  47.798492\n",
      "1      39.10  38.531337\n",
      "2      55.07  55.977756\n",
      "3      53.28  54.282059\n",
      "4      24.16  22.808229\n",
      "...      ...        ...\n",
      "1019   33.92  33.868101\n",
      "1020   40.61  40.848071\n",
      "1021   31.91  32.837615\n",
      "1022   26.76  26.102173\n",
      "1023   30.16  29.941291\n",
      "\n",
      "[1024 rows x 2 columns]\n",
      "Epoch 8/25, Training Loss: 0.0106\n",
      "Epoch 8/25, Validation Loss: 0.0071\n",
      "      actual  predicted\n",
      "0      47.52  47.980521\n",
      "1      39.10  38.812765\n",
      "2      55.07  56.775917\n",
      "3      53.28  55.081262\n",
      "4      24.16  23.119826\n",
      "...      ...        ...\n",
      "1019   33.92  33.825231\n",
      "1020   40.61  40.532419\n",
      "1021   31.91  32.753300\n",
      "1022   26.76  26.194428\n",
      "1023   30.16  29.772301\n",
      "\n",
      "[1024 rows x 2 columns]\n",
      "Epoch 9/25, Training Loss: 0.0096\n",
      "Epoch 9/25, Validation Loss: 0.0052\n",
      "      actual  predicted\n",
      "0      47.52  47.601011\n",
      "1      39.10  38.868116\n",
      "2      55.07  56.072612\n",
      "3      53.28  54.560495\n",
      "4      24.16  23.171577\n",
      "...      ...        ...\n",
      "1019   33.92  33.945127\n",
      "1020   40.61  40.789060\n",
      "1021   31.91  32.811625\n",
      "1022   26.76  26.460993\n",
      "1023   30.16  29.994580\n",
      "\n",
      "[1024 rows x 2 columns]\n",
      "Epoch 10/25, Training Loss: 0.0092\n",
      "Epoch 10/25, Validation Loss: 0.0038\n",
      "      actual  predicted\n",
      "0      47.52  47.915671\n",
      "1      39.10  39.097612\n",
      "2      55.07  56.719510\n",
      "3      53.28  55.586804\n",
      "4      24.16  23.232121\n",
      "...      ...        ...\n",
      "1019   33.92  33.869674\n",
      "1020   40.61  40.769044\n",
      "1021   31.91  32.783576\n",
      "1022   26.76  26.282857\n",
      "1023   30.16  30.082456\n",
      "\n",
      "[1024 rows x 2 columns]\n",
      "Epoch 11/25, Training Loss: 0.0090\n",
      "Epoch 11/25, Validation Loss: 0.0054\n",
      "      actual  predicted\n",
      "0      47.52  47.933772\n",
      "1      39.10  39.114450\n",
      "2      55.07  56.348001\n",
      "3      53.28  55.090545\n",
      "4      24.16  23.328816\n",
      "...      ...        ...\n",
      "1019   33.92  33.806866\n",
      "1020   40.61  40.753773\n",
      "1021   31.91  32.624547\n",
      "1022   26.76  26.052394\n",
      "1023   30.16  29.906711\n",
      "\n",
      "[1024 rows x 2 columns]\n",
      "Epoch 12/25, Training Loss: 0.0088\n",
      "Epoch 12/25, Validation Loss: 0.0048\n",
      "      actual  predicted\n",
      "0      47.52  47.685617\n",
      "1      39.10  38.587944\n",
      "2      55.07  55.887984\n",
      "3      53.28  54.672085\n",
      "4      24.16  22.991976\n",
      "...      ...        ...\n",
      "1019   33.92  33.634096\n",
      "1020   40.61  40.828149\n",
      "1021   31.91  32.506131\n",
      "1022   26.76  26.102954\n",
      "1023   30.16  29.703311\n",
      "\n",
      "[1024 rows x 2 columns]\n",
      "Epoch 13/25, Training Loss: 0.0085\n",
      "Epoch 13/25, Validation Loss: 0.0045\n",
      "      actual  predicted\n",
      "0      47.52  47.704640\n",
      "1      39.10  39.152534\n",
      "2      55.07  56.079591\n",
      "3      53.28  54.964563\n",
      "4      24.16  22.995092\n",
      "...      ...        ...\n",
      "1019   33.92  33.915163\n",
      "1020   40.61  40.909332\n",
      "1021   31.91  32.698716\n",
      "1022   26.76  26.129508\n",
      "1023   30.16  29.922000\n",
      "\n",
      "[1024 rows x 2 columns]\n",
      "Epoch 14/25, Training Loss: 0.0083\n",
      "Epoch 14/25, Validation Loss: 0.0059\n",
      "      actual  predicted\n",
      "0      47.52  47.592073\n",
      "1      39.10  39.124390\n",
      "2      55.07  56.332684\n",
      "3      53.28  55.013354\n",
      "4      24.16  23.098178\n",
      "...      ...        ...\n",
      "1019   33.92  33.870731\n",
      "1020   40.61  40.763753\n",
      "1021   31.91  32.747899\n",
      "1022   26.76  26.470795\n",
      "1023   30.16  30.032814\n",
      "\n",
      "[1024 rows x 2 columns]\n",
      "Epoch 15/25, Training Loss: 0.0080\n",
      "Epoch 15/25, Validation Loss: 0.0036\n",
      "      actual  predicted\n",
      "0      47.52  47.667439\n",
      "1      39.10  38.812038\n",
      "2      55.07  56.202137\n",
      "3      53.28  54.848707\n",
      "4      24.16  23.369889\n",
      "...      ...        ...\n",
      "1019   33.92  33.866092\n",
      "1020   40.61  40.705537\n",
      "1021   31.91  32.728514\n",
      "1022   26.76  26.315858\n",
      "1023   30.16  29.940641\n",
      "\n",
      "[1024 rows x 2 columns]\n",
      "Epoch 16/25, Training Loss: 0.0078\n",
      "Epoch 16/25, Validation Loss: 0.0033\n",
      "      actual  predicted\n",
      "0      47.52  47.563592\n",
      "1      39.10  38.941087\n",
      "2      55.07  56.010423\n",
      "3      53.28  54.689142\n",
      "4      24.16  23.213470\n",
      "...      ...        ...\n",
      "1019   33.92  33.857739\n",
      "1020   40.61  40.855836\n",
      "1021   31.91  32.743925\n",
      "1022   26.76  26.399493\n",
      "1023   30.16  29.998676\n",
      "\n",
      "[1024 rows x 2 columns]\n",
      "Epoch 17/25, Training Loss: 0.0076\n",
      "Epoch 17/25, Validation Loss: 0.0030\n",
      "      actual  predicted\n",
      "0      47.52  47.736681\n",
      "1      39.10  38.940249\n",
      "2      55.07  56.370452\n",
      "3      53.28  54.910515\n",
      "4      24.16  22.957982\n",
      "...      ...        ...\n",
      "1019   33.92  33.710818\n",
      "1020   40.61  40.756681\n",
      "1021   31.91  32.554051\n",
      "1022   26.76  26.084854\n",
      "1023   30.16  29.634174\n",
      "\n",
      "[1024 rows x 2 columns]\n",
      "Epoch 18/25, Training Loss: 0.0076\n",
      "Epoch 18/25, Validation Loss: 0.0037\n",
      "      actual  predicted\n",
      "0      47.52  48.026106\n",
      "1      39.10  39.094338\n",
      "2      55.07  56.597044\n",
      "3      53.28  55.194593\n",
      "4      24.16  23.158565\n",
      "...      ...        ...\n",
      "1019   33.92  34.012044\n",
      "1020   40.61  40.851110\n",
      "1021   31.91  32.983934\n",
      "1022   26.76  26.568619\n",
      "1023   30.16  30.113330\n",
      "\n",
      "[1024 rows x 2 columns]\n",
      "Epoch 19/25, Training Loss: 0.0075\n",
      "Epoch 19/25, Validation Loss: 0.0033\n",
      "      actual  predicted\n",
      "0      47.52  47.524353\n",
      "1      39.10  38.746454\n",
      "2      55.07  56.010369\n",
      "3      53.28  54.587559\n",
      "4      24.16  23.223578\n",
      "...      ...        ...\n",
      "1019   33.92  33.727076\n",
      "1020   40.61  40.389729\n",
      "1021   31.91  32.760419\n",
      "1022   26.76  26.356553\n",
      "1023   30.16  29.959661\n",
      "\n",
      "[1024 rows x 2 columns]\n",
      "Epoch 20/25, Training Loss: 0.0074\n",
      "Epoch 20/25, Validation Loss: 0.0030\n",
      "      actual  predicted\n",
      "0      47.52  47.683692\n",
      "1      39.10  38.991202\n",
      "2      55.07  56.083548\n",
      "3      53.28  54.674258\n",
      "4      24.16  23.050997\n",
      "...      ...        ...\n",
      "1019   33.92  33.862237\n",
      "1020   40.61  40.558403\n",
      "1021   31.91  32.783430\n",
      "1022   26.76  26.370731\n",
      "1023   30.16  30.040772\n",
      "\n",
      "[1024 rows x 2 columns]\n",
      "Epoch 21/25, Training Loss: 0.0073\n",
      "Epoch 21/25, Validation Loss: 0.0031\n",
      "      actual  predicted\n",
      "0      47.52  47.364605\n",
      "1      39.10  38.867146\n",
      "2      55.07  56.028844\n",
      "3      53.28  54.410998\n",
      "4      24.16  23.543576\n",
      "...      ...        ...\n",
      "1019   33.92  33.910036\n",
      "1020   40.61  40.747593\n",
      "1021   31.91  32.862977\n",
      "1022   26.76  26.464149\n",
      "1023   30.16  29.984767\n",
      "\n",
      "[1024 rows x 2 columns]\n",
      "Epoch 22/25, Training Loss: 0.0070\n",
      "Epoch 22/25, Validation Loss: 0.0027\n",
      "      actual  predicted\n",
      "0      47.52  47.774859\n",
      "1      39.10  38.884570\n",
      "2      55.07  56.490698\n",
      "3      53.28  54.785772\n",
      "4      24.16  23.471201\n",
      "...      ...        ...\n",
      "1019   33.92  33.998632\n",
      "1020   40.61  40.705267\n",
      "1021   31.91  32.923088\n",
      "1022   26.76  26.510871\n",
      "1023   30.16  29.931790\n",
      "\n",
      "[1024 rows x 2 columns]\n",
      "Epoch 23/25, Training Loss: 0.0070\n",
      "Epoch 23/25, Validation Loss: 0.0028\n",
      "      actual  predicted\n",
      "0      47.52  47.682833\n",
      "1      39.10  38.956823\n",
      "2      55.07  56.248737\n",
      "3      53.28  54.774280\n",
      "4      24.16  23.180627\n",
      "...      ...        ...\n",
      "1019   33.92  33.681438\n",
      "1020   40.61  40.595430\n",
      "1021   31.91  32.593339\n",
      "1022   26.76  26.185697\n",
      "1023   30.16  29.629041\n",
      "\n",
      "[1024 rows x 2 columns]\n",
      "Epoch 24/25, Training Loss: 0.0070\n",
      "Epoch 24/25, Validation Loss: 0.0035\n",
      "      actual  predicted\n",
      "0      47.52  47.483953\n",
      "1      39.10  38.866324\n",
      "2      55.07  56.147811\n",
      "3      53.28  54.598781\n",
      "4      24.16  23.583215\n",
      "...      ...        ...\n",
      "1019   33.92  33.836290\n",
      "1020   40.61  40.653040\n",
      "1021   31.91  32.763556\n",
      "1022   26.76  26.534449\n",
      "1023   30.16  29.930189\n",
      "\n",
      "[1024 rows x 2 columns]\n",
      "Epoch 25/25, Training Loss: 0.0069\n",
      "Epoch 25/25, Validation Loss: 0.0025\n",
      "       actual  predicted\n",
      "0       47.52  47.483953\n",
      "1       39.10  38.866324\n",
      "2       55.07  56.147811\n",
      "3       53.28  54.598781\n",
      "4       24.16  23.583215\n",
      "...       ...        ...\n",
      "61380   34.52  34.512141\n",
      "61381   32.11  32.196694\n",
      "61382   47.23  47.453222\n",
      "61383   25.74  25.578401\n",
      "61384   30.63  31.140199\n",
      "\n",
      "[61385 rows x 2 columns]\n",
      "Score (RMSE): 0.4753\n",
      "Score (MAE): 0.2629\n",
      "Score (ME): 0.0045\n",
      "Score (MAPE): 0.7411%\n",
      "training data cutoff:  2023-07-15 02:45:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Studium\\Semester_6\\IoT_Project\\utils.py:1036: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_train[columns_to_scale] = scaler.fit_transform(df_train[columns_to_scale])\n",
      "c:\\Studium\\Semester_6\\IoT_Project\\utils.py:1037: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_test[columns_to_scale] = scaler.transform(df_test[columns_to_scale])\n",
      "c:\\Studium\\Semester_6\\IoT_Project\\utils.py:1041: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_train.drop(['date_time_rounded'], axis=1, inplace=True)\n",
      "c:\\Studium\\Semester_6\\IoT_Project\\utils.py:1042: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_test.drop(['date_time_rounded'], axis=1, inplace=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device_id              int8\n",
      "tmp                 float64\n",
      "hum                 float64\n",
      "CO2                 float64\n",
      "VOC                 float64\n",
      "vis                 float64\n",
      "IR                  float64\n",
      "WIFI                float64\n",
      "BLE                 float64\n",
      "rssi                float64\n",
      "channel_rssi        float64\n",
      "channel_index       float64\n",
      "spreading_factor    float64\n",
      "bandwidth           float64\n",
      "f_cnt               float64\n",
      "isHoliday           float64\n",
      "isExamTime          float64\n",
      "weekday             float64\n",
      "month               float64\n",
      "hour_sin            float64\n",
      "semester_SS23       float64\n",
      "semester_WS22/23    float64\n",
      "semester_WS23/24    float64\n",
      "group                 int32\n",
      "dtype: object\n",
      "Training data shape: torch.Size([244176, 20, 22]) torch.Size([244176]) torch.Size([244176, 1])\n",
      "Testing data shape: torch.Size([62745, 20, 22]) torch.Size([62745]) torch.Size([62745, 1])\n",
      "Shuffled Training data shape: torch.Size([245536, 20, 22]) torch.Size([245536]) torch.Size([245536, 1])\n",
      "Shuffled Testing data shape: torch.Size([61385, 20, 22]) torch.Size([61385]) torch.Size([61385, 1])\n",
      "23\n",
      "same columns\n",
      "same dtypes\n",
      "0  rows differ from the last saved dataframe.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\t-ehm\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\transformer.py:286: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
      "c:\\Users\\t-ehm\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\optim\\lr_scheduler.py:28: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\"The verbose parameter is deprecated. Please use get_last_lr() \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       actual  predicted\n",
      "0     26.1800  25.739923\n",
      "1     20.7400  19.630887\n",
      "2     23.0800  22.755852\n",
      "3     24.7000  24.701347\n",
      "4     29.2600  29.789676\n",
      "...       ...        ...\n",
      "1019  22.1800  21.738598\n",
      "1020  28.8300  28.660652\n",
      "1021  24.0825  23.691968\n",
      "1022  23.6200  23.512465\n",
      "1023  20.3300  20.172679\n",
      "\n",
      "[1024 rows x 2 columns]\n",
      "Epoch 1/25, Training Loss: 0.0937\n",
      "Epoch 1/25, Validation Loss: 0.0364\n",
      "       actual  predicted\n",
      "0     26.1800  25.946495\n",
      "1     20.7400  20.151578\n",
      "2     23.0800  23.004004\n",
      "3     24.7000  24.627628\n",
      "4     29.2600  30.163808\n",
      "...       ...        ...\n",
      "1019  22.1800  21.599123\n",
      "1020  28.8300  28.841447\n",
      "1021  24.0825  23.713488\n",
      "1022  23.6200  23.542876\n",
      "1023  20.3300  19.966653\n",
      "\n",
      "[1024 rows x 2 columns]\n",
      "Epoch 2/25, Training Loss: 0.0346\n",
      "Epoch 2/25, Validation Loss: 0.0287\n",
      "       actual  predicted\n",
      "0     26.1800  25.945197\n",
      "1     20.7400  20.191053\n",
      "2     23.0800  22.958659\n",
      "3     24.7000  24.565579\n",
      "4     29.2600  29.975600\n",
      "...       ...        ...\n",
      "1019  22.1800  21.847880\n",
      "1020  28.8300  29.048562\n",
      "1021  24.0825  23.818031\n",
      "1022  23.6200  23.464447\n",
      "1023  20.3300  20.025612\n",
      "\n",
      "[1024 rows x 2 columns]\n",
      "Epoch 3/25, Training Loss: 0.0253\n",
      "Epoch 3/25, Validation Loss: 0.0293\n",
      "       actual  predicted\n",
      "0     26.1800  25.832352\n",
      "1     20.7400  20.346636\n",
      "2     23.0800  23.025721\n",
      "3     24.7000  24.591964\n",
      "4     29.2600  29.575527\n",
      "...       ...        ...\n",
      "1019  22.1800  21.865861\n",
      "1020  28.8300  28.883434\n",
      "1021  24.0825  23.794671\n",
      "1022  23.6200  23.573133\n",
      "1023  20.3300  19.867297\n",
      "\n",
      "[1024 rows x 2 columns]\n",
      "Epoch 4/25, Training Loss: 0.0208\n",
      "Epoch 4/25, Validation Loss: 0.0161\n",
      "       actual  predicted\n",
      "0     26.1800  26.082138\n",
      "1     20.7400  20.449443\n",
      "2     23.0800  22.989675\n",
      "3     24.7000  24.554482\n",
      "4     29.2600  29.327870\n",
      "...       ...        ...\n",
      "1019  22.1800  22.079995\n",
      "1020  28.8300  28.624681\n",
      "1021  24.0825  23.817684\n",
      "1022  23.6200  23.528875\n",
      "1023  20.3300  20.311732\n",
      "\n",
      "[1024 rows x 2 columns]\n",
      "Epoch 5/25, Training Loss: 0.0174\n",
      "Epoch 5/25, Validation Loss: 0.0084\n",
      "       actual  predicted\n",
      "0     26.1800  26.098565\n",
      "1     20.7400  20.412408\n",
      "2     23.0800  23.013464\n",
      "3     24.7000  24.756302\n",
      "4     29.2600  29.486296\n",
      "...       ...        ...\n",
      "1019  22.1800  22.095026\n",
      "1020  28.8300  28.721342\n",
      "1021  24.0825  23.835619\n",
      "1022  23.6200  23.571616\n",
      "1023  20.3300  20.156046\n",
      "\n",
      "[1024 rows x 2 columns]\n",
      "Epoch 6/25, Training Loss: 0.0156\n",
      "Epoch 6/25, Validation Loss: 0.0092\n",
      "       actual  predicted\n",
      "0     26.1800  25.982919\n",
      "1     20.7400  20.418603\n",
      "2     23.0800  23.053314\n",
      "3     24.7000  24.745164\n",
      "4     29.2600  29.709816\n",
      "...       ...        ...\n",
      "1019  22.1800  22.153917\n",
      "1020  28.8300  29.073405\n",
      "1021  24.0825  23.954667\n",
      "1022  23.6200  23.571328\n",
      "1023  20.3300  19.925864\n",
      "\n",
      "[1024 rows x 2 columns]\n",
      "Epoch 7/25, Training Loss: 0.0133\n",
      "Epoch 7/25, Validation Loss: 0.0110\n",
      "       actual  predicted\n",
      "0     26.1800  25.992139\n",
      "1     20.7400  20.310178\n",
      "2     23.0800  23.040512\n",
      "3     24.7000  24.575274\n",
      "4     29.2600  29.623960\n",
      "...       ...        ...\n",
      "1019  22.1800  21.914165\n",
      "1020  28.8300  28.680729\n",
      "1021  24.0825  23.744146\n",
      "1022  23.6200  23.393332\n",
      "1023  20.3300  19.903235\n",
      "\n",
      "[1024 rows x 2 columns]\n",
      "Epoch 8/25, Training Loss: 0.0127\n",
      "Epoch 8/25, Validation Loss: 0.0071\n",
      "       actual  predicted\n",
      "0     26.1800  26.278780\n",
      "1     20.7400  20.617494\n",
      "2     23.0800  23.255302\n",
      "3     24.7000  24.790387\n",
      "4     29.2600  29.898146\n",
      "...       ...        ...\n",
      "1019  22.1800  22.130421\n",
      "1020  28.8300  28.853047\n",
      "1021  24.0825  23.969664\n",
      "1022  23.6200  23.696352\n",
      "1023  20.3300  20.251865\n",
      "\n",
      "[1024 rows x 2 columns]\n",
      "Epoch 9/25, Training Loss: 0.0110\n",
      "Epoch 9/25, Validation Loss: 0.0054\n",
      "       actual  predicted\n",
      "0     26.1800  25.999239\n",
      "1     20.7400  20.646541\n",
      "2     23.0800  23.052756\n",
      "3     24.7000  24.660414\n",
      "4     29.2600  29.487666\n",
      "...       ...        ...\n",
      "1019  22.1800  22.008388\n",
      "1020  28.8300  28.947428\n",
      "1021  24.0825  23.923807\n",
      "1022  23.6200  23.442746\n",
      "1023  20.3300  20.020106\n",
      "\n",
      "[1024 rows x 2 columns]\n",
      "Epoch 10/25, Training Loss: 0.0107\n",
      "Epoch 10/25, Validation Loss: 0.0064\n",
      "       actual  predicted\n",
      "0     26.1800  26.074093\n",
      "1     20.7400  20.434975\n",
      "2     23.0800  23.069550\n",
      "3     24.7000  24.702231\n",
      "4     29.2600  29.432327\n",
      "...       ...        ...\n",
      "1019  22.1800  22.124132\n",
      "1020  28.8300  28.718637\n",
      "1021  24.0825  23.955326\n",
      "1022  23.6200  23.451380\n",
      "1023  20.3300  20.106857\n",
      "\n",
      "[1024 rows x 2 columns]\n",
      "Epoch 11/25, Training Loss: 0.0102\n",
      "Epoch 11/25, Validation Loss: 0.0050\n",
      "       actual  predicted\n",
      "0     26.1800  26.103416\n",
      "1     20.7400  20.813531\n",
      "2     23.0800  23.167272\n",
      "3     24.7000  24.781498\n",
      "4     29.2600  29.379216\n",
      "...       ...        ...\n",
      "1019  22.1800  22.220451\n",
      "1020  28.8300  28.747729\n",
      "1021  24.0825  24.014213\n",
      "1022  23.6200  23.709655\n",
      "1023  20.3300  20.231539\n",
      "\n",
      "[1024 rows x 2 columns]\n",
      "Epoch 12/25, Training Loss: 0.0097\n",
      "Epoch 12/25, Validation Loss: 0.0028\n",
      "       actual  predicted\n",
      "0     26.1800  26.170089\n",
      "1     20.7400  20.750428\n",
      "2     23.0800  23.109872\n",
      "3     24.7000  24.777036\n",
      "4     29.2600  29.364990\n",
      "...       ...        ...\n",
      "1019  22.1800  22.206285\n",
      "1020  28.8300  29.105683\n",
      "1021  24.0825  24.079889\n",
      "1022  23.6200  23.599704\n",
      "1023  20.3300  20.272411\n",
      "\n",
      "[1024 rows x 2 columns]\n",
      "Epoch 13/25, Training Loss: 0.0090\n",
      "Epoch 13/25, Validation Loss: 0.0053\n",
      "       actual  predicted\n",
      "0     26.1800  26.119085\n",
      "1     20.7400  20.650962\n",
      "2     23.0800  23.164367\n",
      "3     24.7000  24.739597\n",
      "4     29.2600  29.623118\n",
      "...       ...        ...\n",
      "1019  22.1800  22.216820\n",
      "1020  28.8300  29.039088\n",
      "1021  24.0825  24.115454\n",
      "1022  23.6200  23.616091\n",
      "1023  20.3300  20.254200\n",
      "\n",
      "[1024 rows x 2 columns]\n",
      "Epoch 14/25, Training Loss: 0.0087\n",
      "Epoch 14/25, Validation Loss: 0.0040\n",
      "       actual  predicted\n",
      "0     26.1800  26.147903\n",
      "1     20.7400  20.521136\n",
      "2     23.0800  23.040263\n",
      "3     24.7000  24.758840\n",
      "4     29.2600  29.534683\n",
      "...       ...        ...\n",
      "1019  22.1800  22.210828\n",
      "1020  28.8300  28.885720\n",
      "1021  24.0825  24.020815\n",
      "1022  23.6200  23.559432\n",
      "1023  20.3300  20.262010\n",
      "\n",
      "[1024 rows x 2 columns]\n",
      "Epoch 15/25, Training Loss: 0.0087\n",
      "Epoch 15/25, Validation Loss: 0.0042\n",
      "       actual  predicted\n",
      "0     26.1800  26.204443\n",
      "1     20.7400  20.678821\n",
      "2     23.0800  23.144487\n",
      "3     24.7000  24.755774\n",
      "4     29.2600  29.583305\n",
      "...       ...        ...\n",
      "1019  22.1800  22.191302\n",
      "1020  28.8300  28.999894\n",
      "1021  24.0825  24.072890\n",
      "1022  23.6200  23.532368\n",
      "1023  20.3300  20.232948\n",
      "\n",
      "[1024 rows x 2 columns]\n",
      "Epoch 16/25, Training Loss: 0.0087\n",
      "Epoch 16/25, Validation Loss: 0.0054\n",
      "       actual  predicted\n",
      "0     26.1800  26.026846\n",
      "1     20.7400  20.527707\n",
      "2     23.0800  23.045380\n",
      "3     24.7000  24.631857\n",
      "4     29.2600  29.328861\n",
      "...       ...        ...\n",
      "1019  22.1800  22.153868\n",
      "1020  28.8300  28.716363\n",
      "1021  24.0825  23.999785\n",
      "1022  23.6200  23.596970\n",
      "1023  20.3300  20.174138\n",
      "\n",
      "[1024 rows x 2 columns]\n",
      "Early stopping!\n",
      "       actual  predicted\n",
      "0       26.18  26.026846\n",
      "1       20.74  20.527707\n",
      "2       23.08  23.045380\n",
      "3       24.70  24.631857\n",
      "4       29.26  29.328861\n",
      "...       ...        ...\n",
      "61380   31.10  31.205987\n",
      "61381   24.21  24.188314\n",
      "61382   22.30  22.377283\n",
      "61383   22.46  22.318755\n",
      "61384   23.12  23.114778\n",
      "\n",
      "[61385 rows x 2 columns]\n",
      "Score (RMSE): 0.1928\n",
      "Score (MAE): 0.1182\n",
      "Score (ME): 0.0251\n",
      "Score (MAPE): 0.5069%\n",
      "training data cutoff:  2023-07-15 02:45:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Studium\\Semester_6\\IoT_Project\\utils.py:1036: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_train[columns_to_scale] = scaler.fit_transform(df_train[columns_to_scale])\n",
      "c:\\Studium\\Semester_6\\IoT_Project\\utils.py:1037: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_test[columns_to_scale] = scaler.transform(df_test[columns_to_scale])\n",
      "c:\\Studium\\Semester_6\\IoT_Project\\utils.py:1041: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_train.drop(['date_time_rounded'], axis=1, inplace=True)\n",
      "c:\\Studium\\Semester_6\\IoT_Project\\utils.py:1042: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_test.drop(['date_time_rounded'], axis=1, inplace=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device_id              int8\n",
      "tmp                 float64\n",
      "hum                 float64\n",
      "CO2                 float64\n",
      "VOC                 float64\n",
      "vis                 float64\n",
      "IR                  float64\n",
      "WIFI                float64\n",
      "BLE                 float64\n",
      "rssi                float64\n",
      "channel_rssi        float64\n",
      "channel_index       float64\n",
      "spreading_factor    float64\n",
      "bandwidth           float64\n",
      "f_cnt               float64\n",
      "isHoliday           float64\n",
      "isExamTime          float64\n",
      "weekday             float64\n",
      "month               float64\n",
      "hour_sin            float64\n",
      "semester_SS23       float64\n",
      "semester_WS22/23    float64\n",
      "semester_WS23/24    float64\n",
      "group                 int32\n",
      "dtype: object\n",
      "Training data shape: torch.Size([244176, 20, 22]) torch.Size([244176]) torch.Size([244176, 1])\n",
      "Testing data shape: torch.Size([62745, 20, 22]) torch.Size([62745]) torch.Size([62745, 1])\n",
      "Shuffled Training data shape: torch.Size([245536, 20, 22]) torch.Size([245536]) torch.Size([245536, 1])\n",
      "Shuffled Testing data shape: torch.Size([61385, 20, 22]) torch.Size([61385]) torch.Size([61385, 1])\n",
      "23\n",
      "same columns\n",
      "same dtypes\n",
      "0  rows differ from the last saved dataframe.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\t-ehm\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\transformer.py:286: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
      "c:\\Users\\t-ehm\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\optim\\lr_scheduler.py:28: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\"The verbose parameter is deprecated. Please use get_last_lr() \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          actual  predicted\n",
      "0     178.000000  37.249886\n",
      "1      34.999998  13.760179\n",
      "2     249.000001  52.939944\n",
      "3       9.000005  26.478077\n",
      "4       4.999995  18.776487\n",
      "...          ...        ...\n",
      "1019  119.999999  33.450110\n",
      "1020    4.999995  37.073156\n",
      "1021   12.000000  26.057518\n",
      "1022  124.000003  33.871319\n",
      "1023    5.999998  17.867461\n",
      "\n",
      "[1024 rows x 2 columns]\n",
      "Epoch 1/25, Training Loss: 0.5429\n",
      "Epoch 1/25, Validation Loss: 0.5008\n",
      "          actual  predicted\n",
      "0     178.000000  87.060935\n",
      "1      34.999998  32.456220\n",
      "2     249.000001  99.361079\n",
      "3       9.000005  41.895194\n",
      "4       4.999995  33.595743\n",
      "...          ...        ...\n",
      "1019  119.999999  85.386499\n",
      "1020    4.999995  63.439678\n",
      "1021   12.000000  43.846631\n",
      "1022  124.000003  59.600913\n",
      "1023    5.999998  36.889184\n",
      "\n",
      "[1024 rows x 2 columns]\n",
      "Epoch 2/25, Training Loss: 0.4720\n",
      "Epoch 2/25, Validation Loss: 0.4735\n",
      "          actual   predicted\n",
      "0     178.000000  136.177206\n",
      "1      34.999998   47.296242\n",
      "2     249.000001  193.416360\n",
      "3       9.000005   72.818773\n",
      "4       4.999995   44.790848\n",
      "...          ...         ...\n",
      "1019  119.999999   74.092891\n",
      "1020    4.999995  102.034207\n",
      "1021   12.000000   48.488586\n",
      "1022  124.000003   95.723699\n",
      "1023    5.999998   34.989039\n",
      "\n",
      "[1024 rows x 2 columns]\n",
      "Epoch 3/25, Training Loss: 0.4510\n",
      "Epoch 3/25, Validation Loss: 0.4484\n",
      "          actual   predicted\n",
      "0     178.000000   69.540704\n",
      "1      34.999998   15.987660\n",
      "2     249.000001  138.058267\n",
      "3       9.000005   28.112966\n",
      "4       4.999995   16.055647\n",
      "...          ...         ...\n",
      "1019  119.999999   53.962183\n",
      "1020    4.999995   49.335224\n",
      "1021   12.000000   25.863203\n",
      "1022  124.000003   88.983157\n",
      "1023    5.999998   15.435916\n",
      "\n",
      "[1024 rows x 2 columns]\n",
      "Epoch 4/25, Training Loss: 0.4473\n",
      "Epoch 4/25, Validation Loss: 0.4614\n",
      "          actual   predicted\n",
      "0     178.000000  145.732570\n",
      "1      34.999998   21.841368\n",
      "2     249.000001  152.528895\n",
      "3       9.000005   38.881525\n",
      "4       4.999995   15.379012\n",
      "...          ...         ...\n",
      "1019  119.999999   39.193512\n",
      "1020    4.999995   44.154992\n",
      "1021   12.000000   17.959646\n",
      "1022  124.000003   43.250835\n",
      "1023    5.999998   15.067584\n",
      "\n",
      "[1024 rows x 2 columns]\n",
      "Epoch 5/25, Training Loss: 0.4347\n",
      "Epoch 5/25, Validation Loss: 0.4652\n",
      "          actual  predicted\n",
      "0     178.000000  78.292461\n",
      "1      34.999998  15.809264\n",
      "2     249.000001  96.438564\n",
      "3       9.000005  45.234738\n",
      "4       4.999995  20.311732\n",
      "...          ...        ...\n",
      "1019  119.999999  38.054354\n",
      "1020    4.999995  39.105364\n",
      "1021   12.000000  18.557518\n",
      "1022  124.000003  48.674063\n",
      "1023    5.999998  14.845742\n",
      "\n",
      "[1024 rows x 2 columns]\n",
      "Epoch 6/25, Training Loss: 0.5605\n",
      "Epoch 6/25, Validation Loss: 0.4377\n",
      "          actual   predicted\n",
      "0     178.000000  255.435542\n",
      "1      34.999998   31.563672\n",
      "2     249.000001  217.978969\n",
      "3       9.000005   58.885279\n",
      "4       4.999995   21.009167\n",
      "...          ...         ...\n",
      "1019  119.999999   31.792197\n",
      "1020    4.999995   26.984573\n",
      "1021   12.000000   16.498922\n",
      "1022  124.000003   44.516846\n",
      "1023    5.999998   11.647144\n",
      "\n",
      "[1024 rows x 2 columns]\n",
      "Epoch 7/25, Training Loss: 0.4463\n",
      "Epoch 7/25, Validation Loss: 0.4418\n",
      "          actual   predicted\n",
      "0     178.000000  128.266693\n",
      "1      34.999998   53.662489\n",
      "2     249.000001  149.626188\n",
      "3       9.000005   59.096356\n",
      "4       4.999995   54.636241\n",
      "...          ...         ...\n",
      "1019  119.999999   89.128385\n",
      "1020    4.999995   65.577128\n",
      "1021   12.000000   56.759494\n",
      "1022  124.000003   90.153829\n",
      "1023    5.999998   50.686475\n",
      "\n",
      "[1024 rows x 2 columns]\n",
      "Epoch 8/25, Training Loss: 0.4251\n",
      "Epoch 8/25, Validation Loss: 0.4893\n",
      "          actual   predicted\n",
      "0     178.000000  113.880117\n",
      "1      34.999998   32.554837\n",
      "2     249.000001  230.318469\n",
      "3       9.000005   42.039048\n",
      "4       4.999995   30.511168\n",
      "...          ...         ...\n",
      "1019  119.999999   51.252485\n",
      "1020    4.999995   37.823753\n",
      "1021   12.000000   31.584780\n",
      "1022  124.000003   55.276795\n",
      "1023    5.999998   25.012563\n",
      "\n",
      "[1024 rows x 2 columns]\n",
      "Epoch 9/25, Training Loss: 0.4250\n",
      "Epoch 9/25, Validation Loss: 0.4902\n",
      "          actual   predicted\n",
      "0     178.000000   54.035405\n",
      "1      34.999998   42.651459\n",
      "2     249.000001  113.245288\n",
      "3       9.000005   46.670991\n",
      "4       4.999995   42.978327\n",
      "...          ...         ...\n",
      "1019  119.999999   45.692746\n",
      "1020    4.999995   44.948922\n",
      "1021   12.000000   40.517486\n",
      "1022  124.000003   47.465104\n",
      "1023    5.999998   38.605083\n",
      "\n",
      "[1024 rows x 2 columns]\n",
      "Epoch 10/25, Training Loss: 0.4496\n",
      "Epoch 10/25, Validation Loss: 0.4546\n",
      "          actual   predicted\n",
      "0     178.000000  168.213847\n",
      "1      34.999998   31.781637\n",
      "2     249.000001  332.553561\n",
      "3       9.000005   40.590571\n",
      "4       4.999995   28.923273\n",
      "...          ...         ...\n",
      "1019  119.999999   50.094659\n",
      "1020    4.999995   39.298492\n",
      "1021   12.000000   30.970488\n",
      "1022  124.000003   86.770398\n",
      "1023    5.999998   25.184151\n",
      "\n",
      "[1024 rows x 2 columns]\n",
      "Early stopping!\n",
      "           actual   predicted\n",
      "0      178.000000  168.213847\n",
      "1       34.999998   31.781637\n",
      "2      249.000001  332.553561\n",
      "3        9.000005   40.590571\n",
      "4        4.999995   28.923273\n",
      "...           ...         ...\n",
      "61380    9.000005   35.100154\n",
      "61381   14.000005   34.019678\n",
      "61382    4.999995   27.768560\n",
      "61383  350.600004  134.369657\n",
      "61384  741.999979  859.994716\n",
      "\n",
      "[61385 rows x 2 columns]\n",
      "Score (RMSE): 512.1503\n",
      "Score (MAE): 69.4106\n",
      "Score (ME): -18.5692\n",
      "Score (MAPE): 154077.1053%\n",
      "training data cutoff:  2023-07-14 05:00:00\n",
      "device_id              int8\n",
      "tmp                 float64\n",
      "hum                 float64\n",
      "CO2                 float64\n",
      "VOC                 float64\n",
      "vis                 float64\n",
      "IR                  float64\n",
      "WIFI                float64\n",
      "BLE                 float64\n",
      "rssi                float64\n",
      "channel_rssi        float64\n",
      "channel_index       float64\n",
      "spreading_factor    float64\n",
      "bandwidth           float64\n",
      "f_cnt               float64\n",
      "isHoliday           float64\n",
      "isExamTime          float64\n",
      "weekday             float64\n",
      "month               float64\n",
      "hour_sin            float64\n",
      "semester_SS23       float64\n",
      "semester_WS22/23    float64\n",
      "semester_WS23/24    float64\n",
      "group                 int32\n",
      "dtype: object\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Studium\\Semester_6\\IoT_Project\\utils.py:1036: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_train[columns_to_scale] = scaler.fit_transform(df_train[columns_to_scale])\n",
      "c:\\Studium\\Semester_6\\IoT_Project\\utils.py:1037: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_test[columns_to_scale] = scaler.transform(df_test[columns_to_scale])\n",
      "c:\\Studium\\Semester_6\\IoT_Project\\utils.py:1041: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_train.drop(['date_time_rounded'], axis=1, inplace=True)\n",
      "c:\\Studium\\Semester_6\\IoT_Project\\utils.py:1042: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_test.drop(['date_time_rounded'], axis=1, inplace=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data shape: torch.Size([75940, 20, 22]) torch.Size([75940]) torch.Size([75940, 1])\n",
      "Testing data shape: torch.Size([19215, 20, 22]) torch.Size([19215]) torch.Size([19215, 1])\n",
      "Shuffled Training data shape: torch.Size([76124, 20, 22]) torch.Size([76124]) torch.Size([76124, 1])\n",
      "Shuffled Testing data shape: torch.Size([19031, 20, 22]) torch.Size([19031]) torch.Size([19031, 1])\n",
      "23\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\t-ehm\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\transformer.py:286: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
      "c:\\Users\\t-ehm\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\optim\\lr_scheduler.py:28: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\"The verbose parameter is deprecated. Please use get_last_lr() \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          actual   predicted\n",
      "0     482.000000  416.814163\n",
      "1     515.249999  572.851106\n",
      "2     437.499998  408.629174\n",
      "3     435.250001  406.125044\n",
      "4     434.750001  431.429927\n",
      "...          ...         ...\n",
      "1019  400.499997  410.944252\n",
      "1020  460.250001  475.659887\n",
      "1021  421.999998  409.840948\n",
      "1022  498.500000  514.644230\n",
      "1023  406.250003  413.145933\n",
      "\n",
      "[1024 rows x 2 columns]\n",
      "Epoch 1/25, Training Loss: 0.4298\n",
      "Epoch 1/25, Validation Loss: 0.5986\n",
      "          actual   predicted\n",
      "0     482.000000  440.769802\n",
      "1     515.249999  520.172104\n",
      "2     437.499998  417.368664\n",
      "3     435.250001  408.383673\n",
      "4     434.750001  410.313946\n",
      "...          ...         ...\n",
      "1019  400.499997  404.463124\n",
      "1020  460.250001  464.033849\n",
      "1021  421.999998  414.569267\n",
      "1022  498.500000  508.632159\n",
      "1023  406.250003  414.283341\n",
      "\n",
      "[1024 rows x 2 columns]\n",
      "Epoch 2/25, Training Loss: 0.2696\n",
      "Epoch 2/25, Validation Loss: 0.5249\n",
      "          actual   predicted\n",
      "0     482.000000  462.988380\n",
      "1     515.249999  553.650054\n",
      "2     437.499998  429.197214\n",
      "3     435.250001  429.536945\n",
      "4     434.750001  438.942791\n",
      "...          ...         ...\n",
      "1019  400.499997  419.686704\n",
      "1020  460.250001  465.145870\n",
      "1021  421.999998  426.853948\n",
      "1022  498.500000  521.165826\n",
      "1023  406.250003  423.443407\n",
      "\n",
      "[1024 rows x 2 columns]\n",
      "Epoch 3/25, Training Loss: 0.2482\n",
      "Epoch 3/25, Validation Loss: 0.4987\n",
      "          actual   predicted\n",
      "0     482.000000  475.395992\n",
      "1     515.249999  578.135286\n",
      "2     437.499998  422.435921\n",
      "3     435.250001  418.038787\n",
      "4     434.750001  413.640586\n",
      "...          ...         ...\n",
      "1019  400.499997  406.618612\n",
      "1020  460.250001  470.135027\n",
      "1021  421.999998  426.051973\n",
      "1022  498.500000  524.704716\n",
      "1023  406.250003  414.368763\n",
      "\n",
      "[1024 rows x 2 columns]\n",
      "Epoch 4/25, Training Loss: 0.2443\n",
      "Epoch 4/25, Validation Loss: 0.4883\n",
      "          actual   predicted\n",
      "0     482.000000  452.987729\n",
      "1     515.249999  545.896619\n",
      "2     437.499998  429.305323\n",
      "3     435.250001  417.270130\n",
      "4     434.750001  431.164438\n",
      "...          ...         ...\n",
      "1019  400.499997  406.685203\n",
      "1020  460.250001  462.332860\n",
      "1021  421.999998  416.768133\n",
      "1022  498.500000  510.483290\n",
      "1023  406.250003  412.023283\n",
      "\n",
      "[1024 rows x 2 columns]\n",
      "Epoch 5/25, Training Loss: 0.2337\n",
      "Epoch 5/25, Validation Loss: 0.4691\n",
      "          actual   predicted\n",
      "0     482.000000  440.665284\n",
      "1     515.249999  526.768879\n",
      "2     437.499998  426.415618\n",
      "3     435.250001  419.748817\n",
      "4     434.750001  421.987987\n",
      "...          ...         ...\n",
      "1019  400.499997  409.697546\n",
      "1020  460.250001  451.656295\n",
      "1021  421.999998  422.410646\n",
      "1022  498.500000  491.672560\n",
      "1023  406.250003  414.269109\n",
      "\n",
      "[1024 rows x 2 columns]\n",
      "Epoch 6/25, Training Loss: 0.2352\n",
      "Epoch 6/25, Validation Loss: 0.4769\n",
      "          actual   predicted\n",
      "0     482.000000  450.683591\n",
      "1     515.249999  563.582609\n",
      "2     437.499998  424.559741\n",
      "3     435.250001  421.856244\n",
      "4     434.750001  423.862372\n",
      "...          ...         ...\n",
      "1019  400.499997  409.621545\n",
      "1020  460.250001  473.216370\n",
      "1021  421.999998  421.984393\n",
      "1022  498.500000  543.966781\n",
      "1023  406.250003  416.700139\n",
      "\n",
      "[1024 rows x 2 columns]\n",
      "Epoch 7/25, Training Loss: 0.2391\n",
      "Epoch 7/25, Validation Loss: 0.4583\n",
      "          actual   predicted\n",
      "0     482.000000  447.236022\n",
      "1     515.249999  519.986577\n",
      "2     437.499998  426.675567\n",
      "3     435.250001  426.659531\n",
      "4     434.750001  415.418304\n",
      "...          ...         ...\n",
      "1019  400.499997  407.805106\n",
      "1020  460.250001  463.010263\n",
      "1021  421.999998  423.493841\n",
      "1022  498.500000  516.047055\n",
      "1023  406.250003  415.057195\n",
      "\n",
      "[1024 rows x 2 columns]\n",
      "Epoch 8/25, Training Loss: 0.2355\n",
      "Epoch 8/25, Validation Loss: 0.4488\n",
      "          actual   predicted\n",
      "0     482.000000  472.392236\n",
      "1     515.249999  543.089937\n",
      "2     437.499998  448.305207\n",
      "3     435.250001  446.259373\n",
      "4     434.750001  442.288213\n",
      "...          ...         ...\n",
      "1019  400.499997  431.522327\n",
      "1020  460.250001  484.014737\n",
      "1021  421.999998  440.029257\n",
      "1022  498.500000  515.018031\n",
      "1023  406.250003  436.029653\n",
      "\n",
      "[1024 rows x 2 columns]\n",
      "Epoch 9/25, Training Loss: 0.2285\n",
      "Epoch 9/25, Validation Loss: 0.4914\n",
      "          actual   predicted\n",
      "0     482.000000  438.387872\n",
      "1     515.249999  535.128485\n",
      "2     437.499998  422.603221\n",
      "3     435.250001  416.234666\n",
      "4     434.750001  413.910591\n",
      "...          ...         ...\n",
      "1019  400.499997  402.363016\n",
      "1020  460.250001  445.429898\n",
      "1021  421.999998  416.050125\n",
      "1022  498.500000  498.114154\n",
      "1023  406.250003  406.418228\n",
      "\n",
      "[1024 rows x 2 columns]\n",
      "Epoch 10/25, Training Loss: 0.2249\n",
      "Epoch 10/25, Validation Loss: 0.4343\n",
      "          actual   predicted\n",
      "0     482.000000  452.760029\n",
      "1     515.249999  511.743177\n",
      "2     437.499998  432.836656\n",
      "3     435.250001  424.975366\n",
      "4     434.750001  420.692570\n",
      "...          ...         ...\n",
      "1019  400.499997  408.540559\n",
      "1020  460.250001  454.842426\n",
      "1021  421.999998  423.131694\n",
      "1022  498.500000  506.315397\n",
      "1023  406.250003  414.348322\n",
      "\n",
      "[1024 rows x 2 columns]\n",
      "Epoch 11/25, Training Loss: 0.2231\n",
      "Epoch 11/25, Validation Loss: 0.4355\n",
      "          actual   predicted\n",
      "0     482.000000  456.303855\n",
      "1     515.249999  537.246773\n",
      "2     437.499998  431.388280\n",
      "3     435.250001  427.296108\n",
      "4     434.750001  416.766678\n",
      "...          ...         ...\n",
      "1019  400.499997  401.224859\n",
      "1020  460.250001  454.334113\n",
      "1021  421.999998  420.154277\n",
      "1022  498.500000  514.907145\n",
      "1023  406.250003  412.016016\n",
      "\n",
      "[1024 rows x 2 columns]\n",
      "Epoch 12/25, Training Loss: 0.2229\n",
      "Epoch 12/25, Validation Loss: 0.4233\n",
      "          actual   predicted\n",
      "0     482.000000  448.166726\n",
      "1     515.249999  546.408130\n",
      "2     437.499998  430.259843\n",
      "3     435.250001  421.599597\n",
      "4     434.750001  417.083643\n",
      "...          ...         ...\n",
      "1019  400.499997  403.142569\n",
      "1020  460.250001  476.237956\n",
      "1021  421.999998  428.367813\n",
      "1022  498.500000  543.484036\n",
      "1023  406.250003  415.695576\n",
      "\n",
      "[1024 rows x 2 columns]\n",
      "Epoch 13/25, Training Loss: 0.2310\n",
      "Epoch 13/25, Validation Loss: 0.4808\n",
      "          actual   predicted\n",
      "0     482.000000  446.917834\n",
      "1     515.249999  523.999858\n",
      "2     437.499998  419.561551\n",
      "3     435.250001  418.650211\n",
      "4     434.750001  413.515325\n",
      "...          ...         ...\n",
      "1019  400.499997  399.153009\n",
      "1020  460.250001  454.054013\n",
      "1021  421.999998  415.974244\n",
      "1022  498.500000  509.785516\n",
      "1023  406.250003  412.094928\n",
      "\n",
      "[1024 rows x 2 columns]\n",
      "Epoch 14/25, Training Loss: 0.2257\n",
      "Epoch 14/25, Validation Loss: 0.4256\n",
      "          actual   predicted\n",
      "0     482.000000  460.525329\n",
      "1     515.249999  526.641001\n",
      "2     437.499998  425.074072\n",
      "3     435.250001  424.744382\n",
      "4     434.750001  401.536391\n",
      "...          ...         ...\n",
      "1019  400.499997  407.687905\n",
      "1020  460.250001  441.367781\n",
      "1021  421.999998  418.721571\n",
      "1022  498.500000  497.949303\n",
      "1023  406.250003  412.784772\n",
      "\n",
      "[1024 rows x 2 columns]\n",
      "Epoch 15/25, Training Loss: 0.2213\n",
      "Epoch 15/25, Validation Loss: 0.4135\n",
      "          actual   predicted\n",
      "0     482.000000  469.170997\n",
      "1     515.249999  570.589782\n",
      "2     437.499998  426.620970\n",
      "3     435.250001  422.452414\n",
      "4     434.750001  422.826533\n",
      "...          ...         ...\n",
      "1019  400.499997  402.585829\n",
      "1020  460.250001  471.388485\n",
      "1021  421.999998  423.527407\n",
      "1022  498.500000  535.745329\n",
      "1023  406.250003  408.916650\n",
      "\n",
      "[1024 rows x 2 columns]\n",
      "Epoch 16/25, Training Loss: 0.2227\n",
      "Epoch 16/25, Validation Loss: 0.4291\n",
      "          actual   predicted\n",
      "0     482.000000  449.928628\n",
      "1     515.249999  532.198425\n",
      "2     437.499998  431.263312\n",
      "3     435.250001  427.772215\n",
      "4     434.750001  422.529057\n",
      "...          ...         ...\n",
      "1019  400.499997  410.982515\n",
      "1020  460.250001  456.298319\n",
      "1021  421.999998  421.395821\n",
      "1022  498.500000  527.975069\n",
      "1023  406.250003  421.052203\n",
      "\n",
      "[1024 rows x 2 columns]\n",
      "Epoch 17/25, Training Loss: 0.2235\n",
      "Epoch 17/25, Validation Loss: 0.4028\n",
      "          actual   predicted\n",
      "0     482.000000  444.845713\n",
      "1     515.249999  514.964444\n",
      "2     437.499998  419.443700\n",
      "3     435.250001  425.126383\n",
      "4     434.750001  417.626512\n",
      "...          ...         ...\n",
      "1019  400.499997  404.565369\n",
      "1020  460.250001  445.519371\n",
      "1021  421.999998  414.674362\n",
      "1022  498.500000  505.375360\n",
      "1023  406.250003  407.074484\n",
      "\n",
      "[1024 rows x 2 columns]\n",
      "Epoch 18/25, Training Loss: 0.2103\n",
      "Epoch 18/25, Validation Loss: 0.4388\n",
      "          actual   predicted\n",
      "0     482.000000  457.477239\n",
      "1     515.249999  527.892855\n",
      "2     437.499998  432.930881\n",
      "3     435.250001  428.343717\n",
      "4     434.750001  413.146105\n",
      "...          ...         ...\n",
      "1019  400.499997  403.165317\n",
      "1020  460.250001  467.650952\n",
      "1021  421.999998  422.011769\n",
      "1022  498.500000  510.174080\n",
      "1023  406.250003  412.517272\n",
      "\n",
      "[1024 rows x 2 columns]\n",
      "Epoch 19/25, Training Loss: 0.2205\n",
      "Epoch 19/25, Validation Loss: 0.3920\n",
      "          actual   predicted\n",
      "0     482.000000  474.519458\n",
      "1     515.249999  550.609211\n",
      "2     437.499998  436.737054\n",
      "3     435.250001  435.435765\n",
      "4     434.750001  415.652319\n",
      "...          ...         ...\n",
      "1019  400.499997  402.869292\n",
      "1020  460.250001  487.382311\n",
      "1021  421.999998  418.649388\n",
      "1022  498.500000  538.595276\n",
      "1023  406.250003  416.090644\n",
      "\n",
      "[1024 rows x 2 columns]\n",
      "Epoch 20/25, Training Loss: 0.2228\n",
      "Epoch 20/25, Validation Loss: 0.4827\n",
      "          actual   predicted\n",
      "0     482.000000  445.706654\n",
      "1     515.249999  528.087078\n",
      "2     437.499998  423.904966\n",
      "3     435.250001  404.593585\n",
      "4     434.750001  394.000650\n",
      "...          ...         ...\n",
      "1019  400.499997  381.352371\n",
      "1020  460.250001  466.370200\n",
      "1021  421.999998  404.392744\n",
      "1022  498.500000  515.060688\n",
      "1023  406.250003  392.402711\n",
      "\n",
      "[1024 rows x 2 columns]\n",
      "Epoch 21/25, Training Loss: 0.2164\n",
      "Epoch 21/25, Validation Loss: 0.4038\n",
      "          actual   predicted\n",
      "0     482.000000  452.504218\n",
      "1     515.249999  543.658641\n",
      "2     437.499998  429.682241\n",
      "3     435.250001  422.492963\n",
      "4     434.750001  416.147764\n",
      "...          ...         ...\n",
      "1019  400.499997  407.030590\n",
      "1020  460.250001  454.207751\n",
      "1021  421.999998  422.357517\n",
      "1022  498.500000  514.055829\n",
      "1023  406.250003  413.114756\n",
      "\n",
      "[1024 rows x 2 columns]\n",
      "Epoch 22/25, Training Loss: 0.2086\n",
      "Epoch 22/25, Validation Loss: 0.3647\n",
      "          actual   predicted\n",
      "0     482.000000  433.390452\n",
      "1     515.249999  493.713937\n",
      "2     437.499998  420.904957\n",
      "3     435.250001  417.996245\n",
      "4     434.750001  418.920982\n",
      "...          ...         ...\n",
      "1019  400.499997  404.690595\n",
      "1020  460.250001  450.362252\n",
      "1021  421.999998  412.052669\n",
      "1022  498.500000  495.857756\n",
      "1023  406.250003  408.975216\n",
      "\n",
      "[1024 rows x 2 columns]\n",
      "Epoch 23/25, Training Loss: 0.2199\n",
      "Epoch 23/25, Validation Loss: 0.3993\n",
      "          actual   predicted\n",
      "0     482.000000  451.613064\n",
      "1     515.249999  534.468234\n",
      "2     437.499998  429.871737\n",
      "3     435.250001  422.794925\n",
      "4     434.750001  415.411571\n",
      "...          ...         ...\n",
      "1019  400.499997  397.286348\n",
      "1020  460.250001  453.951957\n",
      "1021  421.999998  410.137576\n",
      "1022  498.500000  521.706160\n",
      "1023  406.250003  403.039454\n",
      "\n",
      "[1024 rows x 2 columns]\n",
      "Epoch 24/25, Training Loss: 0.2024\n",
      "Epoch 24/25, Validation Loss: 0.4642\n",
      "          actual   predicted\n",
      "0     482.000000  466.988184\n",
      "1     515.249999  544.452613\n",
      "2     437.499998  429.030970\n",
      "3     435.250001  420.019774\n",
      "4     434.750001  412.847575\n",
      "...          ...         ...\n",
      "1019  400.499997  389.674037\n",
      "1020  460.250001  446.990491\n",
      "1021  421.999998  408.671924\n",
      "1022  498.500000  518.352334\n",
      "1023  406.250003  398.017659\n",
      "\n",
      "[1024 rows x 2 columns]\n",
      "Epoch 25/25, Training Loss: 0.2088\n",
      "Epoch 25/25, Validation Loss: 0.3504\n",
      "           actual   predicted\n",
      "0      482.000000  466.988184\n",
      "1      515.249999  544.452613\n",
      "2      437.499998  429.030970\n",
      "3      435.250001  420.019774\n",
      "4      434.750001  412.847575\n",
      "...           ...         ...\n",
      "19026  463.499999  469.536458\n",
      "19027  302.500004  373.504298\n",
      "19028  527.250001  527.291992\n",
      "19029  411.249998  417.742594\n",
      "19030  540.249999  547.135020\n",
      "\n",
      "[19031 rows x 2 columns]\n",
      "Score (RMSE): 86.0788\n",
      "Score (MAE): 21.8756\n",
      "Score (ME): 6.4852\n",
      "Score (MAPE): 3.7468%\n",
      "training data cutoff:  2023-07-14 05:00:00\n",
      "device_id              int8\n",
      "tmp                 float64\n",
      "hum                 float64\n",
      "CO2                 float64\n",
      "VOC                 float64\n",
      "vis                 float64\n",
      "IR                  float64\n",
      "WIFI                float64\n",
      "BLE                 float64\n",
      "rssi                float64\n",
      "channel_rssi        float64\n",
      "channel_index       float64\n",
      "spreading_factor    float64\n",
      "bandwidth           float64\n",
      "f_cnt               float64\n",
      "isHoliday           float64\n",
      "isExamTime          float64\n",
      "weekday             float64\n",
      "month               float64\n",
      "hour_sin            float64\n",
      "semester_SS23       float64\n",
      "semester_WS22/23    float64\n",
      "semester_WS23/24    float64\n",
      "group                 int32\n",
      "dtype: object\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Studium\\Semester_6\\IoT_Project\\utils.py:1036: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_train[columns_to_scale] = scaler.fit_transform(df_train[columns_to_scale])\n",
      "c:\\Studium\\Semester_6\\IoT_Project\\utils.py:1037: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_test[columns_to_scale] = scaler.transform(df_test[columns_to_scale])\n",
      "c:\\Studium\\Semester_6\\IoT_Project\\utils.py:1041: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_train.drop(['date_time_rounded'], axis=1, inplace=True)\n",
      "c:\\Studium\\Semester_6\\IoT_Project\\utils.py:1042: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_test.drop(['date_time_rounded'], axis=1, inplace=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data shape: torch.Size([75940, 20, 22]) torch.Size([75940]) torch.Size([75940, 1])\n",
      "Testing data shape: torch.Size([19215, 20, 22]) torch.Size([19215]) torch.Size([19215, 1])\n",
      "Shuffled Training data shape: torch.Size([76124, 20, 22]) torch.Size([76124]) torch.Size([76124, 1])\n",
      "Shuffled Testing data shape: torch.Size([19031, 20, 22]) torch.Size([19031]) torch.Size([19031, 1])\n",
      "23\n",
      "same columns\n",
      "same dtypes\n",
      "0  rows differ from the last saved dataframe.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\t-ehm\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\transformer.py:286: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
      "c:\\Users\\t-ehm\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\optim\\lr_scheduler.py:28: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\"The verbose parameter is deprecated. Please use get_last_lr() \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           actual    predicted\n",
      "0      663.750004   613.683397\n",
      "1      858.250002  1119.108261\n",
      "2      646.250002   598.204713\n",
      "3     1887.000028  2056.745883\n",
      "4      548.999992   580.019294\n",
      "...           ...          ...\n",
      "1019   707.999997   672.859741\n",
      "1020   946.249999  1009.744139\n",
      "1021   605.250001   636.010704\n",
      "1022  1242.750006  1184.046737\n",
      "1023   624.750008   626.905575\n",
      "\n",
      "[1024 rows x 2 columns]\n",
      "Epoch 1/25, Training Loss: 0.3077\n",
      "Epoch 1/25, Validation Loss: 0.1214\n",
      "           actual    predicted\n",
      "0      663.750004   613.034275\n",
      "1      858.250002  1075.166687\n",
      "2      646.250002   605.708918\n",
      "3     1887.000028  1980.188998\n",
      "4      548.999992   579.552741\n",
      "...           ...          ...\n",
      "1019   707.999997   646.299700\n",
      "1020   946.249999   943.629283\n",
      "1021   605.250001   619.107556\n",
      "1022  1242.750006  1184.296400\n",
      "1023   624.750008   623.748438\n",
      "\n",
      "[1024 rows x 2 columns]\n",
      "Epoch 2/25, Training Loss: 0.1618\n",
      "Epoch 2/25, Validation Loss: 0.1189\n",
      "           actual    predicted\n",
      "0      663.750004   656.610596\n",
      "1      858.250002  1041.591885\n",
      "2      646.250002   621.641832\n",
      "3     1887.000028  2307.938678\n",
      "4      548.999992   600.950997\n",
      "...           ...          ...\n",
      "1019   707.999997   680.702999\n",
      "1020   946.249999   935.242987\n",
      "1021   605.250001   649.851985\n",
      "1022  1242.750006  1097.676563\n",
      "1023   624.750008   666.600599\n",
      "\n",
      "[1024 rows x 2 columns]\n",
      "Epoch 3/25, Training Loss: 0.1487\n",
      "Epoch 3/25, Validation Loss: 0.1325\n",
      "           actual    predicted\n",
      "0      663.750004   611.931800\n",
      "1      858.250002  1092.134138\n",
      "2      646.250002   603.165478\n",
      "3     1887.000028  2192.050416\n",
      "4      548.999992   579.360306\n",
      "...           ...          ...\n",
      "1019   707.999997   659.707747\n",
      "1020   946.249999   955.629035\n",
      "1021   605.250001   632.957141\n",
      "1022  1242.750006  1143.287490\n",
      "1023   624.750008   642.969289\n",
      "\n",
      "[1024 rows x 2 columns]\n",
      "Epoch 4/25, Training Loss: 0.1400\n",
      "Epoch 4/25, Validation Loss: 0.1191\n",
      "           actual    predicted\n",
      "0      663.750004   627.154308\n",
      "1      858.250002  1095.148712\n",
      "2      646.250002   634.953328\n",
      "3     1887.000028  1969.968404\n",
      "4      548.999992   597.172949\n",
      "...           ...          ...\n",
      "1019   707.999997   664.763291\n",
      "1020   946.249999   941.727716\n",
      "1021   605.250001   636.881683\n",
      "1022  1242.750006  1147.695140\n",
      "1023   624.750008   654.719228\n",
      "\n",
      "[1024 rows x 2 columns]\n",
      "Epoch 5/25, Training Loss: 0.1361\n",
      "Epoch 5/25, Validation Loss: 0.1119\n",
      "           actual    predicted\n",
      "0      663.750004   636.471534\n",
      "1      858.250002  1263.493943\n",
      "2      646.250002   631.790679\n",
      "3     1887.000028  2141.392284\n",
      "4      548.999992   588.839966\n",
      "...           ...          ...\n",
      "1019   707.999997   674.079262\n",
      "1020   946.249999   963.805500\n",
      "1021   605.250001   618.098174\n",
      "1022  1242.750006  1212.109360\n",
      "1023   624.750008   637.915606\n",
      "\n",
      "[1024 rows x 2 columns]\n",
      "Epoch 6/25, Training Loss: 0.1325\n",
      "Epoch 6/25, Validation Loss: 0.1342\n",
      "           actual    predicted\n",
      "0      663.750004   622.924892\n",
      "1      858.250002  1166.745394\n",
      "2      646.250002   610.575993\n",
      "3     1887.000028  1989.754799\n",
      "4      548.999992   572.345405\n",
      "...           ...          ...\n",
      "1019   707.999997   664.866004\n",
      "1020   946.249999   988.567968\n",
      "1021   605.250001   609.898520\n",
      "1022  1242.750006  1164.612665\n",
      "1023   624.750008   620.300665\n",
      "\n",
      "[1024 rows x 2 columns]\n",
      "Epoch 7/25, Training Loss: 0.1319\n",
      "Epoch 7/25, Validation Loss: 0.1179\n",
      "           actual    predicted\n",
      "0      663.750004   635.288185\n",
      "1      858.250002  1075.695156\n",
      "2      646.250002   627.343197\n",
      "3     1887.000028  2023.772841\n",
      "4      548.999992   596.603666\n",
      "...           ...          ...\n",
      "1019   707.999997   680.782530\n",
      "1020   946.249999   929.933443\n",
      "1021   605.250001   625.622041\n",
      "1022  1242.750006  1179.755650\n",
      "1023   624.750008   653.345734\n",
      "\n",
      "[1024 rows x 2 columns]\n",
      "Epoch 8/25, Training Loss: 0.1302\n",
      "Epoch 8/25, Validation Loss: 0.1074\n",
      "           actual    predicted\n",
      "0      663.750004   605.878339\n",
      "1      858.250002  1208.203601\n",
      "2      646.250002   597.645681\n",
      "3     1887.000028  1873.880932\n",
      "4      548.999992   566.844901\n",
      "...           ...          ...\n",
      "1019   707.999997   655.231678\n",
      "1020   946.249999   986.099803\n",
      "1021   605.250001   593.719664\n",
      "1022  1242.750006  1237.122300\n",
      "1023   624.750008   609.691935\n",
      "\n",
      "[1024 rows x 2 columns]\n",
      "Epoch 9/25, Training Loss: 0.1256\n",
      "Epoch 9/25, Validation Loss: 0.1300\n",
      "           actual    predicted\n",
      "0      663.750004   611.687666\n",
      "1      858.250002  1171.281861\n",
      "2      646.250002   609.613308\n",
      "3     1887.000028  2294.921751\n",
      "4      548.999992   556.328667\n",
      "...           ...          ...\n",
      "1019   707.999997   683.223555\n",
      "1020   946.249999  1000.997232\n",
      "1021   605.250001   600.221123\n",
      "1022  1242.750006  1228.787017\n",
      "1023   624.750008   659.989159\n",
      "\n",
      "[1024 rows x 2 columns]\n",
      "Epoch 10/25, Training Loss: 0.1291\n",
      "Epoch 10/25, Validation Loss: 0.1236\n",
      "           actual    predicted\n",
      "0      663.750004   624.270394\n",
      "1      858.250002  1085.454323\n",
      "2      646.250002   627.023683\n",
      "3     1887.000028  2109.173254\n",
      "4      548.999992   586.972841\n",
      "...           ...          ...\n",
      "1019   707.999997   666.763656\n",
      "1020   946.249999   939.479162\n",
      "1021   605.250001   611.321860\n",
      "1022  1242.750006  1147.171727\n",
      "1023   624.750008   653.416032\n",
      "\n",
      "[1024 rows x 2 columns]\n",
      "Epoch 11/25, Training Loss: 0.1258\n",
      "Epoch 11/25, Validation Loss: 0.1050\n",
      "           actual    predicted\n",
      "0      663.750004   629.164487\n",
      "1      858.250002  1091.854034\n",
      "2      646.250002   623.802349\n",
      "3     1887.000028  2247.651829\n",
      "4      548.999992   585.013905\n",
      "...           ...          ...\n",
      "1019   707.999997   678.075665\n",
      "1020   946.249999   968.238130\n",
      "1021   605.250001   596.383143\n",
      "1022  1242.750006  1175.063999\n",
      "1023   624.750008   644.524115\n",
      "\n",
      "[1024 rows x 2 columns]\n",
      "Epoch 12/25, Training Loss: 0.1257\n",
      "Epoch 12/25, Validation Loss: 0.1099\n",
      "           actual    predicted\n",
      "0      663.750004   615.636242\n",
      "1      858.250002  1141.959929\n",
      "2      646.250002   610.327155\n",
      "3     1887.000028  2070.066157\n",
      "4      548.999992   573.308214\n",
      "...           ...          ...\n",
      "1019   707.999997   668.596558\n",
      "1020   946.249999   955.855808\n",
      "1021   605.250001   604.934226\n",
      "1022  1242.750006  1203.117529\n",
      "1023   624.750008   638.496441\n",
      "\n",
      "[1024 rows x 2 columns]\n",
      "Epoch 13/25, Training Loss: 0.1192\n",
      "Epoch 13/25, Validation Loss: 0.1123\n",
      "           actual    predicted\n",
      "0      663.750004   628.051286\n",
      "1      858.250002  1137.855800\n",
      "2      646.250002   627.226283\n",
      "3     1887.000028  1938.501912\n",
      "4      548.999992   577.232563\n",
      "...           ...          ...\n",
      "1019   707.999997   662.386850\n",
      "1020   946.249999   935.867743\n",
      "1021   605.250001   589.336327\n",
      "1022  1242.750006  1161.255984\n",
      "1023   624.750008   635.932357\n",
      "\n",
      "[1024 rows x 2 columns]\n",
      "Epoch 14/25, Training Loss: 0.1194\n",
      "Epoch 14/25, Validation Loss: 0.1026\n",
      "           actual    predicted\n",
      "0      663.750004   617.014343\n",
      "1      858.250002  1118.221745\n",
      "2      646.250002   612.286108\n",
      "3     1887.000028  1987.810012\n",
      "4      548.999992   572.689759\n",
      "...           ...          ...\n",
      "1019   707.999997   656.261984\n",
      "1020   946.249999   926.350964\n",
      "1021   605.250001   588.134984\n",
      "1022  1242.750006  1137.041997\n",
      "1023   624.750008   639.671012\n",
      "\n",
      "[1024 rows x 2 columns]\n",
      "Epoch 15/25, Training Loss: 0.1192\n",
      "Epoch 15/25, Validation Loss: 0.1081\n",
      "           actual    predicted\n",
      "0      663.750004   614.634163\n",
      "1      858.250002  1126.119774\n",
      "2      646.250002   611.072828\n",
      "3     1887.000028  2185.416541\n",
      "4      548.999992   574.689879\n",
      "...           ...          ...\n",
      "1019   707.999997   693.490283\n",
      "1020   946.249999   949.271226\n",
      "1021   605.250001   598.017825\n",
      "1022  1242.750006  1166.288759\n",
      "1023   624.750008   652.152914\n",
      "\n",
      "[1024 rows x 2 columns]\n",
      "Epoch 16/25, Training Loss: 0.1205\n",
      "Epoch 16/25, Validation Loss: 0.1215\n",
      "           actual    predicted\n",
      "0      663.750004   619.066162\n",
      "1      858.250002  1067.042395\n",
      "2      646.250002   616.643271\n",
      "3     1887.000028  1882.647781\n",
      "4      548.999992   571.334567\n",
      "...           ...          ...\n",
      "1019   707.999997   666.277451\n",
      "1020   946.249999   945.026432\n",
      "1021   605.250001   594.831091\n",
      "1022  1242.750006  1180.569454\n",
      "1023   624.750008   648.146206\n",
      "\n",
      "[1024 rows x 2 columns]\n",
      "Epoch 17/25, Training Loss: 0.1225\n",
      "Epoch 17/25, Validation Loss: 0.1042\n",
      "           actual    predicted\n",
      "0      663.750004   651.615072\n",
      "1      858.250002  1079.563945\n",
      "2      646.250002   644.801348\n",
      "3     1887.000028  1813.241934\n",
      "4      548.999992   588.644108\n",
      "...           ...          ...\n",
      "1019   707.999997   680.128589\n",
      "1020   946.249999   944.126943\n",
      "1021   605.250001   603.574048\n",
      "1022  1242.750006  1148.378020\n",
      "1023   624.750008   657.313339\n",
      "\n",
      "[1024 rows x 2 columns]\n",
      "Epoch 18/25, Training Loss: 0.1180\n",
      "Epoch 18/25, Validation Loss: 0.1045\n",
      "           actual    predicted\n",
      "0      663.750004   623.562744\n",
      "1      858.250002  1035.943026\n",
      "2      646.250002   619.409743\n",
      "3     1887.000028  2039.424387\n",
      "4      548.999992   563.960811\n",
      "...           ...          ...\n",
      "1019   707.999997   666.980177\n",
      "1020   946.249999   923.988198\n",
      "1021   605.250001   580.091041\n",
      "1022  1242.750006  1159.504756\n",
      "1023   624.750008   635.986724\n",
      "\n",
      "[1024 rows x 2 columns]\n",
      "Early stopping!\n",
      "            actual    predicted\n",
      "0       663.750004   623.562744\n",
      "1       858.250002  1035.943026\n",
      "2       646.250002   619.409743\n",
      "3      1887.000028  2039.424387\n",
      "4       548.999992   563.960811\n",
      "...            ...          ...\n",
      "19026   793.750000   772.020537\n",
      "19027   867.750004   798.488903\n",
      "19028   627.000002   588.089798\n",
      "19029  1093.428556   893.949215\n",
      "19030   570.000001   560.437289\n",
      "\n",
      "[19031 rows x 2 columns]\n",
      "Score (RMSE): 95.2835\n",
      "Score (MAE): 44.3817\n",
      "Score (ME): 7.4413\n",
      "Score (MAPE): 5.0541%\n",
      "training data cutoff:  2023-07-14 05:00:00\n",
      "device_id              int8\n",
      "tmp                 float64\n",
      "hum                 float64\n",
      "CO2                 float64\n",
      "VOC                 float64\n",
      "vis                 float64\n",
      "IR                  float64\n",
      "WIFI                float64\n",
      "BLE                 float64\n",
      "rssi                float64\n",
      "channel_rssi        float64\n",
      "channel_index       float64\n",
      "spreading_factor    float64\n",
      "bandwidth           float64\n",
      "f_cnt               float64\n",
      "isHoliday           float64\n",
      "isExamTime          float64\n",
      "weekday             float64\n",
      "month               float64\n",
      "hour_sin            float64\n",
      "semester_SS23       float64\n",
      "semester_WS22/23    float64\n",
      "semester_WS23/24    float64\n",
      "group                 int32\n",
      "dtype: object\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Studium\\Semester_6\\IoT_Project\\utils.py:1036: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_train[columns_to_scale] = scaler.fit_transform(df_train[columns_to_scale])\n",
      "c:\\Studium\\Semester_6\\IoT_Project\\utils.py:1037: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_test[columns_to_scale] = scaler.transform(df_test[columns_to_scale])\n",
      "c:\\Studium\\Semester_6\\IoT_Project\\utils.py:1041: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_train.drop(['date_time_rounded'], axis=1, inplace=True)\n",
      "c:\\Studium\\Semester_6\\IoT_Project\\utils.py:1042: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_test.drop(['date_time_rounded'], axis=1, inplace=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data shape: torch.Size([75940, 20, 22]) torch.Size([75940]) torch.Size([75940, 1])\n",
      "Testing data shape: torch.Size([19215, 20, 22]) torch.Size([19215]) torch.Size([19215, 1])\n",
      "Shuffled Training data shape: torch.Size([76124, 20, 22]) torch.Size([76124]) torch.Size([76124, 1])\n",
      "Shuffled Testing data shape: torch.Size([19031, 20, 22]) torch.Size([19031]) torch.Size([19031, 1])\n",
      "23\n",
      "same columns\n",
      "same dtypes\n",
      "0  rows differ from the last saved dataframe.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\t-ehm\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\transformer.py:286: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
      "c:\\Users\\t-ehm\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\optim\\lr_scheduler.py:28: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\"The verbose parameter is deprecated. Please use get_last_lr() \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         actual  predicted\n",
      "0     42.666667  45.748997\n",
      "1     45.045000  48.124196\n",
      "2     29.677500  28.540098\n",
      "3     37.537500  37.696715\n",
      "4     31.567500  28.130133\n",
      "...         ...        ...\n",
      "1019  35.700000  37.667827\n",
      "1020  35.390000  36.242795\n",
      "1021  47.847500  49.701507\n",
      "1022  38.272500  39.129132\n",
      "1023  53.042501  54.414705\n",
      "\n",
      "[1024 rows x 2 columns]\n",
      "Epoch 1/25, Training Loss: 0.1542\n",
      "Epoch 1/25, Validation Loss: 0.0290\n",
      "         actual  predicted\n",
      "0     42.666667  45.424940\n",
      "1     45.045000  47.426910\n",
      "2     29.677500  30.491884\n",
      "3     37.537500  38.588811\n",
      "4     31.567500  32.009581\n",
      "...         ...        ...\n",
      "1019  35.700000  37.320804\n",
      "1020  35.390000  36.189091\n",
      "1021  47.847500  48.335674\n",
      "1022  38.272500  38.877917\n",
      "1023  53.042501  52.330530\n",
      "\n",
      "[1024 rows x 2 columns]\n",
      "Epoch 2/25, Training Loss: 0.0555\n",
      "Epoch 2/25, Validation Loss: 0.0277\n",
      "         actual  predicted\n",
      "0     42.666667  43.650113\n",
      "1     45.045000  45.876534\n",
      "2     29.677500  26.216910\n",
      "3     37.537500  35.581145\n",
      "4     31.567500  28.594984\n",
      "...         ...        ...\n",
      "1019  35.700000  35.522729\n",
      "1020  35.390000  34.501155\n",
      "1021  47.847500  47.627278\n",
      "1022  38.272500  37.348382\n",
      "1023  53.042501  54.094070\n",
      "\n",
      "[1024 rows x 2 columns]\n",
      "Epoch 3/25, Training Loss: 0.0447\n",
      "Epoch 3/25, Validation Loss: 0.0466\n",
      "         actual  predicted\n",
      "0     42.666667  44.834044\n",
      "1     45.045000  46.544290\n",
      "2     29.677500  29.378197\n",
      "3     37.537500  38.189540\n",
      "4     31.567500  31.080363\n",
      "...         ...        ...\n",
      "1019  35.700000  37.140577\n",
      "1020  35.390000  35.897555\n",
      "1021  47.847500  48.304389\n",
      "1022  38.272500  39.059231\n",
      "1023  53.042501  52.950873\n",
      "\n",
      "[1024 rows x 2 columns]\n",
      "Epoch 4/25, Training Loss: 0.0397\n",
      "Epoch 4/25, Validation Loss: 0.0280\n",
      "         actual  predicted\n",
      "0     42.666667  43.904828\n",
      "1     45.045000  45.517722\n",
      "2     29.677500  29.110368\n",
      "3     37.537500  37.001160\n",
      "4     31.567500  30.745575\n",
      "...         ...        ...\n",
      "1019  35.700000  36.361193\n",
      "1020  35.390000  35.668367\n",
      "1021  47.847500  47.105476\n",
      "1022  38.272500  38.267751\n",
      "1023  53.042501  53.063783\n",
      "\n",
      "[1024 rows x 2 columns]\n",
      "Epoch 5/25, Training Loss: 0.0360\n",
      "Epoch 5/25, Validation Loss: 0.0166\n",
      "         actual  predicted\n",
      "0     42.666667  44.495713\n",
      "1     45.045000  46.310847\n",
      "2     29.677500  30.154483\n",
      "3     37.537500  38.235593\n",
      "4     31.567500  31.408486\n",
      "...         ...        ...\n",
      "1019  35.700000  36.671545\n",
      "1020  35.390000  36.019484\n",
      "1021  47.847500  48.336315\n",
      "1022  38.272500  38.609793\n",
      "1023  53.042501  53.991670\n",
      "\n",
      "[1024 rows x 2 columns]\n",
      "Epoch 6/25, Training Loss: 0.0326\n",
      "Epoch 6/25, Validation Loss: 0.0226\n",
      "         actual  predicted\n",
      "0     42.666667  43.220264\n",
      "1     45.045000  45.164800\n",
      "2     29.677500  28.324161\n",
      "3     37.537500  36.527247\n",
      "4     31.567500  30.069143\n",
      "...         ...        ...\n",
      "1019  35.700000  35.476215\n",
      "1020  35.390000  34.970072\n",
      "1021  47.847500  46.669532\n",
      "1022  38.272500  37.115610\n",
      "1023  53.042501  52.813173\n",
      "\n",
      "[1024 rows x 2 columns]\n",
      "Epoch 7/25, Training Loss: 0.0308\n",
      "Epoch 7/25, Validation Loss: 0.0157\n",
      "         actual  predicted\n",
      "0     42.666667  44.574980\n",
      "1     45.045000  45.820095\n",
      "2     29.677500  29.724676\n",
      "3     37.537500  37.589349\n",
      "4     31.567500  31.322449\n",
      "...         ...        ...\n",
      "1019  35.700000  36.267033\n",
      "1020  35.390000  35.959454\n",
      "1021  47.847500  47.839324\n",
      "1022  38.272500  38.179169\n",
      "1023  53.042501  53.060936\n",
      "\n",
      "[1024 rows x 2 columns]\n",
      "Epoch 8/25, Training Loss: 0.0285\n",
      "Epoch 8/25, Validation Loss: 0.0154\n",
      "         actual  predicted\n",
      "0     42.666667  43.077657\n",
      "1     45.045000  44.948723\n",
      "2     29.677500  28.954565\n",
      "3     37.537500  37.194049\n",
      "4     31.567500  31.047553\n",
      "...         ...        ...\n",
      "1019  35.700000  36.302434\n",
      "1020  35.390000  35.626538\n",
      "1021  47.847500  47.462169\n",
      "1022  38.272500  38.344824\n",
      "1023  53.042501  52.789455\n",
      "\n",
      "[1024 rows x 2 columns]\n",
      "Epoch 9/25, Training Loss: 0.0270\n",
      "Epoch 9/25, Validation Loss: 0.0118\n",
      "         actual  predicted\n",
      "0     42.666667  43.387631\n",
      "1     45.045000  45.560003\n",
      "2     29.677500  29.263956\n",
      "3     37.537500  37.605634\n",
      "4     31.567500  31.033487\n",
      "...         ...        ...\n",
      "1019  35.700000  36.378367\n",
      "1020  35.390000  35.770000\n",
      "1021  47.847500  48.021485\n",
      "1022  38.272500  38.207713\n",
      "1023  53.042501  53.949913\n",
      "\n",
      "[1024 rows x 2 columns]\n",
      "Epoch 10/25, Training Loss: 0.0256\n",
      "Epoch 10/25, Validation Loss: 0.0157\n",
      "         actual  predicted\n",
      "0     42.666667  43.446022\n",
      "1     45.045000  45.568061\n",
      "2     29.677500  28.855451\n",
      "3     37.537500  37.144619\n",
      "4     31.567500  30.877142\n",
      "...         ...        ...\n",
      "1019  35.700000  36.181850\n",
      "1020  35.390000  35.342361\n",
      "1021  47.847500  47.362589\n",
      "1022  38.272500  38.034372\n",
      "1023  53.042501  53.553907\n",
      "\n",
      "[1024 rows x 2 columns]\n",
      "Epoch 11/25, Training Loss: 0.0248\n",
      "Epoch 11/25, Validation Loss: 0.0152\n",
      "         actual  predicted\n",
      "0     42.666667  43.704905\n",
      "1     45.045000  45.925507\n",
      "2     29.677500  28.421346\n",
      "3     37.537500  37.405388\n",
      "4     31.567500  30.583965\n",
      "...         ...        ...\n",
      "1019  35.700000  36.562443\n",
      "1020  35.390000  35.651551\n",
      "1021  47.847500  48.119077\n",
      "1022  38.272500  38.614324\n",
      "1023  53.042501  54.381258\n",
      "\n",
      "[1024 rows x 2 columns]\n",
      "Epoch 12/25, Training Loss: 0.0235\n",
      "Epoch 12/25, Validation Loss: 0.0172\n",
      "         actual  predicted\n",
      "0     42.666667  42.822894\n",
      "1     45.045000  45.004231\n",
      "2     29.677500  29.715774\n",
      "3     37.537500  37.844781\n",
      "4     31.567500  31.263733\n",
      "...         ...        ...\n",
      "1019  35.700000  36.280675\n",
      "1020  35.390000  35.567220\n",
      "1021  47.847500  46.640078\n",
      "1022  38.272500  38.022907\n",
      "1023  53.042501  51.296797\n",
      "\n",
      "[1024 rows x 2 columns]\n",
      "Epoch 13/25, Training Loss: 0.0224\n",
      "Epoch 13/25, Validation Loss: 0.0142\n",
      "         actual  predicted\n",
      "0     42.666667  43.883083\n",
      "1     45.045000  45.870919\n",
      "2     29.677500  29.404625\n",
      "3     37.537500  37.816552\n",
      "4     31.567500  31.136279\n",
      "...         ...        ...\n",
      "1019  35.700000  36.457895\n",
      "1020  35.390000  35.541352\n",
      "1021  47.847500  47.798210\n",
      "1022  38.272500  38.490419\n",
      "1023  53.042501  53.321862\n",
      "\n",
      "[1024 rows x 2 columns]\n",
      "Early stopping!\n",
      "          actual  predicted\n",
      "0      42.666667  43.883083\n",
      "1      45.045000  45.870919\n",
      "2      29.677500  29.404625\n",
      "3      37.537500  37.816552\n",
      "4      31.567500  31.136279\n",
      "...          ...        ...\n",
      "19026  32.380000  32.203122\n",
      "19027  38.463333  38.310590\n",
      "19028  38.975000  39.590865\n",
      "19029  27.005000  26.749690\n",
      "19030  50.340000  55.432131\n",
      "\n",
      "[19031 rows x 2 columns]\n",
      "Score (RMSE): 1.1626\n",
      "Score (MAE): 0.7799\n",
      "Score (ME): -0.0652\n",
      "Score (MAPE): 2.1926%\n",
      "training data cutoff:  2023-07-14 05:00:00\n",
      "device_id              int8\n",
      "tmp                 float64\n",
      "hum                 float64\n",
      "CO2                 float64\n",
      "VOC                 float64\n",
      "vis                 float64\n",
      "IR                  float64\n",
      "WIFI                float64\n",
      "BLE                 float64\n",
      "rssi                float64\n",
      "channel_rssi        float64\n",
      "channel_index       float64\n",
      "spreading_factor    float64\n",
      "bandwidth           float64\n",
      "f_cnt               float64\n",
      "isHoliday           float64\n",
      "isExamTime          float64\n",
      "weekday             float64\n",
      "month               float64\n",
      "hour_sin            float64\n",
      "semester_SS23       float64\n",
      "semester_WS22/23    float64\n",
      "semester_WS23/24    float64\n",
      "group                 int32\n",
      "dtype: object\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Studium\\Semester_6\\IoT_Project\\utils.py:1036: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_train[columns_to_scale] = scaler.fit_transform(df_train[columns_to_scale])\n",
      "c:\\Studium\\Semester_6\\IoT_Project\\utils.py:1037: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_test[columns_to_scale] = scaler.transform(df_test[columns_to_scale])\n",
      "c:\\Studium\\Semester_6\\IoT_Project\\utils.py:1041: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_train.drop(['date_time_rounded'], axis=1, inplace=True)\n",
      "c:\\Studium\\Semester_6\\IoT_Project\\utils.py:1042: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_test.drop(['date_time_rounded'], axis=1, inplace=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data shape: torch.Size([75940, 20, 22]) torch.Size([75940]) torch.Size([75940, 1])\n",
      "Testing data shape: torch.Size([19215, 20, 22]) torch.Size([19215]) torch.Size([19215, 1])\n",
      "Shuffled Training data shape: torch.Size([76124, 20, 22]) torch.Size([76124]) torch.Size([76124, 1])\n",
      "Shuffled Testing data shape: torch.Size([19031, 20, 22]) torch.Size([19031]) torch.Size([19031, 1])\n",
      "23\n",
      "same columns\n",
      "same dtypes\n",
      "0  rows differ from the last saved dataframe.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\t-ehm\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\transformer.py:286: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
      "c:\\Users\\t-ehm\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\optim\\lr_scheduler.py:28: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\"The verbose parameter is deprecated. Please use get_last_lr() \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       actual  predicted\n",
      "0     20.9800  19.167246\n",
      "1     22.5550  21.880145\n",
      "2     25.0625  23.496031\n",
      "3     24.0300  22.922681\n",
      "4     24.4900  23.606272\n",
      "...       ...        ...\n",
      "1019  17.7800  16.550979\n",
      "1020  21.8975  21.426585\n",
      "1021  23.6475  22.984317\n",
      "1022  27.2100  27.288162\n",
      "1023  18.0500  17.008572\n",
      "\n",
      "[1024 rows x 2 columns]\n",
      "Epoch 1/25, Training Loss: 0.2429\n",
      "Epoch 1/25, Validation Loss: 0.0546\n",
      "       actual  predicted\n",
      "0     20.9800  19.416553\n",
      "1     22.5550  21.587298\n",
      "2     25.0625  23.825068\n",
      "3     24.0300  23.411993\n",
      "4     24.4900  23.712931\n",
      "...       ...        ...\n",
      "1019  17.7800  16.579913\n",
      "1020  21.8975  21.158214\n",
      "1021  23.6475  22.850766\n",
      "1022  27.2100  27.153544\n",
      "1023  18.0500  17.267724\n",
      "\n",
      "[1024 rows x 2 columns]\n",
      "Epoch 2/25, Training Loss: 0.0633\n",
      "Epoch 2/25, Validation Loss: 0.0324\n",
      "       actual  predicted\n",
      "0     20.9800  19.908029\n",
      "1     22.5550  22.290795\n",
      "2     25.0625  23.963142\n",
      "3     24.0300  23.487138\n",
      "4     24.4900  23.852477\n",
      "...       ...        ...\n",
      "1019  17.7800  17.289403\n",
      "1020  21.8975  21.655109\n",
      "1021  23.6475  23.194495\n",
      "1022  27.2100  27.619043\n",
      "1023  18.0500  17.962021\n",
      "\n",
      "[1024 rows x 2 columns]\n",
      "Epoch 3/25, Training Loss: 0.0513\n",
      "Epoch 3/25, Validation Loss: 0.0544\n",
      "       actual  predicted\n",
      "0     20.9800  20.920344\n",
      "1     22.5550  22.638605\n",
      "2     25.0625  23.851677\n",
      "3     24.0300  23.338510\n",
      "4     24.4900  23.648827\n",
      "...       ...        ...\n",
      "1019  17.7800  18.098493\n",
      "1020  21.8975  21.900058\n",
      "1021  23.6475  23.181447\n",
      "1022  27.2100  27.293513\n",
      "1023  18.0500  18.644347\n",
      "\n",
      "[1024 rows x 2 columns]\n",
      "Epoch 4/25, Training Loss: 0.0453\n",
      "Epoch 4/25, Validation Loss: 0.0249\n",
      "       actual  predicted\n",
      "0     20.9800  20.032326\n",
      "1     22.5550  22.146006\n",
      "2     25.0625  24.138777\n",
      "3     24.0300  23.568960\n",
      "4     24.4900  23.816633\n",
      "...       ...        ...\n",
      "1019  17.7800  16.462598\n",
      "1020  21.8975  20.905193\n",
      "1021  23.6475  22.590871\n",
      "1022  27.2100  27.015229\n",
      "1023  18.0500  17.052786\n",
      "\n",
      "[1024 rows x 2 columns]\n",
      "Epoch 5/25, Training Loss: 0.0420\n",
      "Epoch 5/25, Validation Loss: 0.0310\n",
      "       actual  predicted\n",
      "0     20.9800  21.010301\n",
      "1     22.5550  22.642248\n",
      "2     25.0625  24.276836\n",
      "3     24.0300  23.808028\n",
      "4     24.4900  24.069324\n",
      "...       ...        ...\n",
      "1019  17.7800  17.046617\n",
      "1020  21.8975  21.898082\n",
      "1021  23.6475  23.221147\n",
      "1022  27.2100  27.076711\n",
      "1023  18.0500  17.298036\n",
      "\n",
      "[1024 rows x 2 columns]\n",
      "Epoch 6/25, Training Loss: 0.0388\n",
      "Epoch 6/25, Validation Loss: 0.0239\n",
      "       actual  predicted\n",
      "0     20.9800  20.459353\n",
      "1     22.5550  22.573966\n",
      "2     25.0625  24.228678\n",
      "3     24.0300  23.679919\n",
      "4     24.4900  24.016595\n",
      "...       ...        ...\n",
      "1019  17.7800  16.146002\n",
      "1020  21.8975  21.373669\n",
      "1021  23.6475  23.296389\n",
      "1022  27.2100  27.618050\n",
      "1023  18.0500  16.498930\n",
      "\n",
      "[1024 rows x 2 columns]\n",
      "Epoch 7/25, Training Loss: 0.0354\n",
      "Epoch 7/25, Validation Loss: 0.0565\n",
      "       actual  predicted\n",
      "0     20.9800  20.769810\n",
      "1     22.5550  22.519395\n",
      "2     25.0625  24.366957\n",
      "3     24.0300  23.899685\n",
      "4     24.4900  24.059703\n",
      "...       ...        ...\n",
      "1019  17.7800  17.521816\n",
      "1020  21.8975  21.445903\n",
      "1021  23.6475  22.980053\n",
      "1022  27.2100  27.312343\n",
      "1023  18.0500  17.861820\n",
      "\n",
      "[1024 rows x 2 columns]\n",
      "Epoch 8/25, Training Loss: 0.0336\n",
      "Epoch 8/25, Validation Loss: 0.0224\n",
      "       actual  predicted\n",
      "0     20.9800  20.380702\n",
      "1     22.5550  22.080080\n",
      "2     25.0625  24.151596\n",
      "3     24.0300  23.497831\n",
      "4     24.4900  23.855012\n",
      "...       ...        ...\n",
      "1019  17.7800  17.008380\n",
      "1020  21.8975  21.189794\n",
      "1021  23.6475  22.929815\n",
      "1022  27.2100  26.853564\n",
      "1023  18.0500  17.463155\n",
      "\n",
      "[1024 rows x 2 columns]\n",
      "Epoch 9/25, Training Loss: 0.0312\n",
      "Epoch 9/25, Validation Loss: 0.0256\n",
      "       actual  predicted\n",
      "0     20.9800  21.322220\n",
      "1     22.5550  22.866237\n",
      "2     25.0625  24.529450\n",
      "3     24.0300  24.008770\n",
      "4     24.4900  24.231904\n",
      "...       ...        ...\n",
      "1019  17.7800  18.231106\n",
      "1020  21.8975  22.097359\n",
      "1021  23.6475  23.514231\n",
      "1022  27.2100  27.783270\n",
      "1023  18.0500  18.712326\n",
      "\n",
      "[1024 rows x 2 columns]\n",
      "Epoch 10/25, Training Loss: 0.0313\n",
      "Epoch 10/25, Validation Loss: 0.0254\n",
      "       actual  predicted\n",
      "0     20.9800  20.609687\n",
      "1     22.5550  22.461508\n",
      "2     25.0625  24.379765\n",
      "3     24.0300  23.756702\n",
      "4     24.4900  23.987078\n",
      "...       ...        ...\n",
      "1019  17.7800  17.613649\n",
      "1020  21.8975  21.672499\n",
      "1021  23.6475  23.090565\n",
      "1022  27.2100  27.457384\n",
      "1023  18.0500  17.819237\n",
      "\n",
      "[1024 rows x 2 columns]\n",
      "Epoch 11/25, Training Loss: 0.0292\n",
      "Epoch 11/25, Validation Loss: 0.0296\n",
      "       actual  predicted\n",
      "0     20.9800  20.721180\n",
      "1     22.5550  22.319381\n",
      "2     25.0625  24.399155\n",
      "3     24.0300  23.727234\n",
      "4     24.4900  24.024858\n",
      "...       ...        ...\n",
      "1019  17.7800  16.709737\n",
      "1020  21.8975  21.557371\n",
      "1021  23.6475  23.123479\n",
      "1022  27.2100  27.407321\n",
      "1023  18.0500  16.920805\n",
      "\n",
      "[1024 rows x 2 columns]\n",
      "Epoch 12/25, Training Loss: 0.0269\n",
      "Epoch 12/25, Validation Loss: 0.0238\n",
      "       actual  predicted\n",
      "0     20.9800  20.950222\n",
      "1     22.5550  22.473192\n",
      "2     25.0625  24.489723\n",
      "3     24.0300  23.849800\n",
      "4     24.4900  24.068830\n",
      "...       ...        ...\n",
      "1019  17.7800  17.596029\n",
      "1020  21.8975  21.699160\n",
      "1021  23.6475  23.237435\n",
      "1022  27.2100  27.253384\n",
      "1023  18.0500  17.848244\n",
      "\n",
      "[1024 rows x 2 columns]\n",
      "Epoch 13/25, Training Loss: 0.0253\n",
      "Epoch 13/25, Validation Loss: 0.0133\n",
      "       actual  predicted\n",
      "0     20.9800  21.043026\n",
      "1     22.5550  22.604069\n",
      "2     25.0625  24.671222\n",
      "3     24.0300  23.993329\n",
      "4     24.4900  24.181388\n",
      "...       ...        ...\n",
      "1019  17.7800  16.972287\n",
      "1020  21.8975  21.724486\n",
      "1021  23.6475  23.287288\n",
      "1022  27.2100  27.656739\n",
      "1023  18.0500  17.334324\n",
      "\n",
      "[1024 rows x 2 columns]\n",
      "Epoch 14/25, Training Loss: 0.0243\n",
      "Epoch 14/25, Validation Loss: 0.0212\n",
      "       actual  predicted\n",
      "0     20.9800  20.810019\n",
      "1     22.5550  22.524074\n",
      "2     25.0625  24.610886\n",
      "3     24.0300  23.939654\n",
      "4     24.4900  24.149171\n",
      "...       ...        ...\n",
      "1019  17.7800  16.947584\n",
      "1020  21.8975  21.621169\n",
      "1021  23.6475  23.227590\n",
      "1022  27.2100  27.615101\n",
      "1023  18.0500  17.213794\n",
      "\n",
      "[1024 rows x 2 columns]\n",
      "Epoch 15/25, Training Loss: 0.0245\n",
      "Epoch 15/25, Validation Loss: 0.0257\n",
      "       actual  predicted\n",
      "0     20.9800  20.716831\n",
      "1     22.5550  22.382860\n",
      "2     25.0625  24.379957\n",
      "3     24.0300  23.667724\n",
      "4     24.4900  23.960146\n",
      "...       ...        ...\n",
      "1019  17.7800  17.614951\n",
      "1020  21.8975  21.527044\n",
      "1021  23.6475  23.105082\n",
      "1022  27.2100  27.477671\n",
      "1023  18.0500  17.943492\n",
      "\n",
      "[1024 rows x 2 columns]\n",
      "Epoch 16/25, Training Loss: 0.0235\n",
      "Epoch 16/25, Validation Loss: 0.0209\n",
      "       actual  predicted\n",
      "0     20.9800  21.037761\n",
      "1     22.5550  22.597055\n",
      "2     25.0625  24.560654\n",
      "3     24.0300  23.913772\n",
      "4     24.4900  24.146592\n",
      "...       ...        ...\n",
      "1019  17.7800  17.594888\n",
      "1020  21.8975  21.834044\n",
      "1021  23.6475  23.228310\n",
      "1022  27.2100  27.441207\n",
      "1023  18.0500  18.076602\n",
      "\n",
      "[1024 rows x 2 columns]\n",
      "Epoch 17/25, Training Loss: 0.0231\n",
      "Epoch 17/25, Validation Loss: 0.0199\n",
      "       actual  predicted\n",
      "0     20.9800  20.946189\n",
      "1     22.5550  22.527096\n",
      "2     25.0625  24.471971\n",
      "3     24.0300  23.800755\n",
      "4     24.4900  24.085577\n",
      "...       ...        ...\n",
      "1019  17.7800  17.721266\n",
      "1020  21.8975  21.715921\n",
      "1021  23.6475  23.227725\n",
      "1022  27.2100  27.377042\n",
      "1023  18.0500  18.046412\n",
      "\n",
      "[1024 rows x 2 columns]\n",
      "Early stopping!\n",
      "          actual  predicted\n",
      "0      20.980000  20.946189\n",
      "1      22.555000  22.527096\n",
      "2      25.062500  24.471971\n",
      "3      24.030000  23.800755\n",
      "4      24.490000  24.085577\n",
      "...          ...        ...\n",
      "19026  23.965000  23.802901\n",
      "19027  26.611250  26.297872\n",
      "19028  24.810000  24.553956\n",
      "19029  28.582500  28.527337\n",
      "19030  31.163333  31.722892\n",
      "\n",
      "[19031 rows x 2 columns]\n",
      "Score (RMSE): 0.4254\n",
      "Score (MAE): 0.2554\n",
      "Score (ME): -0.0503\n",
      "Score (MAPE): 1.0328%\n",
      "training data cutoff:  2023-07-14 05:00:00\n",
      "device_id              int8\n",
      "tmp                 float64\n",
      "hum                 float64\n",
      "CO2                 float64\n",
      "VOC                 float64\n",
      "vis                 float64\n",
      "IR                  float64\n",
      "WIFI                float64\n",
      "BLE                 float64\n",
      "rssi                float64\n",
      "channel_rssi        float64\n",
      "channel_index       float64\n",
      "spreading_factor    float64\n",
      "bandwidth           float64\n",
      "f_cnt               float64\n",
      "isHoliday           float64\n",
      "isExamTime          float64\n",
      "weekday             float64\n",
      "month               float64\n",
      "hour_sin            float64\n",
      "semester_SS23       float64\n",
      "semester_WS22/23    float64\n",
      "semester_WS23/24    float64\n",
      "group                 int32\n",
      "dtype: object\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Studium\\Semester_6\\IoT_Project\\utils.py:1036: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_train[columns_to_scale] = scaler.fit_transform(df_train[columns_to_scale])\n",
      "c:\\Studium\\Semester_6\\IoT_Project\\utils.py:1037: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_test[columns_to_scale] = scaler.transform(df_test[columns_to_scale])\n",
      "c:\\Studium\\Semester_6\\IoT_Project\\utils.py:1041: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_train.drop(['date_time_rounded'], axis=1, inplace=True)\n",
      "c:\\Studium\\Semester_6\\IoT_Project\\utils.py:1042: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_test.drop(['date_time_rounded'], axis=1, inplace=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data shape: torch.Size([75940, 20, 22]) torch.Size([75940]) torch.Size([75940, 1])\n",
      "Testing data shape: torch.Size([19215, 20, 22]) torch.Size([19215]) torch.Size([19215, 1])\n",
      "Shuffled Training data shape: torch.Size([76124, 20, 22]) torch.Size([76124]) torch.Size([76124, 1])\n",
      "Shuffled Testing data shape: torch.Size([19031, 20, 22]) torch.Size([19031]) torch.Size([19031, 1])\n",
      "23\n",
      "same columns\n",
      "same dtypes\n",
      "0  rows differ from the last saved dataframe.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\t-ehm\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\transformer.py:286: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
      "c:\\Users\\t-ehm\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\optim\\lr_scheduler.py:28: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\"The verbose parameter is deprecated. Please use get_last_lr() \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          actual   predicted\n",
      "0       5.499997  252.377539\n",
      "1     218.250000  275.077255\n",
      "2     283.124996  404.700862\n",
      "3       7.333340   41.998723\n",
      "4      37.749993   95.893761\n",
      "...          ...         ...\n",
      "1019   45.749995   72.671586\n",
      "1020   30.249998   91.291315\n",
      "1021    5.499997   96.258704\n",
      "1022    4.499999  100.029531\n",
      "1023  129.250002   76.347963\n",
      "\n",
      "[1024 rows x 2 columns]\n",
      "Epoch 1/25, Training Loss: 0.8585\n",
      "Epoch 1/25, Validation Loss: 0.6413\n",
      "          actual   predicted\n",
      "0       5.499997  668.951393\n",
      "1     218.250000  834.289689\n",
      "2     283.124996  698.404814\n",
      "3       7.333340   26.084571\n",
      "4      37.749993  237.022261\n",
      "...          ...         ...\n",
      "1019   45.749995  164.030240\n",
      "1020   30.249998  400.322214\n",
      "1021    5.499997  348.923617\n",
      "1022    4.499999  441.728746\n",
      "1023  129.250002  219.181549\n",
      "\n",
      "[1024 rows x 2 columns]\n",
      "Epoch 2/25, Training Loss: 0.7065\n",
      "Epoch 2/25, Validation Loss: 0.6484\n",
      "          actual   predicted\n",
      "0       5.499997   81.021378\n",
      "1     218.250000  133.212880\n",
      "2     283.124996  104.172125\n",
      "3       7.333340   26.610276\n",
      "4      37.749993   61.814634\n",
      "...          ...         ...\n",
      "1019   45.749995   86.602779\n",
      "1020   30.249998  137.557722\n",
      "1021    5.499997  140.870633\n",
      "1022    4.499999  267.581028\n",
      "1023  129.250002  112.433563\n",
      "\n",
      "[1024 rows x 2 columns]\n",
      "Epoch 3/25, Training Loss: 0.6968\n",
      "Epoch 3/25, Validation Loss: 0.6657\n",
      "          actual   predicted\n",
      "0       5.499997  102.141759\n",
      "1     218.250000  246.662665\n",
      "2     283.124996  137.432539\n",
      "3       7.333340   10.666467\n",
      "4      37.749993   24.497035\n",
      "...          ...         ...\n",
      "1019   45.749995   16.567178\n",
      "1020   30.249998   64.625063\n",
      "1021    5.499997   93.420533\n",
      "1022    4.499999  113.260211\n",
      "1023  129.250002   68.703023\n",
      "\n",
      "[1024 rows x 2 columns]\n",
      "Epoch 4/25, Training Loss: 0.7078\n",
      "Epoch 4/25, Validation Loss: 0.6147\n",
      "          actual   predicted\n",
      "0       5.499997  132.086225\n",
      "1     218.250000  352.932920\n",
      "2     283.124996  119.995865\n",
      "3       7.333340   67.911005\n",
      "4      37.749993   75.277250\n",
      "...          ...         ...\n",
      "1019   45.749995   78.889832\n",
      "1020   30.249998  110.570119\n",
      "1021    5.499997  115.083895\n",
      "1022    4.499999  143.542238\n",
      "1023  129.250002   96.874885\n",
      "\n",
      "[1024 rows x 2 columns]\n",
      "Epoch 5/25, Training Loss: 0.6734\n",
      "Epoch 5/25, Validation Loss: 0.6185\n",
      "          actual   predicted\n",
      "0       5.499997   53.516303\n",
      "1     218.250000  327.190949\n",
      "2     283.124996   54.333164\n",
      "3       7.333340  -10.453313\n",
      "4      37.749993   11.636175\n",
      "...          ...         ...\n",
      "1019   45.749995   18.556280\n",
      "1020   30.249998   51.387274\n",
      "1021    5.499997  120.237888\n",
      "1022    4.499999  139.397498\n",
      "1023  129.250002   73.469289\n",
      "\n",
      "[1024 rows x 2 columns]\n",
      "Epoch 6/25, Training Loss: 0.6929\n",
      "Epoch 6/25, Validation Loss: 0.6117\n",
      "          actual   predicted\n",
      "0       5.499997   63.791006\n",
      "1     218.250000  178.264786\n",
      "2     283.124996   87.020916\n",
      "3       7.333340   19.481653\n",
      "4      37.749993   22.987276\n",
      "...          ...         ...\n",
      "1019   45.749995   26.578498\n",
      "1020   30.249998   41.725649\n",
      "1021    5.499997   72.789320\n",
      "1022    4.499999   75.506155\n",
      "1023  129.250002   65.869317\n",
      "\n",
      "[1024 rows x 2 columns]\n",
      "Epoch 7/25, Training Loss: 0.6666\n",
      "Epoch 7/25, Validation Loss: 0.6272\n",
      "          actual   predicted\n",
      "0       5.499997   87.422934\n",
      "1     218.250000  119.731397\n",
      "2     283.124996  102.575881\n",
      "3       7.333340   50.785660\n",
      "4      37.749993   65.458203\n",
      "...          ...         ...\n",
      "1019   45.749995   59.776192\n",
      "1020   30.249998   71.396772\n",
      "1021    5.499997   69.967339\n",
      "1022    4.499999   81.643766\n",
      "1023  129.250002   79.540785\n",
      "\n",
      "[1024 rows x 2 columns]\n",
      "Epoch 8/25, Training Loss: 0.6687\n",
      "Epoch 8/25, Validation Loss: 0.6069\n",
      "          actual   predicted\n",
      "0       5.499997  133.723345\n",
      "1     218.250000  156.899475\n",
      "2     283.124996  139.634332\n",
      "3       7.333340  113.699367\n",
      "4      37.749993  116.728030\n",
      "...          ...         ...\n",
      "1019   45.749995  115.764711\n",
      "1020   30.249998  117.876528\n",
      "1021    5.499997  117.571137\n",
      "1022    4.499999  118.439491\n",
      "1023  129.250002  118.797253\n",
      "\n",
      "[1024 rows x 2 columns]\n",
      "Epoch 9/25, Training Loss: 0.7204\n",
      "Epoch 9/25, Validation Loss: 0.6490\n",
      "          actual   predicted\n",
      "0       5.499997  139.910378\n",
      "1     218.250000  160.618244\n",
      "2     283.124996  143.868601\n",
      "3       7.333340  104.129706\n",
      "4      37.749993  118.902367\n",
      "...          ...         ...\n",
      "1019   45.749995  118.185576\n",
      "1020   30.249998  129.042687\n",
      "1021    5.499997  127.179037\n",
      "1022    4.499999  136.350377\n",
      "1023  129.250002  128.083319\n",
      "\n",
      "[1024 rows x 2 columns]\n",
      "Epoch 10/25, Training Loss: 0.7137\n",
      "Epoch 10/25, Validation Loss: 0.6853\n",
      "          actual   predicted\n",
      "0       5.499997   69.975399\n",
      "1     218.250000  104.397792\n",
      "2     283.124996   79.060808\n",
      "3       7.333340   38.706163\n",
      "4      37.749993   47.174440\n",
      "...          ...         ...\n",
      "1019   45.749995   46.516520\n",
      "1020   30.249998   51.482706\n",
      "1021    5.499997   48.300762\n",
      "1022    4.499999   54.553147\n",
      "1023  129.250002   50.072638\n",
      "\n",
      "[1024 rows x 2 columns]\n",
      "Epoch 11/25, Training Loss: 0.6788\n",
      "Epoch 11/25, Validation Loss: 0.5882\n",
      "          actual   predicted\n",
      "0       5.499997  101.562693\n",
      "1     218.250000  370.638455\n",
      "2     283.124996  100.051050\n",
      "3       7.333340   12.311781\n",
      "4      37.749993   16.819952\n",
      "...          ...         ...\n",
      "1019   45.749995   23.363936\n",
      "1020   30.249998   41.341769\n",
      "1021    5.499997   38.434973\n",
      "1022    4.499999   67.173487\n",
      "1023  129.250002   37.583055\n",
      "\n",
      "[1024 rows x 2 columns]\n",
      "Epoch 12/25, Training Loss: 0.6491\n",
      "Epoch 12/25, Validation Loss: 0.5987\n",
      "          actual  predicted\n",
      "0       5.499997  53.483558\n",
      "1     218.250000  85.929294\n",
      "2     283.124996  61.714610\n",
      "3       7.333340  20.945636\n",
      "4      37.749993  14.492745\n",
      "...          ...        ...\n",
      "1019   45.749995  14.942479\n",
      "1020   30.249998  22.412849\n",
      "1021    5.499997  37.319925\n",
      "1022    4.499999  32.508770\n",
      "1023  129.250002  44.033792\n",
      "\n",
      "[1024 rows x 2 columns]\n",
      "Epoch 13/25, Training Loss: 0.6303\n",
      "Epoch 13/25, Validation Loss: 0.5849\n",
      "          actual   predicted\n",
      "0       5.499997  181.195154\n",
      "1     218.250000  779.420842\n",
      "2     283.124996  300.981287\n",
      "3       7.333340   25.990691\n",
      "4      37.749993   53.294927\n",
      "...          ...         ...\n",
      "1019   45.749995   31.615873\n",
      "1020   30.249998   83.905895\n",
      "1021    5.499997  101.007615\n",
      "1022    4.499999  128.683017\n",
      "1023  129.250002  114.942877\n",
      "\n",
      "[1024 rows x 2 columns]\n",
      "Epoch 14/25, Training Loss: 0.6371\n",
      "Epoch 14/25, Validation Loss: 0.5894\n",
      "          actual   predicted\n",
      "0       5.499997  135.812195\n",
      "1     218.250000  524.573524\n",
      "2     283.124996  179.013454\n",
      "3       7.333340   76.630094\n",
      "4      37.749993   81.898947\n",
      "...          ...         ...\n",
      "1019   45.749995   77.102851\n",
      "1020   30.249998   92.886182\n",
      "1021    5.499997  101.585652\n",
      "1022    4.499999  131.139018\n",
      "1023  129.250002  100.421883\n",
      "\n",
      "[1024 rows x 2 columns]\n",
      "Epoch 15/25, Training Loss: 0.6078\n",
      "Epoch 15/25, Validation Loss: 0.5741\n",
      "          actual   predicted\n",
      "0       5.499997  151.516403\n",
      "1     218.250000  168.394539\n",
      "2     283.124996  158.777320\n",
      "3       7.333340  141.725944\n",
      "4      37.749993  141.007570\n",
      "...          ...         ...\n",
      "1019   45.749995  144.493028\n",
      "1020   30.249998  146.442863\n",
      "1021    5.499997  146.508598\n",
      "1022    4.499999  149.721956\n",
      "1023  129.250002  147.306015\n",
      "\n",
      "[1024 rows x 2 columns]\n",
      "Epoch 16/25, Training Loss: 0.6318\n",
      "Epoch 16/25, Validation Loss: 0.6166\n",
      "          actual   predicted\n",
      "0       5.499997   81.671760\n",
      "1     218.250000  291.702854\n",
      "2     283.124996  108.378943\n",
      "3       7.333340   26.474040\n",
      "4      37.749993   11.463252\n",
      "...          ...         ...\n",
      "1019   45.749995   28.427596\n",
      "1020   30.249998   34.952088\n",
      "1021    5.499997   66.855318\n",
      "1022    4.499999   56.232330\n",
      "1023  129.250002   78.986087\n",
      "\n",
      "[1024 rows x 2 columns]\n",
      "Epoch 17/25, Training Loss: 0.6279\n",
      "Epoch 17/25, Validation Loss: 0.6198\n",
      "          actual   predicted\n",
      "0       5.499997   70.729035\n",
      "1     218.250000  241.167884\n",
      "2     283.124996  118.692978\n",
      "3       7.333340   37.007218\n",
      "4      37.749993   34.655310\n",
      "...          ...         ...\n",
      "1019   45.749995   34.814189\n",
      "1020   30.249998   40.286826\n",
      "1021    5.499997   51.111366\n",
      "1022    4.499999   58.181262\n",
      "1023  129.250002   51.509624\n",
      "\n",
      "[1024 rows x 2 columns]\n",
      "Epoch 18/25, Training Loss: 0.5764\n",
      "Epoch 18/25, Validation Loss: 0.6374\n",
      "          actual   predicted\n",
      "0       5.499997  109.121749\n",
      "1     218.250000  280.453851\n",
      "2     283.124996  154.791811\n",
      "3       7.333340   76.279038\n",
      "4      37.749993   73.100324\n",
      "...          ...         ...\n",
      "1019   45.749995   75.138449\n",
      "1020   30.249998   83.533178\n",
      "1021    5.499997  102.352336\n",
      "1022    4.499999  110.644270\n",
      "1023  129.250002  106.191329\n",
      "\n",
      "[1024 rows x 2 columns]\n",
      "Epoch 19/25, Training Loss: 0.6150\n",
      "Epoch 19/25, Validation Loss: 0.5948\n",
      "          actual   predicted\n",
      "0       5.499997   57.468429\n",
      "1     218.250000  249.108227\n",
      "2     283.124996  117.130475\n",
      "3       7.333340   15.001698\n",
      "4      37.749993   11.349310\n",
      "...          ...         ...\n",
      "1019   45.749995    8.711503\n",
      "1020   30.249998   17.033189\n",
      "1021    5.499997   34.094659\n",
      "1022    4.499999   45.146037\n",
      "1023  129.250002   56.861115\n",
      "\n",
      "[1024 rows x 2 columns]\n",
      "Epoch 20/25, Training Loss: 0.5894\n",
      "Epoch 20/25, Validation Loss: 0.5618\n",
      "          actual   predicted\n",
      "0       5.499997  134.884637\n",
      "1     218.250000  640.392310\n",
      "2     283.124996  271.519585\n",
      "3       7.333340   64.499151\n",
      "4      37.749993   51.346201\n",
      "...          ...         ...\n",
      "1019   45.749995   49.786866\n",
      "1020   30.249998   66.636682\n",
      "1021    5.499997   78.478179\n",
      "1022    4.499999   98.578310\n",
      "1023  129.250002   87.931412\n",
      "\n",
      "[1024 rows x 2 columns]\n",
      "Epoch 21/25, Training Loss: 0.5879\n",
      "Epoch 21/25, Validation Loss: 0.5713\n",
      "          actual   predicted\n",
      "0       5.499997   17.898978\n",
      "1     218.250000  119.510742\n",
      "2     283.124996   38.347617\n",
      "3       7.333340    1.806376\n",
      "4      37.749993   -3.380916\n",
      "...          ...         ...\n",
      "1019   45.749995   -0.768443\n",
      "1020   30.249998    3.852672\n",
      "1021    5.499997   11.560393\n",
      "1022    4.499999   15.252383\n",
      "1023  129.250002   14.730525\n",
      "\n",
      "[1024 rows x 2 columns]\n",
      "Epoch 22/25, Training Loss: 0.5665\n",
      "Epoch 22/25, Validation Loss: 0.5762\n",
      "          actual   predicted\n",
      "0       5.499997   48.292893\n",
      "1     218.250000  123.909119\n",
      "2     283.124996   70.858748\n",
      "3       7.333340   34.145360\n",
      "4      37.749993   30.065341\n",
      "...          ...         ...\n",
      "1019   45.749995   30.076203\n",
      "1020   30.249998   33.354576\n",
      "1021    5.499997   39.793327\n",
      "1022    4.499999   43.570615\n",
      "1023  129.250002   41.932727\n",
      "\n",
      "[1024 rows x 2 columns]\n",
      "Epoch 23/25, Training Loss: 0.5434\n",
      "Epoch 23/25, Validation Loss: 0.5943\n",
      "          actual   predicted\n",
      "0       5.499997   33.888357\n",
      "1     218.250000  145.838743\n",
      "2     283.124996   67.812660\n",
      "3       7.333340   14.808333\n",
      "4      37.749993   11.300874\n",
      "...          ...         ...\n",
      "1019   45.749995   11.218473\n",
      "1020   30.249998   16.124173\n",
      "1021    5.499997   23.981906\n",
      "1022    4.499999   30.897182\n",
      "1023  129.250002   30.170083\n",
      "\n",
      "[1024 rows x 2 columns]\n",
      "Epoch 24/25, Training Loss: 0.5792\n",
      "Epoch 24/25, Validation Loss: 0.5764\n",
      "          actual   predicted\n",
      "0       5.499997   94.007532\n",
      "1     218.250000  425.091311\n",
      "2     283.124996  194.043937\n",
      "3       7.333340   27.951720\n",
      "4      37.749993   21.683169\n",
      "...          ...         ...\n",
      "1019   45.749995   20.260624\n",
      "1020   30.249998   30.687492\n",
      "1021    5.499997   48.216620\n",
      "1022    4.499999   73.068118\n",
      "1023  129.250002   51.795555\n",
      "\n",
      "[1024 rows x 2 columns]\n",
      "Epoch 25/25, Training Loss: 0.5680\n",
      "Epoch 25/25, Validation Loss: 0.5494\n",
      "           actual   predicted\n",
      "0        5.499997   94.007532\n",
      "1      218.250000  425.091311\n",
      "2      283.124996  194.043937\n",
      "3        7.333340   27.951720\n",
      "4       37.749993   21.683169\n",
      "...           ...         ...\n",
      "19026   13.249995   42.953752\n",
      "19027    4.000007   27.867720\n",
      "19028    6.499995  121.345328\n",
      "19029  557.999989  259.930076\n",
      "19030  124.250002   47.619931\n",
      "\n",
      "[19031 rows x 2 columns]\n",
      "Score (RMSE): 794.5031\n",
      "Score (MAE): 121.6689\n",
      "Score (ME): 15.2326\n",
      "Score (MAPE): 384137.3972%\n",
      "training data cutoff:  2023-07-14 07:30:00\n",
      "device_id              int8\n",
      "tmp                 float64\n",
      "hum                 float64\n",
      "CO2                 float64\n",
      "VOC                 float64\n",
      "vis                 float64\n",
      "IR                  float64\n",
      "WIFI                float64\n",
      "BLE                 float64\n",
      "rssi                float64\n",
      "channel_rssi        float64\n",
      "channel_index       float64\n",
      "spreading_factor    float64\n",
      "bandwidth           float64\n",
      "f_cnt               float64\n",
      "isHoliday           float64\n",
      "isExamTime          float64\n",
      "weekday             float64\n",
      "month               float64\n",
      "hour_sin            float64\n",
      "semester_SS23       float64\n",
      "semester_WS22/23    float64\n",
      "semester_WS23/24    float64\n",
      "group                 int32\n",
      "dtype: object\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Studium\\Semester_6\\IoT_Project\\utils.py:1036: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_train[columns_to_scale] = scaler.fit_transform(df_train[columns_to_scale])\n",
      "c:\\Studium\\Semester_6\\IoT_Project\\utils.py:1037: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_test[columns_to_scale] = scaler.transform(df_test[columns_to_scale])\n",
      "c:\\Studium\\Semester_6\\IoT_Project\\utils.py:1041: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_train.drop(['date_time_rounded'], axis=1, inplace=True)\n",
      "c:\\Studium\\Semester_6\\IoT_Project\\utils.py:1042: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_test.drop(['date_time_rounded'], axis=1, inplace=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data shape: torch.Size([152512, 20, 22]) torch.Size([152512]) torch.Size([152512, 1])\n",
      "Testing data shape: torch.Size([38893, 20, 22]) torch.Size([38893]) torch.Size([38893, 1])\n",
      "Shuffled Training data shape: torch.Size([153124, 20, 22]) torch.Size([153124]) torch.Size([153124, 1])\n",
      "Shuffled Testing data shape: torch.Size([38281, 20, 22]) torch.Size([38281]) torch.Size([38281, 1])\n",
      "23\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\t-ehm\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\transformer.py:286: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
      "c:\\Users\\t-ehm\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\optim\\lr_scheduler.py:28: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\"The verbose parameter is deprecated. Please use get_last_lr() \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           actual    predicted\n",
      "0      500.000000   482.028006\n",
      "1      446.000001   418.528078\n",
      "2      554.500002   554.296513\n",
      "3      544.000002   560.509294\n",
      "4     1438.249999  1414.383774\n",
      "...           ...          ...\n",
      "1019   409.999996   408.464830\n",
      "1020   419.500001   412.822871\n",
      "1021   403.999996   411.939183\n",
      "1022   458.666666   436.479332\n",
      "1023   379.500000   401.357136\n",
      "\n",
      "[1024 rows x 2 columns]\n",
      "Epoch 1/25, Training Loss: 0.3872\n",
      "Epoch 1/25, Validation Loss: 0.1963\n",
      "           actual    predicted\n",
      "0      500.000000   486.811213\n",
      "1      446.000001   435.807489\n",
      "2      554.500002   553.677169\n",
      "3      544.000002   548.962401\n",
      "4     1438.249999  1330.488468\n",
      "...           ...          ...\n",
      "1019   409.999996   429.622614\n",
      "1020   419.500001   432.868699\n",
      "1021   403.999996   433.799065\n",
      "1022   458.666666   450.664642\n",
      "1023   379.500000   421.293568\n",
      "\n",
      "[1024 rows x 2 columns]\n",
      "Epoch 2/25, Training Loss: 0.2216\n",
      "Epoch 2/25, Validation Loss: 0.1827\n",
      "           actual    predicted\n",
      "0      500.000000   497.663784\n",
      "1      446.000001   431.293568\n",
      "2      554.500002   561.707943\n",
      "3      544.000002   561.206085\n",
      "4     1438.249999  1551.944593\n",
      "...           ...          ...\n",
      "1019   409.999996   414.866618\n",
      "1020   419.500001   421.080830\n",
      "1021   403.999996   418.256123\n",
      "1022   458.666666   444.210469\n",
      "1023   379.500000   402.050170\n",
      "\n",
      "[1024 rows x 2 columns]\n",
      "Epoch 3/25, Training Loss: 0.2000\n",
      "Epoch 3/25, Validation Loss: 0.1769\n",
      "           actual    predicted\n",
      "0      500.000000   479.254180\n",
      "1      446.000001   432.376701\n",
      "2      554.500002   536.251672\n",
      "3      544.000002   536.189296\n",
      "4     1438.249999  1300.212376\n",
      "...           ...          ...\n",
      "1019   409.999996   421.343270\n",
      "1020   419.500001   423.251658\n",
      "1021   403.999996   424.666259\n",
      "1022   458.666666   440.448479\n",
      "1023   379.500000   409.953807\n",
      "\n",
      "[1024 rows x 2 columns]\n",
      "Epoch 4/25, Training Loss: 0.1876\n",
      "Epoch 4/25, Validation Loss: 0.1848\n",
      "           actual    predicted\n",
      "0      500.000000   487.961358\n",
      "1      446.000001   426.186776\n",
      "2      554.500002   581.683176\n",
      "3      544.000002   578.119250\n",
      "4     1438.249999  1384.714487\n",
      "...           ...          ...\n",
      "1019   409.999996   412.130208\n",
      "1020   419.500001   416.715565\n",
      "1021   403.999996   416.680268\n",
      "1022   458.666666   443.476380\n",
      "1023   379.500000   398.161057\n",
      "\n",
      "[1024 rows x 2 columns]\n",
      "Epoch 5/25, Training Loss: 0.1826\n",
      "Epoch 5/25, Validation Loss: 0.1509\n",
      "           actual    predicted\n",
      "0      500.000000   465.154329\n",
      "1      446.000001   437.257008\n",
      "2      554.500002   522.321202\n",
      "3      544.000002   521.447936\n",
      "4     1438.249999  1365.744889\n",
      "...           ...          ...\n",
      "1019   409.999996   417.878024\n",
      "1020   419.500001   419.461048\n",
      "1021   403.999996   417.819021\n",
      "1022   458.666666   442.215506\n",
      "1023   379.500000   407.690284\n",
      "\n",
      "[1024 rows x 2 columns]\n",
      "Epoch 6/25, Training Loss: 0.1682\n",
      "Epoch 6/25, Validation Loss: 0.1537\n"
     ]
    }
   ],
   "source": [
    "importlib.reload(utils)\n",
    "performance_df = pd.read_csv('model_performances.csv')\n",
    "d_model=256\n",
    "nhead=8\n",
    "num_layers=5 \n",
    "dropout_pe=0.15\n",
    "dropout_encoder=0.15\n",
    "batch_size=1024\n",
    "learning_rate=0.00031\n",
    "epochs=25\n",
    "for aggregation_level in ['quarter_hour', 'hour', 'half_hour']:\n",
    "    for y_feature in ['CO2', 'VOC', 'hum', 'tmp', 'vis']:\n",
    "        \n",
    "        if y_feature == 'hum':\n",
    "            # hum we are overfitting with the same parameters. Decreasing num_layers by 2\n",
    "            num_layers -= 2\n",
    "        elif y_feature == 'tmp':\n",
    "            # tmp we are overfitting a little bit with the same parameters. Increasing dropout probability by 0.05 and decreasing num_layers by 1\n",
    "            num_layers -= 1\n",
    "            dropout_pe += 0.05\n",
    "            dropout_encoder += 0.05\n",
    "        \n",
    "        model, scaler, rmse, mae, me, mape, train_loss, val_loss, n_features = utils.create_multivariate_transformer_model_for_feature(df, d_model=d_model, nhead=nhead, num_layers=num_layers, dropout_pe=dropout_pe, dropout_encoder=dropout_encoder, batch_size=batch_size, learning_rate=learning_rate, epochs=epochs, y_feature=y_feature, aggregation_level=aggregation_level)\n",
    "        performance_df = performance_df.append({'model_name': 'multivariate_transformer','aggregation_level': aggregation_level, 'y_feature': y_feature, 'n_features': n_features, 'rmse': rmse, 'mae': mae, 'me': me, 'mape': mape, 'd_model': d_model, 'nhead': nhead, 'num_layers': num_layers, 'dropout_pe': dropout_pe,'dropout_encoder': dropout_encoder, 'batch_size': batch_size, 'learning_rate': learning_rate, 'epochs': epochs, 'train_loss': train_loss, 'val_loss': val_loss, 'note': '2 decoder Linear layers with LeakyReLu, shuffled training data'}, ignore_index=True)\n",
    "        performance_df.to_csv('model_performances.csv', index=False)\n",
    "        \n",
    "        if y_feature == 'hum':\n",
    "            # reverting changes\n",
    "            num_layers += 2\n",
    "        if y_feature == 'tmp':\n",
    "            # reverting changes\n",
    "            num_layers += 1\n",
    "            dropout_pe -= 0.05\n",
    "            dropout_encoder -= 0.05\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "transformer_multivariate_quarter_hour_vis_columns_v1.csv\n",
      "transformer_multivariate_quarter_hour_tmp_model_v1.pth\n",
      "transformer_multivariate_half_hour_tmp_columns_v1.csv\n",
      "transformer_multivariate_hour_vis_columns_v1.csv\n",
      "transformer_model_tmp_v1.pth\n",
      "transformer_multivariate_hour_hum_model_v1.pth\n",
      ".DS_v1\n",
      "renaming .DS_v1 to .DS_v1.DS_v1\n",
      "transformer_multivariate_hour_vis_scaler_v1.pth\n",
      "transformer_multivariate_hour_vis_model_v1.pth\n",
      "transformer_multivariate_hour_tmp_columns_v1.csv\n",
      "transformer_scaler_tmp_v1.pth\n",
      "transformer_multivariate_half_hour_CO2_model_v1.pth\n",
      "transformer_multivariate_half_hour_hum_scaler_v1.pth\n",
      "transformer_multivariate_quarter_hour_CO2_model_v1.pth\n",
      "transformer_multivariate_quarter_hour_hum_columns_v1.csv\n",
      "transformer_multivariate_hour_hum_columns_v1.csv\n",
      "transformer_multivariate_quarter_hour_CO2_scaler_v1.pth\n",
      "transformer_multivariate_quarter_hour_vis_model_v1.pth\n",
      "transformer_multivariate_hour_tmp_scaler_v1.pth\n",
      "transformer_multivariate_half_hour_VOC_columns_v1.csv\n",
      "transformer_multivariate_quarter_hour_tmp_columns_v1.csv\n",
      "transformer_multivariate_quarter_hour_vis_scaler_v1.pth\n",
      "transformer_multivariate_quarter_hour_VOC_model_v1.pth\n",
      "transformer_model_VOC_v1.pth\n",
      "transformer_multivariate_half_hour_vis_columns_v1.csv\n",
      "transformer_multivariate_hour_VOC_model_v1.pth\n",
      "transformer_scaler_v1.pth\n",
      "deleting transformer_scaler_tmp_v1.pth\n",
      "transformer_multivariate_hour_VOC_scaler_v2.pth\n",
      "deleting transformer_multivariate_hour_VOC_scaler_v1.pth\n",
      "renaming transformer_multivariate_hour_VOC_scaler_v2.pth to transformer_multivariate_hour_VOC_scaler_v1.pth\n",
      "transformer_multivariate_hour_CO2_model_v3.pth\n",
      "deleting transformer_multivariate_hour_CO2_model_v1.pth\n",
      "deleting transformer_multivariate_hour_CO2_model_v2.pth\n",
      "renaming transformer_multivariate_hour_CO2_model_v3.pth to transformer_multivariate_hour_CO2_model_v1.pth\n",
      "transformer_multivariate_quarter_hour_VOC_scaler_v2.pth\n",
      "deleting transformer_multivariate_quarter_hour_VOC_scaler_v1.pth\n",
      "renaming transformer_multivariate_quarter_hour_VOC_scaler_v2.pth to transformer_multivariate_quarter_hour_VOC_scaler_v1.pth\n",
      "transformer_multivariate_half_hour_tmp_scaler_v2.pth\n",
      "deleting transformer_multivariate_half_hour_tmp_scaler_v1.pth\n",
      "renaming transformer_multivariate_half_hour_tmp_scaler_v2.pth to transformer_multivariate_half_hour_tmp_scaler_v1.pth\n",
      "transformer_multivariate_quarter_hour_hum_model_v2.pth\n",
      "deleting transformer_multivariate_quarter_hour_hum_model_v1.pth\n",
      "renaming transformer_multivariate_quarter_hour_hum_model_v2.pth to transformer_multivariate_quarter_hour_hum_model_v1.pth\n",
      "transformer_model_hum_v1.pth\n",
      "transformer_model_v1.pth\n",
      "deleting transformer_model_CO2_v1.pth\n",
      "deleting transformer_model_VOC_v1.pth\n",
      "deleting transformer_model_hum_v1.pth\n",
      "deleting transformer_model_tmp_v1.pth\n",
      "transformer_multivariate_hour_VOC_columns_v1.csv\n",
      "transformer_multivariate_half_hour_CO2_columns_v1.csv\n",
      "transformer_multivariate_half_hour_CO2_scaler_v3.pth\n",
      "deleting transformer_multivariate_half_hour_CO2_scaler_v1.pth\n",
      "deleting transformer_multivariate_half_hour_CO2_scaler_v2.pth\n",
      "renaming transformer_multivariate_half_hour_CO2_scaler_v3.pth to transformer_multivariate_half_hour_CO2_scaler_v1.pth\n",
      "transformer_multivariate_quarter_hour_hum_scaler_v2.pth\n",
      "deleting transformer_multivariate_quarter_hour_hum_scaler_v1.pth\n",
      "renaming transformer_multivariate_quarter_hour_hum_scaler_v2.pth to transformer_multivariate_quarter_hour_hum_scaler_v1.pth\n",
      "transformer_multivariate_half_hour_hum_model_v2.pth\n",
      "deleting transformer_multivariate_half_hour_hum_model_v1.pth\n",
      "renaming transformer_multivariate_half_hour_hum_model_v2.pth to transformer_multivariate_half_hour_hum_model_v1.pth\n",
      "transformer_multivariate_half_hour_tmp_model_v2.pth\n",
      "deleting transformer_multivariate_half_hour_tmp_model_v1.pth\n",
      "renaming transformer_multivariate_half_hour_tmp_model_v2.pth to transformer_multivariate_half_hour_tmp_model_v1.pth\n",
      "transformer_multivariate_hour_hum_scaler_v2.pth\n",
      "deleting transformer_multivariate_hour_hum_scaler_v1.pth\n",
      "renaming transformer_multivariate_hour_hum_scaler_v2.pth to transformer_multivariate_hour_hum_scaler_v1.pth\n",
      "transformer_multivariate_half_hour_vis_model_v2.pth\n",
      "deleting transformer_multivariate_half_hour_vis_model_v1.pth\n",
      "renaming transformer_multivariate_half_hour_vis_model_v2.pth to transformer_multivariate_half_hour_vis_model_v1.pth\n",
      "transformer_multivariate_half_hour_vis_scaler_v2.pth\n",
      "deleting transformer_multivariate_half_hour_vis_scaler_v1.pth\n",
      "renaming transformer_multivariate_half_hour_vis_scaler_v2.pth to transformer_multivariate_half_hour_vis_scaler_v1.pth\n",
      "transformer_multivariate_quarter_hour_VOC_columns_v1.csv\n",
      "transformer_multivariate_half_hour_hum_columns_v1.csv\n",
      "transformer_multivariate_hour_tmp_model_v2.pth\n",
      "deleting transformer_multivariate_hour_tmp_model_v1.pth\n",
      "renaming transformer_multivariate_hour_tmp_model_v2.pth to transformer_multivariate_hour_tmp_model_v1.pth\n",
      "transformer_multivariate_quarter_hour_CO2_columns_v2.csv\n",
      "deleting transformer_multivariate_quarter_hour_CO2_columns_v1.pkl\n",
      "renaming transformer_multivariate_quarter_hour_CO2_columns_v2.csv to transformer_multivariate_quarter_hour_CO2_columns_v1.csv\n",
      "transformer_multivariate_quarter_hour_tmp_scaler_v2.pth\n",
      "deleting transformer_multivariate_quarter_hour_tmp_scaler_v1.pth\n",
      "renaming transformer_multivariate_quarter_hour_tmp_scaler_v2.pth to transformer_multivariate_quarter_hour_tmp_scaler_v1.pth\n",
      "transformer_model_CO2_v1.pth\n",
      "transformer_multivariate_half_hour_VOC_model_v2.pth\n",
      "deleting transformer_multivariate_half_hour_VOC_model_v1.pth\n",
      "renaming transformer_multivariate_half_hour_VOC_model_v2.pth to transformer_multivariate_half_hour_VOC_model_v1.pth\n",
      "transformer_multivariate_half_hour_VOC_scaler_v2.pth\n",
      "deleting transformer_multivariate_half_hour_VOC_scaler_v1.pth\n",
      "renaming transformer_multivariate_half_hour_VOC_scaler_v2.pth to transformer_multivariate_half_hour_VOC_scaler_v1.pth\n",
      "transformer_multivariate_hour_CO2_columns_v1.csv\n",
      "transformer_multivariate_hour_CO2_scaler_v3.pth\n",
      "deleting transformer_multivariate_hour_CO2_scaler_v1.pth\n",
      "deleting transformer_multivariate_hour_CO2_scaler_v2.pth\n",
      "renaming transformer_multivariate_hour_CO2_scaler_v3.pth to transformer_multivariate_hour_CO2_scaler_v1.pth\n"
     ]
    }
   ],
   "source": [
    "all_model_files = [f for f in os.listdir('models/')]\n",
    "all_model_files_no_version = [f.rsplit('_', 1)[0] for f in all_model_files]\n",
    "all_model_files_no_version_unique = list(set(all_model_files_no_version))\n",
    "all_model_files_no_version_unique\n",
    "for model_file in all_model_files_no_version_unique:\n",
    "    model_files = [f for f in all_model_files if f.startswith(model_file)]\n",
    "    model_files.sort()\n",
    "    latest_model_file = model_files[-1]\n",
    "    print(latest_model_file)\n",
    "    # delete all other versions\n",
    "    for model_file_to_delete in model_files[:-1]:\n",
    "        print('deleting ' + model_file_to_delete)\n",
    "        os.remove('models/' + model_file_to_delete)\n",
    "    # rename latest model file to v1\n",
    "    file_ending = latest_model_file.rsplit('.', 1)[1]\n",
    "    latest_model_file_rename = latest_model_file.rsplit('_', 1)[0] + '_v1' + '.' + file_ending\n",
    "    if latest_model_file != latest_model_file_rename:\n",
    "        print('renaming ' + latest_model_file + ' to ' + latest_model_file_rename)\n",
    "        os.rename('models/' + latest_model_file, 'models/' + model_file + '_v1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training data cutoff:  2023-07-15 02:45:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/timehmann/Library/Mobile Documents/com~apple~CloudDocs/Studium/Data_Science_Karlsruhe/Data_Science_Semester6/Internet_Of_Things/IoT_Project/utils.py:868: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  feature_count = x[0].shape[1]\n",
      "/Users/timehmann/Library/Mobile Documents/com~apple~CloudDocs/Studium/Data_Science_Karlsruhe/Data_Science_Semester6/Internet_Of_Things/IoT_Project/utils.py:869: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  print(\"feature count: \", feature_count)\n",
      "/Users/timehmann/Library/Mobile Documents/com~apple~CloudDocs/Studium/Data_Science_Karlsruhe/Data_Science_Semester6/Internet_Of_Things/IoT_Project/utils.py:873: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  x_test, y_test = to_sequences(window_size, df_test)\n",
      "/Users/timehmann/Library/Mobile Documents/com~apple~CloudDocs/Studium/Data_Science_Karlsruhe/Data_Science_Semester6/Internet_Of_Things/IoT_Project/utils.py:874: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tmp                         float64\n",
      "hum                         float64\n",
      "CO2                         float64\n",
      "VOC                         float64\n",
      "vis                         float64\n",
      "IR                          float64\n",
      "WIFI                        float64\n",
      "BLE                         float64\n",
      "rssi                        float64\n",
      "channel_rssi                float64\n",
      "channel_index               float64\n",
      "spreading_factor            float64\n",
      "bandwidth                   float64\n",
      "f_cnt                       float64\n",
      "isHoliday                   float64\n",
      "isExamTime                  float64\n",
      "weekday                     float64\n",
      "month                       float64\n",
      "hour_sin                    float64\n",
      "semester_SS23               float64\n",
      "semester_WS22/23            float64\n",
      "semester_WS23/24            float64\n",
      "group                       float64\n",
      "device_id_hka-aqm-am001     float64\n",
      "device_id_hka-aqm-am002     float64\n",
      "device_id_hka-aqm-am003a    float64\n",
      "device_id_hka-aqm-am003b    float64\n",
      "device_id_hka-aqm-am004     float64\n",
      "device_id_hka-aqm-am005     float64\n",
      "device_id_hka-aqm-am107     float64\n",
      "device_id_hka-aqm-am109     float64\n",
      "device_id_hka-aqm-am110     float64\n",
      "device_id_hka-aqm-am111     float64\n",
      "device_id_hka-aqm-am115     float64\n",
      "device_id_hka-aqm-am116     float64\n",
      "device_id_hka-aqm-am117     float64\n",
      "device_id_hka-aqm-am123     float64\n",
      "device_id_hka-aqm-am124     float64\n",
      "device_id_hka-aqm-am126     float64\n",
      "device_id_hka-aqm-am201a    float64\n",
      "device_id_hka-aqm-am201b    float64\n",
      "device_id_hka-aqm-am204     float64\n",
      "device_id_hka-aqm-am205     float64\n",
      "device_id_hka-aqm-am209     float64\n",
      "device_id_hka-aqm-am210     float64\n",
      "device_id_hka-aqm-am211     float64\n",
      "device_id_hka-aqm-am301     float64\n",
      "device_id_hka-aqm-am307     float64\n",
      "device_id_hka-aqm-am308     float64\n",
      "dtype: object\n",
      "feature count:  49\n",
      "feature count:  49\n",
      "Training data shape: torch.Size([244176, 20, 49]) torch.Size([244176, 1])\n",
      "Testing data shape: torch.Size([62745, 20, 49]) torch.Size([62745, 1])\n",
      "         actual   predicted\n",
      "0    466.999999  487.585348\n",
      "1    455.999999  489.097007\n",
      "2    455.999999  484.258748\n",
      "3    437.999999  482.026215\n",
      "4    435.000001  467.013061\n",
      "..          ...         ...\n",
      "123  446.999999  460.052533\n",
      "124  436.999998  470.577530\n",
      "125  446.999999  458.449503\n",
      "126  450.000002  472.874027\n",
      "127  445.000002  472.476152\n",
      "\n",
      "[128 rows x 2 columns]\n",
      "Epoch 1/2, Validation Loss: 0.0735\n",
      "         actual   predicted\n",
      "0    466.999999  529.322873\n",
      "1    455.999999  531.530266\n",
      "2    455.999999  510.827987\n",
      "3    437.999999  503.703505\n",
      "4    435.000001  472.199065\n",
      "..          ...         ...\n",
      "123  446.999999  479.487189\n",
      "124  436.999998  498.077639\n",
      "125  446.999999  475.978976\n",
      "126  450.000002  494.600295\n",
      "127  445.000002  495.114179\n",
      "\n",
      "[128 rows x 2 columns]\n",
      "Epoch 2/2, Validation Loss: 0.0770\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'NoneType' object cannot be interpreted as an integer",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m importlib\u001b[38;5;241m.\u001b[39mreload(utils)\n\u001b[0;32m----> 2\u001b[0m model, scaler, rmse, mae, mape \u001b[38;5;241m=\u001b[39m utils\u001b[38;5;241m.\u001b[39mcreate_multivariate_transformer_model_for_feature(df, d_model\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m128\u001b[39m, nhead\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m8\u001b[39m, num_layers\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m4\u001b[39m, dropout\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.1\u001b[39m, batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m128\u001b[39m, learning_rate\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.00025\u001b[39m, epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)\n",
      "File \u001b[0;32m~/Library/Mobile Documents/com~apple~CloudDocs/Studium/Data_Science_Karlsruhe/Data_Science_Semester6/Internet_Of_Things/IoT_Project/utils.py:954\u001b[0m, in \u001b[0;36mcreate_multivariate_transformer_model_for_feature\u001b[0;34m(df, y_feature, aggregation_level, device, window_size, batch_size, epochs, clean_data, input_dim, d_model, nhead, num_layers, dropout, learning_rate, drop_columns)\u001b[0m\n\u001b[1;32m    951\u001b[0m save_columns(full_preprocessed_df_unscaled, y_feature\u001b[38;5;241m=\u001b[39my_feature, model_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtransformer_multivariate_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00maggregation_level\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    953\u001b[0m \u001b[38;5;66;03m# Evaluate the model\u001b[39;00m\n\u001b[0;32m--> 954\u001b[0m rmse, mae, mape \u001b[38;5;241m=\u001b[39m evaluate_transformer_model(device, test_loader, model, scaler, y_test, y_feature_scaler_index\u001b[38;5;241m=\u001b[39my_feature_scaler_index, input_dim\u001b[38;5;241m=\u001b[39minput_dim)\n\u001b[1;32m    956\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m model, scaler, rmse, mae, mape\n",
      "File \u001b[0;32m~/Library/Mobile Documents/com~apple~CloudDocs/Studium/Data_Science_Karlsruhe/Data_Science_Semester6/Internet_Of_Things/IoT_Project/utils.py:464\u001b[0m, in \u001b[0;36mevaluate_transformer_model\u001b[0;34m(device, test_loader, model, scaler, y_test, y_feature_scaler_index, input_dim)\u001b[0m\n\u001b[1;32m    462\u001b[0m actual_batch \u001b[38;5;241m=\u001b[39m y_batch\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mnumpy()\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m    463\u001b[0m predicted_batch \u001b[38;5;241m=\u001b[39m outputs\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mnumpy()\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m--> 464\u001b[0m zeroes_for_scaler \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mzeros((actual_batch\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m], input_dim))\n\u001b[1;32m    466\u001b[0m zeroes_for_scaler[:, y_feature_scaler_index] \u001b[38;5;241m=\u001b[39m actual_batch\u001b[38;5;241m.\u001b[39mflatten()  \u001b[38;5;66;03m# Insert CO2 values into the correct column\u001b[39;00m\n\u001b[1;32m    467\u001b[0m inverse_transformed \u001b[38;5;241m=\u001b[39m scaler\u001b[38;5;241m.\u001b[39minverse_transform(zeroes_for_scaler)\n",
      "\u001b[0;31mTypeError\u001b[0m: 'NoneType' object cannot be interpreted as an integer"
     ]
    }
   ],
   "source": [
    "importlib.reload(utils)\n",
    "model, scaler, rmse, mae, mape = utils.create_multivariate_transformer_model_for_feature(df, d_model=128, nhead=8, num_layers=4, dropout=0.1, batch_size=128, learning_rate=0.00025, epochs=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data shape: torch.Size([150050, 47]) torch.Size([150050])\n",
      "Testing data shape: torch.Size([50023, 47]) torch.Size([50023])\n",
      "     actual  predicted\n",
      "0     408.0  477.67099\n",
      "1     410.0  477.67099\n",
      "2     406.5  477.67099\n",
      "3     410.5  477.67099\n",
      "4     413.5  477.67099\n",
      "..      ...        ...\n",
      "123   460.0  477.67099\n",
      "124   440.0  477.67099\n",
      "125   432.0  477.67099\n",
      "126   432.5  477.67099\n",
      "127   423.5  477.67099\n",
      "\n",
      "[128 rows x 2 columns]\n",
      "Epoch 1/1000, Validation Loss: 1.3423\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m importlib\u001b[38;5;241m.\u001b[39mreload(utils)\n\u001b[0;32m----> 2\u001b[0m model, scaler \u001b[38;5;241m=\u001b[39m utils\u001b[38;5;241m.\u001b[39mcreate_multivariate_model_for_feature(df, aggregation_level\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhalf_hour\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m~/Library/Mobile Documents/com~apple~CloudDocs/Studium/Data_Science_Karlsruhe/Data_Science_Semester6/Internet_Of_Things/IoT_Project/utils.py:725\u001b[0m, in \u001b[0;36mcreate_multivariate_model_for_feature\u001b[0;34m(df, y_feature, aggregation_level, device, window_size, epochs, clean_data, drop_columns)\u001b[0m\n\u001b[1;32m    723\u001b[0m train_dataset, test_dataset, train_loader, test_loader, scaler, y_test \u001b[38;5;241m=\u001b[39m get_data_for_multivariate_forecast(df, y_feature, window_size, aggregation_level, clean_data\u001b[38;5;241m=\u001b[39mclean_data, drop_columns\u001b[38;5;241m=\u001b[39mdrop_columns)\n\u001b[1;32m    724\u001b[0m \u001b[38;5;66;03m# Train the model\u001b[39;00m\n\u001b[0;32m--> 725\u001b[0m model \u001b[38;5;241m=\u001b[39m train_fcn_model(device, train_loader, test_loader, scaler, epochs)\n\u001b[1;32m    726\u001b[0m \u001b[38;5;66;03m# Evaluate the model\u001b[39;00m\n\u001b[1;32m    727\u001b[0m \u001b[38;5;66;03m#evaluate_transformer_model(device, test_loader, model, scaler, y_test)\u001b[39;00m\n\u001b[1;32m    728\u001b[0m \u001b[38;5;66;03m# Save the model and the scaler\u001b[39;00m\n\u001b[1;32m    729\u001b[0m \u001b[38;5;66;03m#save_model(model, y_feature=y_feature)\u001b[39;00m\n\u001b[1;32m    730\u001b[0m \u001b[38;5;66;03m#save_scaler(scaler, y_feature=y_feature)\u001b[39;00m\n\u001b[1;32m    732\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m model, scaler\n",
      "File \u001b[0;32m~/Library/Mobile Documents/com~apple~CloudDocs/Studium/Data_Science_Karlsruhe/Data_Science_Semester6/Internet_Of_Things/IoT_Project/utils.py:372\u001b[0m, in \u001b[0;36mtrain_fcn_model\u001b[0;34m(device, train_loader, test_loader, scaler, epochs)\u001b[0m\n\u001b[1;32m    370\u001b[0m     loss \u001b[38;5;241m=\u001b[39m criterion(outputs, y_batch\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m1\u001b[39m))  \u001b[38;5;66;03m# Add unsqueeze to match target size\u001b[39;00m\n\u001b[1;32m    371\u001b[0m     loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[0;32m--> 372\u001b[0m     optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m    374\u001b[0m \u001b[38;5;66;03m# Validation\u001b[39;00m\n\u001b[1;32m    375\u001b[0m model\u001b[38;5;241m.\u001b[39meval()\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/torch/optim/optimizer.py:280\u001b[0m, in \u001b[0;36mOptimizer.profile_hook_step.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    276\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    277\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must return None or a tuple of (new_args, new_kwargs),\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    278\u001b[0m                                \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbut got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresult\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 280\u001b[0m out \u001b[38;5;241m=\u001b[39m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    281\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_optimizer_step_code()\n\u001b[1;32m    283\u001b[0m \u001b[38;5;66;03m# call optimizer step post hooks\u001b[39;00m\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/torch/optim/optimizer.py:33\u001b[0m, in \u001b[0;36m_use_grad_for_differentiable.<locals>._use_grad\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     32\u001b[0m     torch\u001b[38;5;241m.\u001b[39mset_grad_enabled(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdefaults[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdifferentiable\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m---> 33\u001b[0m     ret \u001b[38;5;241m=\u001b[39m func(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m     34\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     35\u001b[0m     torch\u001b[38;5;241m.\u001b[39mset_grad_enabled(prev_grad)\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/torch/optim/adam.py:141\u001b[0m, in \u001b[0;36mAdam.step\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m    130\u001b[0m     beta1, beta2 \u001b[38;5;241m=\u001b[39m group[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbetas\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m    132\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_init_group(\n\u001b[1;32m    133\u001b[0m         group,\n\u001b[1;32m    134\u001b[0m         params_with_grad,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    138\u001b[0m         max_exp_avg_sqs,\n\u001b[1;32m    139\u001b[0m         state_steps)\n\u001b[0;32m--> 141\u001b[0m     adam(\n\u001b[1;32m    142\u001b[0m         params_with_grad,\n\u001b[1;32m    143\u001b[0m         grads,\n\u001b[1;32m    144\u001b[0m         exp_avgs,\n\u001b[1;32m    145\u001b[0m         exp_avg_sqs,\n\u001b[1;32m    146\u001b[0m         max_exp_avg_sqs,\n\u001b[1;32m    147\u001b[0m         state_steps,\n\u001b[1;32m    148\u001b[0m         amsgrad\u001b[38;5;241m=\u001b[39mgroup[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mamsgrad\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[1;32m    149\u001b[0m         beta1\u001b[38;5;241m=\u001b[39mbeta1,\n\u001b[1;32m    150\u001b[0m         beta2\u001b[38;5;241m=\u001b[39mbeta2,\n\u001b[1;32m    151\u001b[0m         lr\u001b[38;5;241m=\u001b[39mgroup[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlr\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[1;32m    152\u001b[0m         weight_decay\u001b[38;5;241m=\u001b[39mgroup[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mweight_decay\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[1;32m    153\u001b[0m         eps\u001b[38;5;241m=\u001b[39mgroup[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124meps\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[1;32m    154\u001b[0m         maximize\u001b[38;5;241m=\u001b[39mgroup[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmaximize\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[1;32m    155\u001b[0m         foreach\u001b[38;5;241m=\u001b[39mgroup[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mforeach\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[1;32m    156\u001b[0m         capturable\u001b[38;5;241m=\u001b[39mgroup[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcapturable\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[1;32m    157\u001b[0m         differentiable\u001b[38;5;241m=\u001b[39mgroup[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdifferentiable\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[1;32m    158\u001b[0m         fused\u001b[38;5;241m=\u001b[39mgroup[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfused\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[1;32m    159\u001b[0m         grad_scale\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgrad_scale\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[1;32m    160\u001b[0m         found_inf\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfound_inf\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[1;32m    161\u001b[0m     )\n\u001b[1;32m    163\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m loss\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/torch/optim/adam.py:281\u001b[0m, in \u001b[0;36madam\u001b[0;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, foreach, capturable, differentiable, fused, grad_scale, found_inf, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize)\u001b[0m\n\u001b[1;32m    278\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    279\u001b[0m     func \u001b[38;5;241m=\u001b[39m _single_tensor_adam\n\u001b[0;32m--> 281\u001b[0m func(params,\n\u001b[1;32m    282\u001b[0m      grads,\n\u001b[1;32m    283\u001b[0m      exp_avgs,\n\u001b[1;32m    284\u001b[0m      exp_avg_sqs,\n\u001b[1;32m    285\u001b[0m      max_exp_avg_sqs,\n\u001b[1;32m    286\u001b[0m      state_steps,\n\u001b[1;32m    287\u001b[0m      amsgrad\u001b[38;5;241m=\u001b[39mamsgrad,\n\u001b[1;32m    288\u001b[0m      beta1\u001b[38;5;241m=\u001b[39mbeta1,\n\u001b[1;32m    289\u001b[0m      beta2\u001b[38;5;241m=\u001b[39mbeta2,\n\u001b[1;32m    290\u001b[0m      lr\u001b[38;5;241m=\u001b[39mlr,\n\u001b[1;32m    291\u001b[0m      weight_decay\u001b[38;5;241m=\u001b[39mweight_decay,\n\u001b[1;32m    292\u001b[0m      eps\u001b[38;5;241m=\u001b[39meps,\n\u001b[1;32m    293\u001b[0m      maximize\u001b[38;5;241m=\u001b[39mmaximize,\n\u001b[1;32m    294\u001b[0m      capturable\u001b[38;5;241m=\u001b[39mcapturable,\n\u001b[1;32m    295\u001b[0m      differentiable\u001b[38;5;241m=\u001b[39mdifferentiable,\n\u001b[1;32m    296\u001b[0m      grad_scale\u001b[38;5;241m=\u001b[39mgrad_scale,\n\u001b[1;32m    297\u001b[0m      found_inf\u001b[38;5;241m=\u001b[39mfound_inf)\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/torch/optim/adam.py:391\u001b[0m, in \u001b[0;36m_single_tensor_adam\u001b[0;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, grad_scale, found_inf, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize, capturable, differentiable)\u001b[0m\n\u001b[1;32m    389\u001b[0m     denom \u001b[38;5;241m=\u001b[39m (max_exp_avg_sqs[i]\u001b[38;5;241m.\u001b[39msqrt() \u001b[38;5;241m/\u001b[39m bias_correction2_sqrt)\u001b[38;5;241m.\u001b[39madd_(eps)\n\u001b[1;32m    390\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 391\u001b[0m     denom \u001b[38;5;241m=\u001b[39m (exp_avg_sq\u001b[38;5;241m.\u001b[39msqrt() \u001b[38;5;241m/\u001b[39m bias_correction2_sqrt)\u001b[38;5;241m.\u001b[39madd_(eps)\n\u001b[1;32m    393\u001b[0m param\u001b[38;5;241m.\u001b[39maddcdiv_(exp_avg, denom, value\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39mstep_size)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "importlib.reload(utils)\n",
    "model, scaler = utils.create_multivariate_model_for_feature(df, aggregation_level='half_hour')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['tmp', 'hum', 'CO2', 'VOC', 'vis', 'IR', 'WIFI', 'BLE', 'rssi',\n",
       "       'channel_rssi', 'channel_index', 'spreading_factor', 'bandwidth',\n",
       "       'f_cnt', 'isHoliday', 'isExamTime', 'weekday', 'month', 'hour_sin',\n",
       "       'semester_SS23', 'semester_WS22/23', 'semester_WS23/24', 'tmp_lag_1',\n",
       "       'tmp_lag_2', 'tmp_lag_3', 'tmp_lag_4', 'tmp_lag_5', 'hum_lag_1',\n",
       "       'hum_lag_2', 'hum_lag_3', 'hum_lag_4', 'hum_lag_5', 'CO2_lag_1',\n",
       "       'CO2_lag_2', 'CO2_lag_3', 'CO2_lag_4', 'CO2_lag_5', 'CO2_next',\n",
       "       'VOC_lag_1', 'VOC_lag_2', 'VOC_lag_3', 'VOC_lag_4', 'VOC_lag_5',\n",
       "       'vis_lag_1', 'vis_lag_2', 'vis_lag_3', 'vis_lag_4', 'vis_lag_5',\n",
       "       'CO2_next_scaled'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading latest scaler: models/transformer_multivariate_quarter_hour_CO2_scaler_v1.pth\n",
      "loading latest model: models/transformer_multivariate_quarter_hour_CO2_model_v1.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date_time_rounded</th>\n",
       "      <th>CO2_pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2022-11-03 00:00:00</td>\n",
       "      <td>458.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2022-11-03 00:15:00</td>\n",
       "      <td>457.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2022-11-03 00:30:00</td>\n",
       "      <td>463.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2022-11-03 00:45:00</td>\n",
       "      <td>462.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2022-11-03 01:00:00</td>\n",
       "      <td>459.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>2022-11-03 22:45:00</td>\n",
       "      <td>461.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>2022-11-03 23:00:00</td>\n",
       "      <td>461.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>2022-11-03 23:15:00</td>\n",
       "      <td>461.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>2022-11-03 23:30:00</td>\n",
       "      <td>461.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>2022-11-03 23:45:00</td>\n",
       "      <td>461.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>96 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     date_time_rounded  CO2_pred\n",
       "0  2022-11-03 00:00:00     458.0\n",
       "1  2022-11-03 00:15:00     457.0\n",
       "2  2022-11-03 00:30:00     463.0\n",
       "3  2022-11-03 00:45:00     462.0\n",
       "4  2022-11-03 01:00:00     459.0\n",
       "..                 ...       ...\n",
       "91 2022-11-03 22:45:00     461.0\n",
       "92 2022-11-03 23:00:00     461.0\n",
       "93 2022-11-03 23:15:00     461.0\n",
       "94 2022-11-03 23:30:00     461.0\n",
       "95 2022-11-03 23:45:00     461.0\n",
       "\n",
       "[96 rows x 2 columns]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "importlib.reload(utils)\n",
    "start_time = datetime.strptime('2022-11-03 10:00:00', '%Y-%m-%d %H:%M:%S')\n",
    "predictions = utils.predict_data_multivariate_transformer(start_time=start_time, selected_room='am001', prediction_count=5)\n",
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['date_time_rounded', 'tmp', 'hum', 'CO2', 'VOC', 'vis', 'IR', 'WIFI',\n",
       "       'BLE', 'rssi', 'channel_rssi', 'channel_index', 'spreading_factor',\n",
       "       'bandwidth', 'f_cnt', 'isHoliday', 'isExamTime', 'weekday', 'month',\n",
       "       'hour_sin', 'semester_SS23', 'semester_WS22/23', 'semester_WS23/24',\n",
       "       'group', 'device_id_hka-aqm-am001', 'device_id_hka-aqm-am002',\n",
       "       'device_id_hka-aqm-am003a', 'device_id_hka-aqm-am003b',\n",
       "       'device_id_hka-aqm-am004', 'device_id_hka-aqm-am005',\n",
       "       'device_id_hka-aqm-am107', 'device_id_hka-aqm-am109',\n",
       "       'device_id_hka-aqm-am110', 'device_id_hka-aqm-am111',\n",
       "       'device_id_hka-aqm-am115', 'device_id_hka-aqm-am116',\n",
       "       'device_id_hka-aqm-am117', 'device_id_hka-aqm-am123',\n",
       "       'device_id_hka-aqm-am124', 'device_id_hka-aqm-am126',\n",
       "       'device_id_hka-aqm-am201a', 'device_id_hka-aqm-am201b',\n",
       "       'device_id_hka-aqm-am204', 'device_id_hka-aqm-am205',\n",
       "       'device_id_hka-aqm-am209', 'device_id_hka-aqm-am210',\n",
       "       'device_id_hka-aqm-am211', 'device_id_hka-aqm-am301',\n",
       "       'device_id_hka-aqm-am307', 'device_id_hka-aqm-am308'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions.columns"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
