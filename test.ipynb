{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\t-ehm\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\stpyvista\\__init__.py:18: UserWarning: Using Panel interactively in VSCode notebooks requires the jupyter_bokeh package to be installed. You can install it with:\n",
      "\n",
      "   pip install jupyter_bokeh\n",
      "\n",
      "or:\n",
      "    conda install jupyter_bokeh\n",
      "\n",
      "and try again.\n",
      "  pn.extension(\"vtk\", sizing_mode=\"stretch_both\")\n"
     ]
    },
    {
     "data": {
      "application/javascript": "(function(root) {\n  function now() {\n    return new Date();\n  }\n\n  var force = true;\n  var py_version = '3.4.1'.replace('rc', '-rc.').replace('.dev', '-dev.');\n  var reloading = false;\n  var Bokeh = root.Bokeh;\n\n  if (typeof (root._bokeh_timeout) === \"undefined\" || force) {\n    root._bokeh_timeout = Date.now() + 5000;\n    root._bokeh_failed_load = false;\n  }\n\n  function run_callbacks() {\n    try {\n      root._bokeh_onload_callbacks.forEach(function(callback) {\n        if (callback != null)\n          callback();\n      });\n    } finally {\n      delete root._bokeh_onload_callbacks;\n    }\n    console.debug(\"Bokeh: all callbacks have finished\");\n  }\n\n  function load_libs(css_urls, js_urls, js_modules, js_exports, callback) {\n    if (css_urls == null) css_urls = [];\n    if (js_urls == null) js_urls = [];\n    if (js_modules == null) js_modules = [];\n    if (js_exports == null) js_exports = {};\n\n    root._bokeh_onload_callbacks.push(callback);\n\n    if (root._bokeh_is_loading > 0) {\n      console.debug(\"Bokeh: BokehJS is being loaded, scheduling callback at\", now());\n      return null;\n    }\n    if (js_urls.length === 0 && js_modules.length === 0 && Object.keys(js_exports).length === 0) {\n      run_callbacks();\n      return null;\n    }\n    if (!reloading) {\n      console.debug(\"Bokeh: BokehJS not loaded, scheduling load and callback at\", now());\n    }\n\n    function on_load() {\n      root._bokeh_is_loading--;\n      if (root._bokeh_is_loading === 0) {\n        console.debug(\"Bokeh: all BokehJS libraries/stylesheets loaded\");\n        run_callbacks()\n      }\n    }\n    window._bokeh_on_load = on_load\n\n    function on_error() {\n      console.error(\"failed to load \" + url);\n    }\n\n    var skip = [];\n    if (window.requirejs) {\n      window.requirejs.config({'packages': {}, 'paths': {'vtk': 'https://cdn.jsdelivr.net/npm/vtk.js@30.1.0/vtk'}, 'shim': {'vtk': {'exports': 'vtk'}}});\n      require([\"vtk\"], function() {\n\ton_load()\n      })\n      root._bokeh_is_loading = css_urls.length + 1;\n    } else {\n      root._bokeh_is_loading = css_urls.length + js_urls.length + js_modules.length + Object.keys(js_exports).length;\n    }\n\n    var existing_stylesheets = []\n    var links = document.getElementsByTagName('link')\n    for (var i = 0; i < links.length; i++) {\n      var link = links[i]\n      if (link.href != null) {\n\texisting_stylesheets.push(link.href)\n      }\n    }\n    for (var i = 0; i < css_urls.length; i++) {\n      var url = css_urls[i];\n      if (existing_stylesheets.indexOf(url) !== -1) {\n\ton_load()\n\tcontinue;\n      }\n      const element = document.createElement(\"link\");\n      element.onload = on_load;\n      element.onerror = on_error;\n      element.rel = \"stylesheet\";\n      element.type = \"text/css\";\n      element.href = url;\n      console.debug(\"Bokeh: injecting link tag for BokehJS stylesheet: \", url);\n      document.body.appendChild(element);\n    }    if (((window.vtk !== undefined) && (!(window.vtk instanceof HTMLElement))) || window.requirejs) {\n      var urls = ['https://cdn.holoviz.org/panel/1.4.4/dist/bundled/abstractvtkplot/vtk.js@30.1.0/vtk.js'];\n      for (var i = 0; i < urls.length; i++) {\n        skip.push(urls[i])\n      }\n    }    var existing_scripts = []\n    var scripts = document.getElementsByTagName('script')\n    for (var i = 0; i < scripts.length; i++) {\n      var script = scripts[i]\n      if (script.src != null) {\n\texisting_scripts.push(script.src)\n      }\n    }\n    for (var i = 0; i < js_urls.length; i++) {\n      var url = js_urls[i];\n      if (skip.indexOf(url) !== -1 || existing_scripts.indexOf(url) !== -1) {\n\tif (!window.requirejs) {\n\t  on_load();\n\t}\n\tcontinue;\n      }\n      var element = document.createElement('script');\n      element.onload = on_load;\n      element.onerror = on_error;\n      element.async = false;\n      element.src = url;\n      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n      document.head.appendChild(element);\n    }\n    for (var i = 0; i < js_modules.length; i++) {\n      var url = js_modules[i];\n      if (skip.indexOf(url) !== -1 || existing_scripts.indexOf(url) !== -1) {\n\tif (!window.requirejs) {\n\t  on_load();\n\t}\n\tcontinue;\n      }\n      var element = document.createElement('script');\n      element.onload = on_load;\n      element.onerror = on_error;\n      element.async = false;\n      element.src = url;\n      element.type = \"module\";\n      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n      document.head.appendChild(element);\n    }\n    for (const name in js_exports) {\n      var url = js_exports[name];\n      if (skip.indexOf(url) >= 0 || root[name] != null) {\n\tif (!window.requirejs) {\n\t  on_load();\n\t}\n\tcontinue;\n      }\n      var element = document.createElement('script');\n      element.onerror = on_error;\n      element.async = false;\n      element.type = \"module\";\n      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n      element.textContent = `\n      import ${name} from \"${url}\"\n      window.${name} = ${name}\n      window._bokeh_on_load()\n      `\n      document.head.appendChild(element);\n    }\n    if (!js_urls.length && !js_modules.length) {\n      on_load()\n    }\n  };\n\n  function inject_raw_css(css) {\n    const element = document.createElement(\"style\");\n    element.appendChild(document.createTextNode(css));\n    document.body.appendChild(element);\n  }\n\n  var js_urls = [\"https://cdn.holoviz.org/panel/1.4.4/dist/bundled/abstractvtkplot/vtk.js@30.1.0/vtk.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-3.4.1.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-gl-3.4.1.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-widgets-3.4.1.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-tables-3.4.1.min.js\", \"https://cdn.holoviz.org/panel/1.4.4/dist/panel.min.js\"];\n  var js_modules = [];\n  var js_exports = {};\n  var css_urls = [];\n  var inline_js = [    function(Bokeh) {\n      Bokeh.set_log_level(\"info\");\n    },\nfunction(Bokeh) {} // ensure no trailing comma for IE\n  ];\n\n  function run_inline_js() {\n    if ((root.Bokeh !== undefined) || (force === true)) {\n      for (var i = 0; i < inline_js.length; i++) {\n\ttry {\n          inline_js[i].call(root, root.Bokeh);\n\t} catch(e) {\n\t  if (!reloading) {\n\t    throw e;\n\t  }\n\t}\n      }\n      // Cache old bokeh versions\n      if (Bokeh != undefined && !reloading) {\n\tvar NewBokeh = root.Bokeh;\n\tif (Bokeh.versions === undefined) {\n\t  Bokeh.versions = new Map();\n\t}\n\tif (NewBokeh.version !== Bokeh.version) {\n\t  Bokeh.versions.set(NewBokeh.version, NewBokeh)\n\t}\n\troot.Bokeh = Bokeh;\n      }} else if (Date.now() < root._bokeh_timeout) {\n      setTimeout(run_inline_js, 100);\n    } else if (!root._bokeh_failed_load) {\n      console.log(\"Bokeh: BokehJS failed to load within specified timeout.\");\n      root._bokeh_failed_load = true;\n    }\n    root._bokeh_is_initializing = false\n  }\n\n  function load_or_wait() {\n    // Implement a backoff loop that tries to ensure we do not load multiple\n    // versions of Bokeh and its dependencies at the same time.\n    // In recent versions we use the root._bokeh_is_initializing flag\n    // to determine whether there is an ongoing attempt to initialize\n    // bokeh, however for backward compatibility we also try to ensure\n    // that we do not start loading a newer (Panel>=1.0 and Bokeh>3) version\n    // before older versions are fully initialized.\n    if (root._bokeh_is_initializing && Date.now() > root._bokeh_timeout) {\n      root._bokeh_is_initializing = false;\n      root._bokeh_onload_callbacks = undefined;\n      console.log(\"Bokeh: BokehJS was loaded multiple times but one version failed to initialize.\");\n      load_or_wait();\n    } else if (root._bokeh_is_initializing || (typeof root._bokeh_is_initializing === \"undefined\" && root._bokeh_onload_callbacks !== undefined)) {\n      setTimeout(load_or_wait, 100);\n    } else {\n      root._bokeh_is_initializing = true\n      root._bokeh_onload_callbacks = []\n      var bokeh_loaded = Bokeh != null && (Bokeh.version === py_version || (Bokeh.versions !== undefined && Bokeh.versions.has(py_version)));\n      if (!reloading && !bokeh_loaded) {\n\troot.Bokeh = undefined;\n      }\n      load_libs(css_urls, js_urls, js_modules, js_exports, function() {\n\tconsole.debug(\"Bokeh: BokehJS plotting callback run at\", now());\n\trun_inline_js();\n      });\n    }\n  }\n  // Give older versions of the autoload script a head-start to ensure\n  // they initialize before we start loading newer version.\n  setTimeout(load_or_wait, 100)\n}(window));",
      "application/vnd.holoviews_load.v0+json": ""
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": "\nif ((window.PyViz === undefined) || (window.PyViz instanceof HTMLElement)) {\n  window.PyViz = {comms: {}, comm_status:{}, kernels:{}, receivers: {}, plot_index: []}\n}\n\n\n    function JupyterCommManager() {\n    }\n\n    JupyterCommManager.prototype.register_target = function(plot_id, comm_id, msg_handler) {\n      if (window.comm_manager || ((window.Jupyter !== undefined) && (Jupyter.notebook.kernel != null))) {\n        var comm_manager = window.comm_manager || Jupyter.notebook.kernel.comm_manager;\n        comm_manager.register_target(comm_id, function(comm) {\n          comm.on_msg(msg_handler);\n        });\n      } else if ((plot_id in window.PyViz.kernels) && (window.PyViz.kernels[plot_id])) {\n        window.PyViz.kernels[plot_id].registerCommTarget(comm_id, function(comm) {\n          comm.onMsg = msg_handler;\n        });\n      } else if (typeof google != 'undefined' && google.colab.kernel != null) {\n        google.colab.kernel.comms.registerTarget(comm_id, (comm) => {\n          var messages = comm.messages[Symbol.asyncIterator]();\n          function processIteratorResult(result) {\n            var message = result.value;\n            console.log(message)\n            var content = {data: message.data, comm_id};\n            var buffers = []\n            for (var buffer of message.buffers || []) {\n              buffers.push(new DataView(buffer))\n            }\n            var metadata = message.metadata || {};\n            var msg = {content, buffers, metadata}\n            msg_handler(msg);\n            return messages.next().then(processIteratorResult);\n          }\n          return messages.next().then(processIteratorResult);\n        })\n      }\n    }\n\n    JupyterCommManager.prototype.get_client_comm = function(plot_id, comm_id, msg_handler) {\n      if (comm_id in window.PyViz.comms) {\n        return window.PyViz.comms[comm_id];\n      } else if (window.comm_manager || ((window.Jupyter !== undefined) && (Jupyter.notebook.kernel != null))) {\n        var comm_manager = window.comm_manager || Jupyter.notebook.kernel.comm_manager;\n        var comm = comm_manager.new_comm(comm_id, {}, {}, {}, comm_id);\n        if (msg_handler) {\n          comm.on_msg(msg_handler);\n        }\n      } else if ((plot_id in window.PyViz.kernels) && (window.PyViz.kernels[plot_id])) {\n        var comm = window.PyViz.kernels[plot_id].connectToComm(comm_id);\n        comm.open();\n        if (msg_handler) {\n          comm.onMsg = msg_handler;\n        }\n      } else if (typeof google != 'undefined' && google.colab.kernel != null) {\n        var comm_promise = google.colab.kernel.comms.open(comm_id)\n        comm_promise.then((comm) => {\n          window.PyViz.comms[comm_id] = comm;\n          if (msg_handler) {\n            var messages = comm.messages[Symbol.asyncIterator]();\n            function processIteratorResult(result) {\n              var message = result.value;\n              var content = {data: message.data};\n              var metadata = message.metadata || {comm_id};\n              var msg = {content, metadata}\n              msg_handler(msg);\n              return messages.next().then(processIteratorResult);\n            }\n            return messages.next().then(processIteratorResult);\n          }\n        }) \n        var sendClosure = (data, metadata, buffers, disposeOnDone) => {\n          return comm_promise.then((comm) => {\n            comm.send(data, metadata, buffers, disposeOnDone);\n          });\n        };\n        var comm = {\n          send: sendClosure\n        };\n      }\n      window.PyViz.comms[comm_id] = comm;\n      return comm;\n    }\n    window.PyViz.comm_manager = new JupyterCommManager();\n    \n\n\nvar JS_MIME_TYPE = 'application/javascript';\nvar HTML_MIME_TYPE = 'text/html';\nvar EXEC_MIME_TYPE = 'application/vnd.holoviews_exec.v0+json';\nvar CLASS_NAME = 'output';\n\n/**\n * Render data to the DOM node\n */\nfunction render(props, node) {\n  var div = document.createElement(\"div\");\n  var script = document.createElement(\"script\");\n  node.appendChild(div);\n  node.appendChild(script);\n}\n\n/**\n * Handle when a new output is added\n */\nfunction handle_add_output(event, handle) {\n  var output_area = handle.output_area;\n  var output = handle.output;\n  if ((output.data == undefined) || (!output.data.hasOwnProperty(EXEC_MIME_TYPE))) {\n    return\n  }\n  var id = output.metadata[EXEC_MIME_TYPE][\"id\"];\n  var toinsert = output_area.element.find(\".\" + CLASS_NAME.split(' ')[0]);\n  if (id !== undefined) {\n    var nchildren = toinsert.length;\n    var html_node = toinsert[nchildren-1].children[0];\n    html_node.innerHTML = output.data[HTML_MIME_TYPE];\n    var scripts = [];\n    var nodelist = html_node.querySelectorAll(\"script\");\n    for (var i in nodelist) {\n      if (nodelist.hasOwnProperty(i)) {\n        scripts.push(nodelist[i])\n      }\n    }\n\n    scripts.forEach( function (oldScript) {\n      var newScript = document.createElement(\"script\");\n      var attrs = [];\n      var nodemap = oldScript.attributes;\n      for (var j in nodemap) {\n        if (nodemap.hasOwnProperty(j)) {\n          attrs.push(nodemap[j])\n        }\n      }\n      attrs.forEach(function(attr) { newScript.setAttribute(attr.name, attr.value) });\n      newScript.appendChild(document.createTextNode(oldScript.innerHTML));\n      oldScript.parentNode.replaceChild(newScript, oldScript);\n    });\n    if (JS_MIME_TYPE in output.data) {\n      toinsert[nchildren-1].children[1].textContent = output.data[JS_MIME_TYPE];\n    }\n    output_area._hv_plot_id = id;\n    if ((window.Bokeh !== undefined) && (id in Bokeh.index)) {\n      window.PyViz.plot_index[id] = Bokeh.index[id];\n    } else {\n      window.PyViz.plot_index[id] = null;\n    }\n  } else if (output.metadata[EXEC_MIME_TYPE][\"server_id\"] !== undefined) {\n    var bk_div = document.createElement(\"div\");\n    bk_div.innerHTML = output.data[HTML_MIME_TYPE];\n    var script_attrs = bk_div.children[0].attributes;\n    for (var i = 0; i < script_attrs.length; i++) {\n      toinsert[toinsert.length - 1].childNodes[1].setAttribute(script_attrs[i].name, script_attrs[i].value);\n    }\n    // store reference to server id on output_area\n    output_area._bokeh_server_id = output.metadata[EXEC_MIME_TYPE][\"server_id\"];\n  }\n}\n\n/**\n * Handle when an output is cleared or removed\n */\nfunction handle_clear_output(event, handle) {\n  var id = handle.cell.output_area._hv_plot_id;\n  var server_id = handle.cell.output_area._bokeh_server_id;\n  if (((id === undefined) || !(id in PyViz.plot_index)) && (server_id !== undefined)) { return; }\n  var comm = window.PyViz.comm_manager.get_client_comm(\"hv-extension-comm\", \"hv-extension-comm\", function () {});\n  if (server_id !== null) {\n    comm.send({event_type: 'server_delete', 'id': server_id});\n    return;\n  } else if (comm !== null) {\n    comm.send({event_type: 'delete', 'id': id});\n  }\n  delete PyViz.plot_index[id];\n  if ((window.Bokeh !== undefined) & (id in window.Bokeh.index)) {\n    var doc = window.Bokeh.index[id].model.document\n    doc.clear();\n    const i = window.Bokeh.documents.indexOf(doc);\n    if (i > -1) {\n      window.Bokeh.documents.splice(i, 1);\n    }\n  }\n}\n\n/**\n * Handle kernel restart event\n */\nfunction handle_kernel_cleanup(event, handle) {\n  delete PyViz.comms[\"hv-extension-comm\"];\n  window.PyViz.plot_index = {}\n}\n\n/**\n * Handle update_display_data messages\n */\nfunction handle_update_output(event, handle) {\n  handle_clear_output(event, {cell: {output_area: handle.output_area}})\n  handle_add_output(event, handle)\n}\n\nfunction register_renderer(events, OutputArea) {\n  function append_mime(data, metadata, element) {\n    // create a DOM node to render to\n    var toinsert = this.create_output_subarea(\n    metadata,\n    CLASS_NAME,\n    EXEC_MIME_TYPE\n    );\n    this.keyboard_manager.register_events(toinsert);\n    // Render to node\n    var props = {data: data, metadata: metadata[EXEC_MIME_TYPE]};\n    render(props, toinsert[0]);\n    element.append(toinsert);\n    return toinsert\n  }\n\n  events.on('output_added.OutputArea', handle_add_output);\n  events.on('output_updated.OutputArea', handle_update_output);\n  events.on('clear_output.CodeCell', handle_clear_output);\n  events.on('delete.Cell', handle_clear_output);\n  events.on('kernel_ready.Kernel', handle_kernel_cleanup);\n\n  OutputArea.prototype.register_mime_type(EXEC_MIME_TYPE, append_mime, {\n    safe: true,\n    index: 0\n  });\n}\n\nif (window.Jupyter !== undefined) {\n  try {\n    var events = require('base/js/events');\n    var OutputArea = require('notebook/js/outputarea').OutputArea;\n    if (OutputArea.prototype.mime_types().indexOf(EXEC_MIME_TYPE) == -1) {\n      register_renderer(events, OutputArea);\n    }\n  } catch(err) {\n  }\n}\n",
      "application/vnd.holoviews_load.v0+json": ""
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>*[data-root-id],\n",
       "*[data-root-id] > * {\n",
       "  box-sizing: border-box;\n",
       "  font-family: var(--jp-ui-font-family);\n",
       "  font-size: var(--jp-ui-font-size1);\n",
       "  color: var(--vscode-editor-foreground, var(--jp-ui-font-color1));\n",
       "}\n",
       "\n",
       "/* Override VSCode background color */\n",
       ".cell-output-ipywidget-background:has(\n",
       "    > .cell-output-ipywidget-background > .lm-Widget > *[data-root-id]\n",
       "  ),\n",
       ".cell-output-ipywidget-background:has(> .lm-Widget > *[data-root-id]) {\n",
       "  background-color: transparent !important;\n",
       "}\n",
       "</style>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.holoviews_exec.v0+json": "",
      "text/html": [
       "<div id='686be88c-4b22-48aa-b470-eed91c7d7832'>\n",
       "  <div id=\"a7ebd951-0ff9-411f-b82d-9b2d78586b7e\" data-root-id=\"686be88c-4b22-48aa-b470-eed91c7d7832\" style=\"display: contents;\"></div>\n",
       "</div>\n",
       "<script type=\"application/javascript\">(function(root) {\n",
       "  var docs_json = {\"2c35c3aa-31ae-4566-bdc9-0ba3a362bb11\":{\"version\":\"3.4.1\",\"title\":\"Bokeh Application\",\"roots\":[{\"type\":\"object\",\"name\":\"panel.models.browser.BrowserInfo\",\"id\":\"686be88c-4b22-48aa-b470-eed91c7d7832\"},{\"type\":\"object\",\"name\":\"panel.models.comm_manager.CommManager\",\"id\":\"5c19d4ca-cdc0-4d0a-8e12-5ac93ee9ac0b\",\"attributes\":{\"plot_id\":\"686be88c-4b22-48aa-b470-eed91c7d7832\",\"comm_id\":\"0863cec740f24c5d87351718a9dcdd4b\",\"client_comm_id\":\"80ae9fc50451459caccb2fee2b310650\"}}],\"defs\":[{\"type\":\"model\",\"name\":\"ReactiveHTML1\"},{\"type\":\"model\",\"name\":\"FlexBox1\",\"properties\":[{\"name\":\"align_content\",\"kind\":\"Any\",\"default\":\"flex-start\"},{\"name\":\"align_items\",\"kind\":\"Any\",\"default\":\"flex-start\"},{\"name\":\"flex_direction\",\"kind\":\"Any\",\"default\":\"row\"},{\"name\":\"flex_wrap\",\"kind\":\"Any\",\"default\":\"wrap\"},{\"name\":\"gap\",\"kind\":\"Any\",\"default\":\"\"},{\"name\":\"justify_content\",\"kind\":\"Any\",\"default\":\"flex-start\"}]},{\"type\":\"model\",\"name\":\"FloatPanel1\",\"properties\":[{\"name\":\"config\",\"kind\":\"Any\",\"default\":{\"type\":\"map\"}},{\"name\":\"contained\",\"kind\":\"Any\",\"default\":true},{\"name\":\"position\",\"kind\":\"Any\",\"default\":\"right-top\"},{\"name\":\"offsetx\",\"kind\":\"Any\",\"default\":null},{\"name\":\"offsety\",\"kind\":\"Any\",\"default\":null},{\"name\":\"theme\",\"kind\":\"Any\",\"default\":\"primary\"},{\"name\":\"status\",\"kind\":\"Any\",\"default\":\"normalized\"}]},{\"type\":\"model\",\"name\":\"GridStack1\",\"properties\":[{\"name\":\"mode\",\"kind\":\"Any\",\"default\":\"warn\"},{\"name\":\"ncols\",\"kind\":\"Any\",\"default\":null},{\"name\":\"nrows\",\"kind\":\"Any\",\"default\":null},{\"name\":\"allow_resize\",\"kind\":\"Any\",\"default\":true},{\"name\":\"allow_drag\",\"kind\":\"Any\",\"default\":true},{\"name\":\"state\",\"kind\":\"Any\",\"default\":[]}]},{\"type\":\"model\",\"name\":\"drag1\",\"properties\":[{\"name\":\"slider_width\",\"kind\":\"Any\",\"default\":5},{\"name\":\"slider_color\",\"kind\":\"Any\",\"default\":\"black\"},{\"name\":\"value\",\"kind\":\"Any\",\"default\":50}]},{\"type\":\"model\",\"name\":\"click1\",\"properties\":[{\"name\":\"terminal_output\",\"kind\":\"Any\",\"default\":\"\"},{\"name\":\"debug_name\",\"kind\":\"Any\",\"default\":\"\"},{\"name\":\"clears\",\"kind\":\"Any\",\"default\":0}]},{\"type\":\"model\",\"name\":\"FastWrapper1\",\"properties\":[{\"name\":\"object\",\"kind\":\"Any\",\"default\":null},{\"name\":\"style\",\"kind\":\"Any\",\"default\":null}]},{\"type\":\"model\",\"name\":\"NotificationAreaBase1\",\"properties\":[{\"name\":\"js_events\",\"kind\":\"Any\",\"default\":{\"type\":\"map\"}},{\"name\":\"position\",\"kind\":\"Any\",\"default\":\"bottom-right\"},{\"name\":\"_clear\",\"kind\":\"Any\",\"default\":0}]},{\"type\":\"model\",\"name\":\"NotificationArea1\",\"properties\":[{\"name\":\"js_events\",\"kind\":\"Any\",\"default\":{\"type\":\"map\"}},{\"name\":\"notifications\",\"kind\":\"Any\",\"default\":[]},{\"name\":\"position\",\"kind\":\"Any\",\"default\":\"bottom-right\"},{\"name\":\"_clear\",\"kind\":\"Any\",\"default\":0},{\"name\":\"types\",\"kind\":\"Any\",\"default\":[{\"type\":\"map\",\"entries\":[[\"type\",\"warning\"],[\"background\",\"#ffc107\"],[\"icon\",{\"type\":\"map\",\"entries\":[[\"className\",\"fas fa-exclamation-triangle\"],[\"tagName\",\"i\"],[\"color\",\"white\"]]}]]},{\"type\":\"map\",\"entries\":[[\"type\",\"info\"],[\"background\",\"#007bff\"],[\"icon\",{\"type\":\"map\",\"entries\":[[\"className\",\"fas fa-info-circle\"],[\"tagName\",\"i\"],[\"color\",\"white\"]]}]]}]}]},{\"type\":\"model\",\"name\":\"Notification\",\"properties\":[{\"name\":\"background\",\"kind\":\"Any\",\"default\":null},{\"name\":\"duration\",\"kind\":\"Any\",\"default\":3000},{\"name\":\"icon\",\"kind\":\"Any\",\"default\":null},{\"name\":\"message\",\"kind\":\"Any\",\"default\":\"\"},{\"name\":\"notification_type\",\"kind\":\"Any\",\"default\":null},{\"name\":\"_destroyed\",\"kind\":\"Any\",\"default\":false}]},{\"type\":\"model\",\"name\":\"TemplateActions1\",\"properties\":[{\"name\":\"open_modal\",\"kind\":\"Any\",\"default\":0},{\"name\":\"close_modal\",\"kind\":\"Any\",\"default\":0}]},{\"type\":\"model\",\"name\":\"BootstrapTemplateActions1\",\"properties\":[{\"name\":\"open_modal\",\"kind\":\"Any\",\"default\":0},{\"name\":\"close_modal\",\"kind\":\"Any\",\"default\":0}]},{\"type\":\"model\",\"name\":\"TemplateEditor1\",\"properties\":[{\"name\":\"layout\",\"kind\":\"Any\",\"default\":[]}]},{\"type\":\"model\",\"name\":\"MaterialTemplateActions1\",\"properties\":[{\"name\":\"open_modal\",\"kind\":\"Any\",\"default\":0},{\"name\":\"close_modal\",\"kind\":\"Any\",\"default\":0}]},{\"type\":\"model\",\"name\":\"copy_to_clipboard1\",\"properties\":[{\"name\":\"fill\",\"kind\":\"Any\",\"default\":\"none\"},{\"name\":\"value\",\"kind\":\"Any\",\"default\":null}]}]}};\n",
       "  var render_items = [{\"docid\":\"2c35c3aa-31ae-4566-bdc9-0ba3a362bb11\",\"roots\":{\"686be88c-4b22-48aa-b470-eed91c7d7832\":\"a7ebd951-0ff9-411f-b82d-9b2d78586b7e\"},\"root_ids\":[\"686be88c-4b22-48aa-b470-eed91c7d7832\"]}];\n",
       "  var docs = Object.values(docs_json)\n",
       "  if (!docs) {\n",
       "    return\n",
       "  }\n",
       "  const py_version = docs[0].version.replace('rc', '-rc.').replace('.dev', '-dev.')\n",
       "  async function embed_document(root) {\n",
       "    var Bokeh = get_bokeh(root)\n",
       "    await Bokeh.embed.embed_items_notebook(docs_json, render_items);\n",
       "    for (const render_item of render_items) {\n",
       "      for (const root_id of render_item.root_ids) {\n",
       "\tconst id_el = document.getElementById(root_id)\n",
       "\tif (id_el.children.length && id_el.children[0].hasAttribute('data-root-id')) {\n",
       "\t  const root_el = id_el.children[0]\n",
       "\t  root_el.id = root_el.id + '-rendered'\n",
       "\t  for (const child of root_el.children) {\n",
       "            // Ensure JupyterLab does not capture keyboard shortcuts\n",
       "            // see: https://jupyterlab.readthedocs.io/en/4.1.x/extension/notebook.html#keyboard-interaction-model\n",
       "\t    child.setAttribute('data-lm-suppress-shortcuts', 'true')\n",
       "\t  }\n",
       "\t}\n",
       "      }\n",
       "    }\n",
       "  }\n",
       "  function get_bokeh(root) {\n",
       "    if (root.Bokeh === undefined) {\n",
       "      return null\n",
       "    } else if (root.Bokeh.version !== py_version) {\n",
       "      if (root.Bokeh.versions === undefined || !root.Bokeh.versions.has(py_version)) {\n",
       "\treturn null\n",
       "      }\n",
       "      return root.Bokeh.versions.get(py_version);\n",
       "    } else if (root.Bokeh.version === py_version) {\n",
       "      return root.Bokeh\n",
       "    }\n",
       "    return null\n",
       "  }\n",
       "  function is_loaded(root) {\n",
       "    var Bokeh = get_bokeh(root)\n",
       "    return (Bokeh != null && Bokeh.Panel !== undefined && ( root.vtk !== undefined) && ( root.vtk !== undefined))\n",
       "  }\n",
       "  if (is_loaded(root)) {\n",
       "    embed_document(root);\n",
       "  } else {\n",
       "    var attempts = 0;\n",
       "    var timer = setInterval(function(root) {\n",
       "      if (is_loaded(root)) {\n",
       "        clearInterval(timer);\n",
       "        embed_document(root);\n",
       "      } else if (document.readyState == \"complete\") {\n",
       "        attempts++;\n",
       "        if (attempts > 200) {\n",
       "          clearInterval(timer);\n",
       "\t  var Bokeh = get_bokeh(root)\n",
       "\t  if (Bokeh == null || Bokeh.Panel == null) {\n",
       "            console.warn(\"Panel: ERROR: Unable to run Panel code because Bokeh or Panel library is missing\");\n",
       "\t  } else {\n",
       "\t    console.warn(\"Panel: WARNING: Attempting to render but not all required libraries could be resolved.\")\n",
       "\t    embed_document(root)\n",
       "\t  }\n",
       "        }\n",
       "      }\n",
       "    }, 25, root)\n",
       "  }\n",
       "})(window);</script>"
      ]
     },
     "metadata": {
      "application/vnd.holoviews_exec.v0+json": {
       "id": "ae981a2b-1086-4d0b-9052-cee4aa9448e4"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import streamlit as st\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pyvista as pv\n",
    "import os\n",
    "import utils\n",
    "from stpyvista import stpyvista\n",
    "from datetime import datetime\n",
    "import importlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(608036, 18)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.concat([pd.read_csv('hka-aqm-am/' + f.removeprefix('._'), skiprows=1, sep=';', engine='python') for f in os.listdir('hka-aqm-am/')])\n",
    "df.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training data cutoff:  2023-07-15 02:45:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Studium\\Semester_6\\IoT_Project\\utils.py:911: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_train[columns_to_scale] = scaler.fit_transform(df_train[columns_to_scale])\n",
      "c:\\Studium\\Semester_6\\IoT_Project\\utils.py:912: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_test[columns_to_scale] = scaler.transform(df_test[columns_to_scale])\n",
      "c:\\Studium\\Semester_6\\IoT_Project\\utils.py:916: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_train.drop(['date_time_rounded'], axis=1, inplace=True)\n",
      "c:\\Studium\\Semester_6\\IoT_Project\\utils.py:917: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_test.drop(['date_time_rounded'], axis=1, inplace=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tmp                         float64\n",
      "hum                         float64\n",
      "CO2                         float64\n",
      "VOC                         float64\n",
      "vis                         float64\n",
      "IR                          float64\n",
      "WIFI                        float64\n",
      "BLE                         float64\n",
      "rssi                        float64\n",
      "channel_rssi                float64\n",
      "channel_index               float64\n",
      "spreading_factor            float64\n",
      "bandwidth                   float64\n",
      "f_cnt                       float64\n",
      "isHoliday                   float64\n",
      "isExamTime                  float64\n",
      "weekday                     float64\n",
      "month                       float64\n",
      "hour_sin                    float64\n",
      "semester_SS23               float64\n",
      "semester_WS22/23            float64\n",
      "semester_WS23/24            float64\n",
      "group                       float64\n",
      "device_id_hka-aqm-am001     float64\n",
      "device_id_hka-aqm-am002     float64\n",
      "device_id_hka-aqm-am003a    float64\n",
      "device_id_hka-aqm-am003b    float64\n",
      "device_id_hka-aqm-am004     float64\n",
      "device_id_hka-aqm-am005     float64\n",
      "device_id_hka-aqm-am107     float64\n",
      "device_id_hka-aqm-am109     float64\n",
      "device_id_hka-aqm-am110     float64\n",
      "device_id_hka-aqm-am111     float64\n",
      "device_id_hka-aqm-am115     float64\n",
      "device_id_hka-aqm-am116     float64\n",
      "device_id_hka-aqm-am117     float64\n",
      "device_id_hka-aqm-am123     float64\n",
      "device_id_hka-aqm-am124     float64\n",
      "device_id_hka-aqm-am126     float64\n",
      "device_id_hka-aqm-am201a    float64\n",
      "device_id_hka-aqm-am201b    float64\n",
      "device_id_hka-aqm-am204     float64\n",
      "device_id_hka-aqm-am205     float64\n",
      "device_id_hka-aqm-am209     float64\n",
      "device_id_hka-aqm-am210     float64\n",
      "device_id_hka-aqm-am211     float64\n",
      "device_id_hka-aqm-am301     float64\n",
      "device_id_hka-aqm-am307     float64\n",
      "device_id_hka-aqm-am308     float64\n",
      "dtype: object\n",
      "feature count:  49\n",
      "feature count:  49\n",
      "Training data shape: torch.Size([244176, 20, 49]) torch.Size([244176, 1])\n",
      "Testing data shape: torch.Size([62745, 20, 49]) torch.Size([62745, 1])\n",
      "same columns\n",
      "date_time_rounded           datetime64[ns]\n",
      "tmp                                float64\n",
      "hum                                float64\n",
      "CO2                                float64\n",
      "VOC                                float64\n",
      "vis                                float64\n",
      "IR                                 float64\n",
      "WIFI                               float64\n",
      "BLE                                float64\n",
      "rssi                               float64\n",
      "channel_rssi                       float64\n",
      "channel_index                      float64\n",
      "spreading_factor                   float64\n",
      "bandwidth                          float64\n",
      "f_cnt                              float64\n",
      "isHoliday                          float64\n",
      "isExamTime                         float64\n",
      "weekday                            float64\n",
      "month                              float64\n",
      "hour_sin                           float64\n",
      "semester_SS23                      float64\n",
      "semester_WS22/23                   float64\n",
      "semester_WS23/24                   float64\n",
      "group                                int32\n",
      "device_id_hka-aqm-am001              uint8\n",
      "device_id_hka-aqm-am002              uint8\n",
      "device_id_hka-aqm-am003a             uint8\n",
      "device_id_hka-aqm-am003b             uint8\n",
      "device_id_hka-aqm-am004              uint8\n",
      "device_id_hka-aqm-am005              uint8\n",
      "device_id_hka-aqm-am107              uint8\n",
      "device_id_hka-aqm-am109              uint8\n",
      "device_id_hka-aqm-am110              uint8\n",
      "device_id_hka-aqm-am111              uint8\n",
      "device_id_hka-aqm-am115              uint8\n",
      "device_id_hka-aqm-am116              uint8\n",
      "device_id_hka-aqm-am117              uint8\n",
      "device_id_hka-aqm-am123              uint8\n",
      "device_id_hka-aqm-am124              uint8\n",
      "device_id_hka-aqm-am126              uint8\n",
      "device_id_hka-aqm-am201a             uint8\n",
      "device_id_hka-aqm-am201b             uint8\n",
      "device_id_hka-aqm-am204              uint8\n",
      "device_id_hka-aqm-am205              uint8\n",
      "device_id_hka-aqm-am209              uint8\n",
      "device_id_hka-aqm-am210              uint8\n",
      "device_id_hka-aqm-am211              uint8\n",
      "device_id_hka-aqm-am301              uint8\n",
      "device_id_hka-aqm-am307              uint8\n",
      "device_id_hka-aqm-am308              uint8\n",
      "dtype: object\n",
      "date_time_rounded           datetime64[ns]\n",
      "tmp                                float64\n",
      "hum                                float64\n",
      "CO2                                float64\n",
      "VOC                                float64\n",
      "vis                                float64\n",
      "IR                                 float64\n",
      "WIFI                               float64\n",
      "BLE                                float64\n",
      "rssi                               float64\n",
      "channel_rssi                       float64\n",
      "channel_index                      float64\n",
      "spreading_factor                   float64\n",
      "bandwidth                          float64\n",
      "f_cnt                              float64\n",
      "isHoliday                          float64\n",
      "isExamTime                         float64\n",
      "weekday                            float64\n",
      "month                              float64\n",
      "hour_sin                           float64\n",
      "semester_SS23                      float64\n",
      "semester_WS22/23                   float64\n",
      "semester_WS23/24                   float64\n",
      "group                                int32\n",
      "device_id_hka-aqm-am001              uint8\n",
      "device_id_hka-aqm-am002              uint8\n",
      "device_id_hka-aqm-am003a             uint8\n",
      "device_id_hka-aqm-am003b             uint8\n",
      "device_id_hka-aqm-am004              uint8\n",
      "device_id_hka-aqm-am005              uint8\n",
      "device_id_hka-aqm-am107              uint8\n",
      "device_id_hka-aqm-am109              uint8\n",
      "device_id_hka-aqm-am110              uint8\n",
      "device_id_hka-aqm-am111              uint8\n",
      "device_id_hka-aqm-am115              uint8\n",
      "device_id_hka-aqm-am116              uint8\n",
      "device_id_hka-aqm-am117              uint8\n",
      "device_id_hka-aqm-am123              uint8\n",
      "device_id_hka-aqm-am124              uint8\n",
      "device_id_hka-aqm-am126              uint8\n",
      "device_id_hka-aqm-am201a             uint8\n",
      "device_id_hka-aqm-am201b             uint8\n",
      "device_id_hka-aqm-am204              uint8\n",
      "device_id_hka-aqm-am205              uint8\n",
      "device_id_hka-aqm-am209              uint8\n",
      "device_id_hka-aqm-am210              uint8\n",
      "device_id_hka-aqm-am211              uint8\n",
      "device_id_hka-aqm-am301              uint8\n",
      "device_id_hka-aqm-am307              uint8\n",
      "device_id_hka-aqm-am308              uint8\n",
      "dtype: object\n",
      "         date_time_rounded        tmp        hum         CO2         VOC  \\\n",
      "382774 2022-10-10 14:45:00  24.373333  47.616667  760.000000  487.666667   \n",
      "382775 2022-10-10 16:00:00  25.310000  43.320000  586.000000  522.000000   \n",
      "382776 2022-10-10 16:30:00  25.360000  44.336667  563.666667  555.000000   \n",
      "382777 2022-10-10 17:00:00  25.570000  44.940000  574.000000  579.000000   \n",
      "382778 2022-10-10 17:15:00  25.530000  45.140000  575.000000  585.000000   \n",
      "...                    ...        ...        ...         ...         ...   \n",
      "545031 2023-09-26 22:30:00  27.360000  37.510000  527.000000  951.000000   \n",
      "545032 2023-09-26 22:45:00  27.380000  37.580000  520.000000  950.000000   \n",
      "545033 2023-09-26 23:15:00  27.350000  37.610000  529.000000  966.000000   \n",
      "545034 2023-09-26 23:30:00  27.340000  37.650000  525.000000  944.000000   \n",
      "545035 2023-09-26 23:45:00  27.330000  37.650000  525.000000  951.000000   \n",
      "\n",
      "          vis         IR      WIFI        BLE  rssi  ...  \\\n",
      "382774  207.0  27.000000  1.666667   2.666667 -64.0  ...   \n",
      "382775  159.0  18.000000  0.000000   0.000000 -61.0  ...   \n",
      "382776  115.0  12.666667  1.000000   2.000000 -59.0  ...   \n",
      "382777  157.0  16.000000  0.000000   0.000000 -55.0  ...   \n",
      "382778  155.0  16.000000  0.000000   0.000000 -59.0  ...   \n",
      "...       ...        ...       ...        ...   ...  ...   \n",
      "545031    4.0   1.000000  2.000000   0.000000 -73.0  ...   \n",
      "545032    7.0   3.000000  2.000000   0.000000 -73.0  ...   \n",
      "545033    4.0   0.000000  6.000000  27.000000 -75.0  ...   \n",
      "545034    4.0   0.000000  0.000000   0.000000 -75.0  ...   \n",
      "545035    4.0   0.000000  0.000000   0.000000 -70.0  ...   \n",
      "\n",
      "        device_id_hka-aqm-am201a  device_id_hka-aqm-am201b  \\\n",
      "382774                         0                         0   \n",
      "382775                         0                         0   \n",
      "382776                         0                         0   \n",
      "382777                         0                         0   \n",
      "382778                         0                         0   \n",
      "...                          ...                       ...   \n",
      "545031                         0                         0   \n",
      "545032                         0                         0   \n",
      "545033                         0                         0   \n",
      "545034                         0                         0   \n",
      "545035                         0                         0   \n",
      "\n",
      "        device_id_hka-aqm-am204  device_id_hka-aqm-am205  \\\n",
      "382774                        0                        0   \n",
      "382775                        0                        0   \n",
      "382776                        0                        0   \n",
      "382777                        0                        0   \n",
      "382778                        0                        0   \n",
      "...                         ...                      ...   \n",
      "545031                        0                        0   \n",
      "545032                        0                        0   \n",
      "545033                        0                        0   \n",
      "545034                        0                        0   \n",
      "545035                        0                        0   \n",
      "\n",
      "        device_id_hka-aqm-am209  device_id_hka-aqm-am210  \\\n",
      "382774                        0                        0   \n",
      "382775                        0                        0   \n",
      "382776                        0                        0   \n",
      "382777                        0                        0   \n",
      "382778                        0                        0   \n",
      "...                         ...                      ...   \n",
      "545031                        0                        0   \n",
      "545032                        0                        0   \n",
      "545033                        0                        0   \n",
      "545034                        0                        0   \n",
      "545035                        0                        0   \n",
      "\n",
      "        device_id_hka-aqm-am211  device_id_hka-aqm-am301  \\\n",
      "382774                        0                        0   \n",
      "382775                        0                        0   \n",
      "382776                        0                        0   \n",
      "382777                        0                        0   \n",
      "382778                        0                        0   \n",
      "...                         ...                      ...   \n",
      "545031                        0                        0   \n",
      "545032                        0                        0   \n",
      "545033                        0                        0   \n",
      "545034                        0                        0   \n",
      "545035                        0                        0   \n",
      "\n",
      "        device_id_hka-aqm-am307  device_id_hka-aqm-am308  \n",
      "382774                        0                        0  \n",
      "382775                        0                        0  \n",
      "382776                        0                        0  \n",
      "382777                        0                        0  \n",
      "382778                        0                        0  \n",
      "...                         ...                      ...  \n",
      "545031                        0                        1  \n",
      "545032                        0                        1  \n",
      "545033                        0                        1  \n",
      "545034                        0                        1  \n",
      "545035                        0                        1  \n",
      "\n",
      "[162262 rows x 50 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\t-ehm\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\transformer.py:286: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
      "c:\\Users\\t-ehm\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\optim\\lr_scheduler.py:28: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\"The verbose parameter is deprecated. Please use get_last_lr() \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         actual   predicted\n",
      "0    466.999999  507.917490\n",
      "1    455.999999  511.247045\n",
      "2    455.999999  497.097126\n",
      "3    437.999999  491.931977\n",
      "4    435.000001  467.129341\n",
      "..          ...         ...\n",
      "507  449.000001  452.418577\n",
      "508  445.000002  460.463943\n",
      "509  457.999999  459.616637\n",
      "510  441.999999  473.774526\n",
      "511  444.000001  461.024506\n",
      "\n",
      "[512 rows x 2 columns]\n",
      "Epoch 1/20, Training Loss: 0.3396\n",
      "Epoch 1/20, Validation Loss: 0.0724\n",
      "         actual   predicted\n",
      "0    466.999999  514.766013\n",
      "1    455.999999  511.370191\n",
      "2    455.999999  495.964425\n",
      "3    437.999999  487.313577\n",
      "4    435.000001  468.542723\n",
      "..          ...         ...\n",
      "507  449.000001  474.936236\n",
      "508  445.000002  477.902228\n",
      "509  457.999999  475.026242\n",
      "510  441.999999  486.233993\n",
      "511  444.000001  474.150770\n",
      "\n",
      "[512 rows x 2 columns]\n",
      "Epoch 2/20, Training Loss: 0.2429\n",
      "Epoch 2/20, Validation Loss: 0.1063\n",
      "         actual   predicted\n",
      "0    466.999999  475.073285\n",
      "1    455.999999  474.116854\n",
      "2    455.999999  462.390160\n",
      "3    437.999999  455.989527\n",
      "4    435.000001  438.907573\n",
      "..          ...         ...\n",
      "507  449.000001  451.298979\n",
      "508  445.000002  454.895498\n",
      "509  457.999999  451.837325\n",
      "510  441.999999  465.659453\n",
      "511  444.000001  450.520177\n",
      "\n",
      "[512 rows x 2 columns]\n",
      "Epoch 3/20, Training Loss: 0.2196\n",
      "Epoch 3/20, Validation Loss: 0.0849\n",
      "         actual   predicted\n",
      "0    466.999999  510.680084\n",
      "1    455.999999  511.983311\n",
      "2    455.999999  501.308222\n",
      "3    437.999999  492.628977\n",
      "4    435.000001  472.884622\n",
      "..          ...         ...\n",
      "507  449.000001  469.442853\n",
      "508  445.000002  471.096748\n",
      "509  457.999999  468.360247\n",
      "510  441.999999  482.283163\n",
      "511  444.000001  468.835218\n",
      "\n",
      "[512 rows x 2 columns]\n",
      "Epoch 4/20, Training Loss: 0.2051\n",
      "Epoch 4/20, Validation Loss: 0.0897\n",
      "         actual   predicted\n",
      "0    466.999999  502.853801\n",
      "1    455.999999  502.078917\n",
      "2    455.999999  485.314875\n",
      "3    437.999999  483.392934\n",
      "4    435.000001  458.471750\n",
      "..          ...         ...\n",
      "507  449.000001  456.459888\n",
      "508  445.000002  458.753160\n",
      "509  457.999999  450.675938\n",
      "510  441.999999  467.000483\n",
      "511  444.000001  450.329318\n",
      "\n",
      "[512 rows x 2 columns]\n",
      "Epoch 5/20, Training Loss: 0.1918\n",
      "Epoch 5/20, Validation Loss: 0.0698\n",
      "         actual   predicted\n",
      "0    466.999999  519.948311\n",
      "1    455.999999  518.169976\n",
      "2    455.999999  499.897312\n",
      "3    437.999999  497.151823\n",
      "4    435.000001  468.431395\n",
      "..          ...         ...\n",
      "507  449.000001  471.459150\n",
      "508  445.000002  474.768254\n",
      "509  457.999999  467.259866\n",
      "510  441.999999  485.628774\n",
      "511  444.000001  464.097284\n",
      "\n",
      "[512 rows x 2 columns]\n",
      "Epoch 6/20, Training Loss: 0.1751\n",
      "Epoch 6/20, Validation Loss: 0.0957\n",
      "         actual   predicted\n",
      "0    466.999999  486.385677\n",
      "1    455.999999  487.728027\n",
      "2    455.999999  477.177448\n",
      "3    437.999999  473.027739\n",
      "4    435.000001  452.815184\n",
      "..          ...         ...\n",
      "507  449.000001  452.950768\n",
      "508  445.000002  459.891549\n",
      "509  457.999999  457.235943\n",
      "510  441.999999  471.176898\n",
      "511  444.000001  453.775816\n",
      "\n",
      "[512 rows x 2 columns]\n",
      "Epoch 7/20, Training Loss: 0.1692\n",
      "Epoch 7/20, Validation Loss: 0.0699\n",
      "         actual   predicted\n",
      "0    466.999999  488.503694\n",
      "1    455.999999  490.498965\n",
      "2    455.999999  479.114329\n",
      "3    437.999999  479.482952\n",
      "4    435.000001  456.782621\n",
      "..          ...         ...\n",
      "507  449.000001  458.487467\n",
      "508  445.000002  464.937241\n",
      "509  457.999999  460.753643\n",
      "510  441.999999  478.342174\n",
      "511  444.000001  460.004907\n",
      "\n",
      "[512 rows x 2 columns]\n",
      "Epoch 8/20, Training Loss: 0.1557\n",
      "Epoch 8/20, Validation Loss: 0.0669\n",
      "         actual   predicted\n",
      "0    466.999999  490.837102\n",
      "1    455.999999  492.896468\n",
      "2    455.999999  482.086706\n",
      "3    437.999999  477.630299\n",
      "4    435.000001  457.370145\n",
      "..          ...         ...\n",
      "507  449.000001  452.427948\n",
      "508  445.000002  459.377896\n",
      "509  457.999999  456.292319\n",
      "510  441.999999  470.780040\n",
      "511  444.000001  452.445761\n",
      "\n",
      "[512 rows x 2 columns]\n",
      "Epoch 9/20, Training Loss: 0.1432\n",
      "Epoch 9/20, Validation Loss: 0.0551\n",
      "         actual   predicted\n",
      "0    466.999999  494.223023\n",
      "1    455.999999  495.630800\n",
      "2    455.999999  481.574124\n",
      "3    437.999999  481.385736\n",
      "4    435.000001  459.676601\n",
      "..          ...         ...\n",
      "507  449.000001  460.774592\n",
      "508  445.000002  468.578433\n",
      "509  457.999999  461.367905\n",
      "510  441.999999  480.527155\n",
      "511  444.000001  459.099832\n",
      "\n",
      "[512 rows x 2 columns]\n",
      "Epoch 10/20, Training Loss: 0.1416\n",
      "Epoch 10/20, Validation Loss: 0.0659\n",
      "         actual   predicted\n",
      "0    466.999999  500.565753\n",
      "1    455.999999  501.408696\n",
      "2    455.999999  488.762558\n",
      "3    437.999999  488.579384\n",
      "4    435.000001  466.029135\n",
      "..          ...         ...\n",
      "507  449.000001  465.266695\n",
      "508  445.000002  472.484623\n",
      "509  457.999999  466.858191\n",
      "510  441.999999  485.531437\n",
      "511  444.000001  464.185031\n",
      "\n",
      "[512 rows x 2 columns]\n",
      "Epoch 11/20, Training Loss: 0.1315\n",
      "Epoch 11/20, Validation Loss: 0.0657\n",
      "         actual   predicted\n",
      "0    466.999999  490.258628\n",
      "1    455.999999  492.049548\n",
      "2    455.999999  480.191853\n",
      "3    437.999999  480.082920\n",
      "4    435.000001  458.220971\n",
      "..          ...         ...\n",
      "507  449.000001  454.049055\n",
      "508  445.000002  460.175677\n",
      "509  457.999999  455.392848\n",
      "510  441.999999  471.921213\n",
      "511  444.000001  452.271721\n",
      "\n",
      "[512 rows x 2 columns]\n",
      "Epoch 12/20, Training Loss: 0.1302\n",
      "Epoch 12/20, Validation Loss: 0.0552\n",
      "         actual   predicted\n",
      "0    466.999999  482.387421\n",
      "1    455.999999  483.492679\n",
      "2    455.999999  472.885283\n",
      "3    437.999999  472.128469\n",
      "4    435.000001  454.730195\n",
      "..          ...         ...\n",
      "507  449.000001  451.675784\n",
      "508  445.000002  457.482399\n",
      "509  457.999999  453.837810\n",
      "510  441.999999  468.671976\n",
      "511  444.000001  450.824037\n",
      "\n",
      "[512 rows x 2 columns]\n",
      "Epoch 13/20, Training Loss: 0.1223\n",
      "Epoch 13/20, Validation Loss: 0.0595\n",
      "         actual   predicted\n",
      "0    466.999999  484.512375\n",
      "1    455.999999  485.451821\n",
      "2    455.999999  474.706286\n",
      "3    437.999999  474.131341\n",
      "4    435.000001  456.656538\n",
      "..          ...         ...\n",
      "507  449.000001  456.605332\n",
      "508  445.000002  462.310216\n",
      "509  457.999999  458.450262\n",
      "510  441.999999  474.072718\n",
      "511  444.000001  456.217420\n",
      "\n",
      "[512 rows x 2 columns]\n",
      "Epoch 14/20, Training Loss: 0.1132\n",
      "Epoch 14/20, Validation Loss: 0.0534\n",
      "         actual   predicted\n",
      "0    466.999999  474.812259\n",
      "1    455.999999  475.406626\n",
      "2    455.999999  465.473978\n",
      "3    437.999999  466.055063\n",
      "4    435.000001  450.722272\n",
      "..          ...         ...\n",
      "507  449.000001  452.060247\n",
      "508  445.000002  457.848211\n",
      "509  457.999999  453.216183\n",
      "510  441.999999  468.474806\n",
      "511  444.000001  452.347007\n",
      "\n",
      "[512 rows x 2 columns]\n",
      "Epoch 15/20, Training Loss: 0.1051\n",
      "Epoch 15/20, Validation Loss: 0.0476\n",
      "         actual   predicted\n",
      "0    466.999999  476.171688\n",
      "1    455.999999  478.426663\n",
      "2    455.999999  467.676349\n",
      "3    437.999999  467.738482\n",
      "4    435.000001  448.905339\n",
      "..          ...         ...\n",
      "507  449.000001  445.351163\n",
      "508  445.000002  451.502695\n",
      "509  457.999999  447.819346\n",
      "510  441.999999  464.167048\n",
      "511  444.000001  446.137029\n",
      "\n",
      "[512 rows x 2 columns]\n",
      "Epoch 16/20, Training Loss: 0.1055\n",
      "Epoch 16/20, Validation Loss: 0.0408\n",
      "         actual   predicted\n",
      "0    466.999999  480.732690\n",
      "1    455.999999  482.389982\n",
      "2    455.999999  471.486281\n",
      "3    437.999999  470.612748\n",
      "4    435.000001  452.397199\n",
      "..          ...         ...\n",
      "507  449.000001  448.813809\n",
      "508  445.000002  454.731960\n",
      "509  457.999999  451.905400\n",
      "510  441.999999  466.717879\n",
      "511  444.000001  449.178149\n",
      "\n",
      "[512 rows x 2 columns]\n",
      "Epoch 17/20, Training Loss: 0.1015\n",
      "Epoch 17/20, Validation Loss: 0.0411\n",
      "         actual   predicted\n",
      "0    466.999999  484.383013\n",
      "1    455.999999  486.189940\n",
      "2    455.999999  478.094203\n",
      "3    437.999999  475.923517\n",
      "4    435.000001  459.794472\n",
      "..          ...         ...\n",
      "507  449.000001  458.989997\n",
      "508  445.000002  464.214321\n",
      "509  457.999999  462.925566\n",
      "510  441.999999  475.346456\n",
      "511  444.000001  459.947138\n",
      "\n",
      "[512 rows x 2 columns]\n",
      "Epoch 18/20, Training Loss: 0.0976\n",
      "Epoch 18/20, Validation Loss: 0.0531\n",
      "         actual   predicted\n",
      "0    466.999999  479.927129\n",
      "1    455.999999  481.204421\n",
      "2    455.999999  470.577574\n",
      "3    437.999999  469.833213\n",
      "4    435.000001  450.678411\n",
      "..          ...         ...\n",
      "507  449.000001  450.328004\n",
      "508  445.000002  456.865701\n",
      "509  457.999999  453.415763\n",
      "510  441.999999  470.131602\n",
      "511  444.000001  451.598605\n",
      "\n",
      "[512 rows x 2 columns]\n",
      "Epoch 19/20, Training Loss: 0.0914\n",
      "Epoch 19/20, Validation Loss: 0.0407\n",
      "         actual   predicted\n",
      "0    466.999999  475.093713\n",
      "1    455.999999  477.883882\n",
      "2    455.999999  467.911879\n",
      "3    437.999999  466.085721\n",
      "4    435.000001  447.916665\n",
      "..          ...         ...\n",
      "507  449.000001  445.656394\n",
      "508  445.000002  452.123772\n",
      "509  457.999999  449.427658\n",
      "510  441.999999  463.966225\n",
      "511  444.000001  446.686289\n",
      "\n",
      "[512 rows x 2 columns]\n",
      "Epoch 20/20, Training Loss: 0.0894\n",
      "Epoch 20/20, Validation Loss: 0.0369\n",
      "           actual   predicted\n",
      "0      466.999999  475.093713\n",
      "1      455.999999  477.883882\n",
      "2      455.999999  467.911879\n",
      "3      437.999999  466.085721\n",
      "4      435.000001  447.916665\n",
      "...           ...         ...\n",
      "62740  520.000000  546.888798\n",
      "62741  529.000000  540.289928\n",
      "62742  529.000000  549.721379\n",
      "62743  525.000001  554.874888\n",
      "62744  525.000001  546.579254\n",
      "\n",
      "[62745 rows x 2 columns]\n",
      "Score (RMSE): 26.7755\n",
      "Score (MAE): 19.1476\n",
      "Score (MAPE): 4.1775%\n",
      "training data cutoff:  2023-07-15 02:45:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Studium\\Semester_6\\IoT_Project\\utils.py:911: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_train[columns_to_scale] = scaler.fit_transform(df_train[columns_to_scale])\n",
      "c:\\Studium\\Semester_6\\IoT_Project\\utils.py:912: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_test[columns_to_scale] = scaler.transform(df_test[columns_to_scale])\n",
      "c:\\Studium\\Semester_6\\IoT_Project\\utils.py:916: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_train.drop(['date_time_rounded'], axis=1, inplace=True)\n",
      "c:\\Studium\\Semester_6\\IoT_Project\\utils.py:917: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_test.drop(['date_time_rounded'], axis=1, inplace=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tmp                         float64\n",
      "hum                         float64\n",
      "CO2                         float64\n",
      "VOC                         float64\n",
      "vis                         float64\n",
      "IR                          float64\n",
      "WIFI                        float64\n",
      "BLE                         float64\n",
      "rssi                        float64\n",
      "channel_rssi                float64\n",
      "channel_index               float64\n",
      "spreading_factor            float64\n",
      "bandwidth                   float64\n",
      "f_cnt                       float64\n",
      "isHoliday                   float64\n",
      "isExamTime                  float64\n",
      "weekday                     float64\n",
      "month                       float64\n",
      "hour_sin                    float64\n",
      "semester_SS23               float64\n",
      "semester_WS22/23            float64\n",
      "semester_WS23/24            float64\n",
      "group                       float64\n",
      "device_id_hka-aqm-am001     float64\n",
      "device_id_hka-aqm-am002     float64\n",
      "device_id_hka-aqm-am003a    float64\n",
      "device_id_hka-aqm-am003b    float64\n",
      "device_id_hka-aqm-am004     float64\n",
      "device_id_hka-aqm-am005     float64\n",
      "device_id_hka-aqm-am107     float64\n",
      "device_id_hka-aqm-am109     float64\n",
      "device_id_hka-aqm-am110     float64\n",
      "device_id_hka-aqm-am111     float64\n",
      "device_id_hka-aqm-am115     float64\n",
      "device_id_hka-aqm-am116     float64\n",
      "device_id_hka-aqm-am117     float64\n",
      "device_id_hka-aqm-am123     float64\n",
      "device_id_hka-aqm-am124     float64\n",
      "device_id_hka-aqm-am126     float64\n",
      "device_id_hka-aqm-am201a    float64\n",
      "device_id_hka-aqm-am201b    float64\n",
      "device_id_hka-aqm-am204     float64\n",
      "device_id_hka-aqm-am205     float64\n",
      "device_id_hka-aqm-am209     float64\n",
      "device_id_hka-aqm-am210     float64\n",
      "device_id_hka-aqm-am211     float64\n",
      "device_id_hka-aqm-am301     float64\n",
      "device_id_hka-aqm-am307     float64\n",
      "device_id_hka-aqm-am308     float64\n",
      "dtype: object\n",
      "feature count:  49\n",
      "feature count:  49\n",
      "Training data shape: torch.Size([244176, 20, 49]) torch.Size([244176, 1])\n",
      "Testing data shape: torch.Size([62745, 20, 49]) torch.Size([62745, 1])\n",
      "same columns\n",
      "date_time_rounded           datetime64[ns]\n",
      "tmp                                float64\n",
      "hum                                float64\n",
      "CO2                                float64\n",
      "VOC                                float64\n",
      "vis                                float64\n",
      "IR                                 float64\n",
      "WIFI                               float64\n",
      "BLE                                float64\n",
      "rssi                               float64\n",
      "channel_rssi                       float64\n",
      "channel_index                      float64\n",
      "spreading_factor                   float64\n",
      "bandwidth                          float64\n",
      "f_cnt                              float64\n",
      "isHoliday                          float64\n",
      "isExamTime                         float64\n",
      "weekday                            float64\n",
      "month                              float64\n",
      "hour_sin                           float64\n",
      "semester_SS23                      float64\n",
      "semester_WS22/23                   float64\n",
      "semester_WS23/24                   float64\n",
      "group                                int32\n",
      "device_id_hka-aqm-am001              uint8\n",
      "device_id_hka-aqm-am002              uint8\n",
      "device_id_hka-aqm-am003a             uint8\n",
      "device_id_hka-aqm-am003b             uint8\n",
      "device_id_hka-aqm-am004              uint8\n",
      "device_id_hka-aqm-am005              uint8\n",
      "device_id_hka-aqm-am107              uint8\n",
      "device_id_hka-aqm-am109              uint8\n",
      "device_id_hka-aqm-am110              uint8\n",
      "device_id_hka-aqm-am111              uint8\n",
      "device_id_hka-aqm-am115              uint8\n",
      "device_id_hka-aqm-am116              uint8\n",
      "device_id_hka-aqm-am117              uint8\n",
      "device_id_hka-aqm-am123              uint8\n",
      "device_id_hka-aqm-am124              uint8\n",
      "device_id_hka-aqm-am126              uint8\n",
      "device_id_hka-aqm-am201a             uint8\n",
      "device_id_hka-aqm-am201b             uint8\n",
      "device_id_hka-aqm-am204              uint8\n",
      "device_id_hka-aqm-am205              uint8\n",
      "device_id_hka-aqm-am209              uint8\n",
      "device_id_hka-aqm-am210              uint8\n",
      "device_id_hka-aqm-am211              uint8\n",
      "device_id_hka-aqm-am301              uint8\n",
      "device_id_hka-aqm-am307              uint8\n",
      "device_id_hka-aqm-am308              uint8\n",
      "dtype: object\n",
      "date_time_rounded           datetime64[ns]\n",
      "tmp                                float64\n",
      "hum                                float64\n",
      "CO2                                float64\n",
      "VOC                                float64\n",
      "vis                                float64\n",
      "IR                                 float64\n",
      "WIFI                               float64\n",
      "BLE                                float64\n",
      "rssi                               float64\n",
      "channel_rssi                       float64\n",
      "channel_index                      float64\n",
      "spreading_factor                   float64\n",
      "bandwidth                          float64\n",
      "f_cnt                              float64\n",
      "isHoliday                          float64\n",
      "isExamTime                         float64\n",
      "weekday                            float64\n",
      "month                              float64\n",
      "hour_sin                           float64\n",
      "semester_SS23                      float64\n",
      "semester_WS22/23                   float64\n",
      "semester_WS23/24                   float64\n",
      "group                                int32\n",
      "device_id_hka-aqm-am001              uint8\n",
      "device_id_hka-aqm-am002              uint8\n",
      "device_id_hka-aqm-am003a             uint8\n",
      "device_id_hka-aqm-am003b             uint8\n",
      "device_id_hka-aqm-am004              uint8\n",
      "device_id_hka-aqm-am005              uint8\n",
      "device_id_hka-aqm-am107              uint8\n",
      "device_id_hka-aqm-am109              uint8\n",
      "device_id_hka-aqm-am110              uint8\n",
      "device_id_hka-aqm-am111              uint8\n",
      "device_id_hka-aqm-am115              uint8\n",
      "device_id_hka-aqm-am116              uint8\n",
      "device_id_hka-aqm-am117              uint8\n",
      "device_id_hka-aqm-am123              uint8\n",
      "device_id_hka-aqm-am124              uint8\n",
      "device_id_hka-aqm-am126              uint8\n",
      "device_id_hka-aqm-am201a             uint8\n",
      "device_id_hka-aqm-am201b             uint8\n",
      "device_id_hka-aqm-am204              uint8\n",
      "device_id_hka-aqm-am205              uint8\n",
      "device_id_hka-aqm-am209              uint8\n",
      "device_id_hka-aqm-am210              uint8\n",
      "device_id_hka-aqm-am211              uint8\n",
      "device_id_hka-aqm-am301              uint8\n",
      "device_id_hka-aqm-am307              uint8\n",
      "device_id_hka-aqm-am308              uint8\n",
      "dtype: object\n",
      "         date_time_rounded        tmp        hum         CO2         VOC  \\\n",
      "382774 2022-10-10 14:45:00  24.373333  47.616667  760.000000  487.666667   \n",
      "382775 2022-10-10 16:30:00  25.360000  44.336667  563.666667  555.000000   \n",
      "382776 2022-10-10 17:00:00  25.570000  44.940000  574.000000  579.000000   \n",
      "382777 2022-10-10 17:15:00  25.530000  45.140000  575.000000  585.000000   \n",
      "382778 2022-10-10 17:45:00  25.480000  46.590000  586.000000  620.000000   \n",
      "...                    ...        ...        ...         ...         ...   \n",
      "529479 2023-09-26 22:30:00  27.360000  37.510000  527.000000  951.000000   \n",
      "529480 2023-09-26 22:45:00  27.380000  37.580000  520.000000  950.000000   \n",
      "529481 2023-09-26 23:15:00  27.350000  37.610000  529.000000  966.000000   \n",
      "529482 2023-09-26 23:30:00  27.340000  37.650000  525.000000  944.000000   \n",
      "529483 2023-09-26 23:45:00  27.330000  37.650000  525.000000  951.000000   \n",
      "\n",
      "          vis         IR      WIFI        BLE  rssi  ...  \\\n",
      "382774  207.0  27.000000  1.666667   2.666667 -64.0  ...   \n",
      "382775  115.0  12.666667  1.000000   2.000000 -59.0  ...   \n",
      "382776  157.0  16.000000  0.000000   0.000000 -55.0  ...   \n",
      "382777  155.0  16.000000  0.000000   0.000000 -59.0  ...   \n",
      "382778  157.0  18.000000  0.000000   0.000000 -60.0  ...   \n",
      "...       ...        ...       ...        ...   ...  ...   \n",
      "529479    4.0   1.000000  2.000000   0.000000 -73.0  ...   \n",
      "529480    7.0   3.000000  2.000000   0.000000 -73.0  ...   \n",
      "529481    4.0   0.000000  6.000000  27.000000 -75.0  ...   \n",
      "529482    4.0   0.000000  0.000000   0.000000 -75.0  ...   \n",
      "529483    4.0   0.000000  0.000000   0.000000 -70.0  ...   \n",
      "\n",
      "        device_id_hka-aqm-am201a  device_id_hka-aqm-am201b  \\\n",
      "382774                         0                         0   \n",
      "382775                         0                         0   \n",
      "382776                         0                         0   \n",
      "382777                         0                         0   \n",
      "382778                         0                         0   \n",
      "...                          ...                       ...   \n",
      "529479                         0                         0   \n",
      "529480                         0                         0   \n",
      "529481                         0                         0   \n",
      "529482                         0                         0   \n",
      "529483                         0                         0   \n",
      "\n",
      "        device_id_hka-aqm-am204  device_id_hka-aqm-am205  \\\n",
      "382774                        0                        0   \n",
      "382775                        0                        0   \n",
      "382776                        0                        0   \n",
      "382777                        0                        0   \n",
      "382778                        0                        0   \n",
      "...                         ...                      ...   \n",
      "529479                        0                        0   \n",
      "529480                        0                        0   \n",
      "529481                        0                        0   \n",
      "529482                        0                        0   \n",
      "529483                        0                        0   \n",
      "\n",
      "        device_id_hka-aqm-am209  device_id_hka-aqm-am210  \\\n",
      "382774                        0                        0   \n",
      "382775                        0                        0   \n",
      "382776                        0                        0   \n",
      "382777                        0                        0   \n",
      "382778                        0                        0   \n",
      "...                         ...                      ...   \n",
      "529479                        0                        0   \n",
      "529480                        0                        0   \n",
      "529481                        0                        0   \n",
      "529482                        0                        0   \n",
      "529483                        0                        0   \n",
      "\n",
      "        device_id_hka-aqm-am211  device_id_hka-aqm-am301  \\\n",
      "382774                        0                        0   \n",
      "382775                        0                        0   \n",
      "382776                        0                        0   \n",
      "382777                        0                        0   \n",
      "382778                        0                        0   \n",
      "...                         ...                      ...   \n",
      "529479                        0                        0   \n",
      "529480                        0                        0   \n",
      "529481                        0                        0   \n",
      "529482                        0                        0   \n",
      "529483                        0                        0   \n",
      "\n",
      "        device_id_hka-aqm-am307  device_id_hka-aqm-am308  \n",
      "382774                        0                        0  \n",
      "382775                        0                        0  \n",
      "382776                        0                        0  \n",
      "382777                        0                        0  \n",
      "382778                        0                        0  \n",
      "...                         ...                      ...  \n",
      "529479                        0                        1  \n",
      "529480                        0                        1  \n",
      "529481                        0                        1  \n",
      "529482                        0                        1  \n",
      "529483                        0                        1  \n",
      "\n",
      "[146710 rows x 50 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\t-ehm\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\transformer.py:286: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
      "c:\\Users\\t-ehm\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\optim\\lr_scheduler.py:28: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\"The verbose parameter is deprecated. Please use get_last_lr() \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     actual  predicted\n",
      "0     45.49  39.383798\n",
      "1     45.01  41.031854\n",
      "2     44.88  40.033061\n",
      "3     44.84  39.558371\n",
      "4     45.36  38.371148\n",
      "..      ...        ...\n",
      "507   48.32  42.478060\n",
      "508   48.00  42.484023\n",
      "509   47.68  42.227448\n",
      "510   47.68  42.459135\n",
      "511   47.81  42.055908\n",
      "\n",
      "[512 rows x 2 columns]\n",
      "Epoch 1/20, Training Loss: 0.1342\n",
      "Epoch 1/20, Validation Loss: 0.6005\n",
      "     actual  predicted\n",
      "0     45.49  43.348831\n",
      "1     45.01  45.200762\n",
      "2     44.88  44.321886\n",
      "3     44.84  43.757006\n",
      "4     45.36  42.673203\n",
      "..      ...        ...\n",
      "507   48.32  46.877629\n",
      "508   48.00  46.700777\n",
      "509   47.68  46.906944\n",
      "510   47.68  46.899269\n",
      "511   47.81  46.802118\n",
      "\n",
      "[512 rows x 2 columns]\n",
      "Epoch 2/20, Training Loss: 0.0268\n",
      "Epoch 2/20, Validation Loss: 0.1264\n",
      "     actual  predicted\n",
      "0     45.49  43.229552\n",
      "1     45.01  44.757822\n",
      "2     44.88  43.696754\n",
      "3     44.84  43.596156\n",
      "4     45.36  42.620873\n",
      "..      ...        ...\n",
      "507   48.32  45.922762\n",
      "508   48.00  45.600496\n",
      "509   47.68  45.381485\n",
      "510   47.68  45.560036\n",
      "511   47.81  45.325079\n",
      "\n",
      "[512 rows x 2 columns]\n",
      "Epoch 3/20, Training Loss: 0.0179\n",
      "Epoch 3/20, Validation Loss: 0.1319\n",
      "     actual  predicted\n",
      "0     45.49  43.212809\n",
      "1     45.01  44.734655\n",
      "2     44.88  43.820093\n",
      "3     44.84  43.459856\n",
      "4     45.36  42.575060\n",
      "..      ...        ...\n",
      "507   48.32  46.586662\n",
      "508   48.00  46.463132\n",
      "509   47.68  46.422515\n",
      "510   47.68  46.588507\n",
      "511   47.81  46.373595\n",
      "\n",
      "[512 rows x 2 columns]\n",
      "Epoch 4/20, Training Loss: 0.0128\n",
      "Epoch 4/20, Validation Loss: 0.1048\n",
      "     actual  predicted\n",
      "0     45.49  43.708892\n",
      "1     45.01  44.941575\n",
      "2     44.88  44.080254\n",
      "3     44.84  43.595169\n",
      "4     45.36  42.982868\n",
      "..      ...        ...\n",
      "507   48.32  45.943273\n",
      "508   48.00  45.636596\n",
      "509   47.68  45.661977\n",
      "510   47.68  45.713813\n",
      "511   47.81  45.670363\n",
      "\n",
      "[512 rows x 2 columns]\n",
      "Epoch 5/20, Training Loss: 0.0105\n",
      "Epoch 5/20, Validation Loss: 0.1372\n",
      "     actual  predicted\n",
      "0     45.49  44.713108\n",
      "1     45.01  45.901975\n",
      "2     44.88  45.075721\n",
      "3     44.84  44.618439\n",
      "4     45.36  44.190889\n",
      "..      ...        ...\n",
      "507   48.32  47.015748\n",
      "508   48.00  47.001406\n",
      "509   47.68  46.997838\n",
      "510   47.68  46.894604\n",
      "511   47.81  46.586641\n",
      "\n",
      "[512 rows x 2 columns]\n",
      "Epoch 6/20, Training Loss: 0.0091\n",
      "Epoch 6/20, Validation Loss: 0.0670\n",
      "     actual  predicted\n",
      "0     45.49  44.758242\n",
      "1     45.01  46.143585\n",
      "2     44.88  45.524764\n",
      "3     44.84  45.251269\n",
      "4     45.36  44.774755\n",
      "..      ...        ...\n",
      "507   48.32  46.628975\n",
      "508   48.00  46.455692\n",
      "509   47.68  46.525208\n",
      "510   47.68  46.485786\n",
      "511   47.81  46.225898\n",
      "\n",
      "[512 rows x 2 columns]\n",
      "Epoch 7/20, Training Loss: 0.0080\n",
      "Epoch 7/20, Validation Loss: 0.0660\n",
      "     actual  predicted\n",
      "0     45.49  44.019725\n",
      "1     45.01  44.972364\n",
      "2     44.88  44.232748\n",
      "3     44.84  44.106854\n",
      "4     45.36  43.874532\n",
      "..      ...        ...\n",
      "507   48.32  46.928702\n",
      "508   48.00  46.837279\n",
      "509   47.68  46.722368\n",
      "510   47.68  46.690272\n",
      "511   47.81  46.536687\n",
      "\n",
      "[512 rows x 2 columns]\n",
      "Epoch 8/20, Training Loss: 0.0072\n",
      "Epoch 8/20, Validation Loss: 0.0619\n",
      "     actual  predicted\n",
      "0     45.49  44.958809\n",
      "1     45.01  46.022405\n",
      "2     44.88  45.377005\n",
      "3     44.84  45.101622\n",
      "4     45.36  44.820075\n",
      "..      ...        ...\n",
      "507   48.32  47.693935\n",
      "508   48.00  47.472494\n",
      "509   47.68  47.142512\n",
      "510   47.68  47.044661\n",
      "511   47.81  46.969742\n",
      "\n",
      "[512 rows x 2 columns]\n",
      "Epoch 9/20, Training Loss: 0.0065\n",
      "Epoch 9/20, Validation Loss: 0.0502\n",
      "     actual  predicted\n",
      "0     45.49  44.327913\n",
      "1     45.01  45.272970\n",
      "2     44.88  44.722242\n",
      "3     44.84  44.592145\n",
      "4     45.36  44.256112\n",
      "..      ...        ...\n",
      "507   48.32  47.423527\n",
      "508   48.00  47.069125\n",
      "509   47.68  46.748840\n",
      "510   47.68  46.531758\n",
      "511   47.81  46.514479\n",
      "\n",
      "[512 rows x 2 columns]\n",
      "Epoch 10/20, Training Loss: 0.0062\n",
      "Epoch 10/20, Validation Loss: 0.0588\n",
      "     actual  predicted\n",
      "0     45.49  43.568905\n",
      "1     45.01  44.469871\n",
      "2     44.88  43.941065\n",
      "3     44.84  43.922368\n",
      "4     45.36  43.702893\n",
      "..      ...        ...\n",
      "507   48.32  46.093571\n",
      "508   48.00  45.916409\n",
      "509   47.68  45.634114\n",
      "510   47.68  45.409965\n",
      "511   47.81  45.339490\n",
      "\n",
      "[512 rows x 2 columns]\n",
      "Epoch 11/20, Training Loss: 0.0057\n",
      "Epoch 11/20, Validation Loss: 0.1118\n",
      "     actual  predicted\n",
      "0     45.49  44.666243\n",
      "1     45.01  45.623690\n",
      "2     44.88  45.084840\n",
      "3     44.84  44.952032\n",
      "4     45.36  44.623732\n",
      "..      ...        ...\n",
      "507   48.32  47.583857\n",
      "508   48.00  47.146628\n",
      "509   47.68  46.736398\n",
      "510   47.68  46.477511\n",
      "511   47.81  46.523942\n",
      "\n",
      "[512 rows x 2 columns]\n",
      "Epoch 12/20, Training Loss: 0.0055\n",
      "Epoch 12/20, Validation Loss: 0.0534\n",
      "     actual  predicted\n",
      "0     45.49  44.581325\n",
      "1     45.01  45.470522\n",
      "2     44.88  44.949588\n",
      "3     44.84  44.910361\n",
      "4     45.36  44.655189\n",
      "..      ...        ...\n",
      "507   48.32  47.525630\n",
      "508   48.00  47.128293\n",
      "509   47.68  46.706354\n",
      "510   47.68  46.409027\n",
      "511   47.81  46.529508\n",
      "\n",
      "[512 rows x 2 columns]\n",
      "Epoch 13/20, Training Loss: 0.0052\n",
      "Epoch 13/20, Validation Loss: 0.0622\n",
      "     actual  predicted\n",
      "0     45.49  44.741720\n",
      "1     45.01  45.550211\n",
      "2     44.88  45.109852\n",
      "3     44.84  45.071760\n",
      "4     45.36  44.770725\n",
      "..      ...        ...\n",
      "507   48.32  47.659898\n",
      "508   48.00  47.295358\n",
      "509   47.68  46.906963\n",
      "510   47.68  46.607975\n",
      "511   47.81  46.695186\n",
      "\n",
      "[512 rows x 2 columns]\n",
      "Epoch 14/20, Training Loss: 0.0045\n",
      "Epoch 14/20, Validation Loss: 0.0463\n",
      "     actual  predicted\n",
      "0     45.49  44.632508\n",
      "1     45.01  45.569061\n",
      "2     44.88  45.087153\n",
      "3     44.84  45.003329\n",
      "4     45.36  44.735468\n",
      "..      ...        ...\n",
      "507   48.32  47.757345\n",
      "508   48.00  47.440506\n",
      "509   47.68  47.077222\n",
      "510   47.68  46.831865\n",
      "511   47.81  46.788061\n",
      "\n",
      "[512 rows x 2 columns]\n",
      "Epoch 15/20, Training Loss: 0.0044\n",
      "Epoch 15/20, Validation Loss: 0.0533\n",
      "     actual  predicted\n",
      "0     45.49  44.170039\n",
      "1     45.01  45.128565\n",
      "2     44.88  44.476249\n",
      "3     44.84  44.320089\n",
      "4     45.36  44.067245\n",
      "..      ...        ...\n",
      "507   48.32  47.604327\n",
      "508   48.00  47.215999\n",
      "509   47.68  46.741033\n",
      "510   47.68  46.483830\n",
      "511   47.81  46.500967\n",
      "\n",
      "[512 rows x 2 columns]\n",
      "Epoch 16/20, Training Loss: 0.0043\n",
      "Epoch 16/20, Validation Loss: 0.0568\n",
      "     actual  predicted\n",
      "0     45.49  44.625226\n",
      "1     45.01  45.547390\n",
      "2     44.88  44.905219\n",
      "3     44.84  44.776337\n",
      "4     45.36  44.579103\n",
      "..      ...        ...\n",
      "507   48.32  48.492806\n",
      "508   48.00  48.083215\n",
      "509   47.68  47.553995\n",
      "510   47.68  47.190693\n",
      "511   47.81  47.167189\n",
      "\n",
      "[512 rows x 2 columns]\n",
      "Epoch 17/20, Training Loss: 0.0042\n",
      "Epoch 17/20, Validation Loss: 0.0399\n",
      "     actual  predicted\n",
      "0     45.49  44.880891\n",
      "1     45.01  45.892907\n",
      "2     44.88  45.455567\n",
      "3     44.84  45.374680\n",
      "4     45.36  45.114988\n",
      "..      ...        ...\n",
      "507   48.32  48.380787\n",
      "508   48.00  47.980123\n",
      "509   47.68  47.553148\n",
      "510   47.68  47.305523\n",
      "511   47.81  47.333315\n",
      "\n",
      "[512 rows x 2 columns]\n",
      "Epoch 18/20, Training Loss: 0.0041\n",
      "Epoch 18/20, Validation Loss: 0.0276\n",
      "     actual  predicted\n",
      "0     45.49  44.502745\n",
      "1     45.01  45.513068\n",
      "2     44.88  44.861387\n",
      "3     44.84  44.721825\n",
      "4     45.36  44.504164\n",
      "..      ...        ...\n",
      "507   48.32  47.522177\n",
      "508   48.00  47.157718\n",
      "509   47.68  46.711488\n",
      "510   47.68  46.469707\n",
      "511   47.81  46.402921\n",
      "\n",
      "[512 rows x 2 columns]\n",
      "Epoch 19/20, Training Loss: 0.0040\n",
      "Epoch 19/20, Validation Loss: 0.0446\n",
      "     actual  predicted\n",
      "0     45.49  44.455071\n",
      "1     45.01  45.398468\n",
      "2     44.88  44.914397\n",
      "3     44.84  44.742413\n",
      "4     45.36  44.556335\n",
      "..      ...        ...\n",
      "507   48.32  47.564969\n",
      "508   48.00  47.173201\n",
      "509   47.68  46.918524\n",
      "510   47.68  46.689343\n",
      "511   47.81  46.803777\n",
      "\n",
      "[512 rows x 2 columns]\n",
      "Epoch 20/20, Training Loss: 0.0039\n",
      "Epoch 20/20, Validation Loss: 0.0339\n",
      "       actual  predicted\n",
      "0       45.49  44.455071\n",
      "1       45.01  45.398468\n",
      "2       44.88  44.914397\n",
      "3       44.84  44.742413\n",
      "4       45.36  44.556335\n",
      "...       ...        ...\n",
      "62740   37.58  36.287188\n",
      "62741   37.58  36.400415\n",
      "62742   37.61  36.527607\n",
      "62743   37.65  36.666865\n",
      "62744   37.65  36.716867\n",
      "\n",
      "[62745 rows x 2 columns]\n",
      "Score (RMSE): 1.7597\n",
      "Score (MAE): 1.3676\n",
      "Score (MAPE): 2.9538%\n",
      "training data cutoff:  2023-07-15 02:45:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Studium\\Semester_6\\IoT_Project\\utils.py:911: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_train[columns_to_scale] = scaler.fit_transform(df_train[columns_to_scale])\n",
      "c:\\Studium\\Semester_6\\IoT_Project\\utils.py:912: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_test[columns_to_scale] = scaler.transform(df_test[columns_to_scale])\n",
      "c:\\Studium\\Semester_6\\IoT_Project\\utils.py:916: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_train.drop(['date_time_rounded'], axis=1, inplace=True)\n",
      "c:\\Studium\\Semester_6\\IoT_Project\\utils.py:917: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_test.drop(['date_time_rounded'], axis=1, inplace=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tmp                         float64\n",
      "hum                         float64\n",
      "CO2                         float64\n",
      "VOC                         float64\n",
      "vis                         float64\n",
      "IR                          float64\n",
      "WIFI                        float64\n",
      "BLE                         float64\n",
      "rssi                        float64\n",
      "channel_rssi                float64\n",
      "channel_index               float64\n",
      "spreading_factor            float64\n",
      "bandwidth                   float64\n",
      "f_cnt                       float64\n",
      "isHoliday                   float64\n",
      "isExamTime                  float64\n",
      "weekday                     float64\n",
      "month                       float64\n",
      "hour_sin                    float64\n",
      "semester_SS23               float64\n",
      "semester_WS22/23            float64\n",
      "semester_WS23/24            float64\n",
      "group                       float64\n",
      "device_id_hka-aqm-am001     float64\n",
      "device_id_hka-aqm-am002     float64\n",
      "device_id_hka-aqm-am003a    float64\n",
      "device_id_hka-aqm-am003b    float64\n",
      "device_id_hka-aqm-am004     float64\n",
      "device_id_hka-aqm-am005     float64\n",
      "device_id_hka-aqm-am107     float64\n",
      "device_id_hka-aqm-am109     float64\n",
      "device_id_hka-aqm-am110     float64\n",
      "device_id_hka-aqm-am111     float64\n",
      "device_id_hka-aqm-am115     float64\n",
      "device_id_hka-aqm-am116     float64\n",
      "device_id_hka-aqm-am117     float64\n",
      "device_id_hka-aqm-am123     float64\n",
      "device_id_hka-aqm-am124     float64\n",
      "device_id_hka-aqm-am126     float64\n",
      "device_id_hka-aqm-am201a    float64\n",
      "device_id_hka-aqm-am201b    float64\n",
      "device_id_hka-aqm-am204     float64\n",
      "device_id_hka-aqm-am205     float64\n",
      "device_id_hka-aqm-am209     float64\n",
      "device_id_hka-aqm-am210     float64\n",
      "device_id_hka-aqm-am211     float64\n",
      "device_id_hka-aqm-am301     float64\n",
      "device_id_hka-aqm-am307     float64\n",
      "device_id_hka-aqm-am308     float64\n",
      "dtype: object\n",
      "feature count:  49\n",
      "feature count:  49\n",
      "Training data shape: torch.Size([244176, 20, 49]) torch.Size([244176, 1])\n",
      "Testing data shape: torch.Size([62745, 20, 49]) torch.Size([62745, 1])\n",
      "same columns\n",
      "date_time_rounded           datetime64[ns]\n",
      "tmp                                float64\n",
      "hum                                float64\n",
      "CO2                                float64\n",
      "VOC                                float64\n",
      "vis                                float64\n",
      "IR                                 float64\n",
      "WIFI                               float64\n",
      "BLE                                float64\n",
      "rssi                               float64\n",
      "channel_rssi                       float64\n",
      "channel_index                      float64\n",
      "spreading_factor                   float64\n",
      "bandwidth                          float64\n",
      "f_cnt                              float64\n",
      "isHoliday                          float64\n",
      "isExamTime                         float64\n",
      "weekday                            float64\n",
      "month                              float64\n",
      "hour_sin                           float64\n",
      "semester_SS23                      float64\n",
      "semester_WS22/23                   float64\n",
      "semester_WS23/24                   float64\n",
      "group                                int32\n",
      "device_id_hka-aqm-am001              uint8\n",
      "device_id_hka-aqm-am002              uint8\n",
      "device_id_hka-aqm-am003a             uint8\n",
      "device_id_hka-aqm-am003b             uint8\n",
      "device_id_hka-aqm-am004              uint8\n",
      "device_id_hka-aqm-am005              uint8\n",
      "device_id_hka-aqm-am107              uint8\n",
      "device_id_hka-aqm-am109              uint8\n",
      "device_id_hka-aqm-am110              uint8\n",
      "device_id_hka-aqm-am111              uint8\n",
      "device_id_hka-aqm-am115              uint8\n",
      "device_id_hka-aqm-am116              uint8\n",
      "device_id_hka-aqm-am117              uint8\n",
      "device_id_hka-aqm-am123              uint8\n",
      "device_id_hka-aqm-am124              uint8\n",
      "device_id_hka-aqm-am126              uint8\n",
      "device_id_hka-aqm-am201a             uint8\n",
      "device_id_hka-aqm-am201b             uint8\n",
      "device_id_hka-aqm-am204              uint8\n",
      "device_id_hka-aqm-am205              uint8\n",
      "device_id_hka-aqm-am209              uint8\n",
      "device_id_hka-aqm-am210              uint8\n",
      "device_id_hka-aqm-am211              uint8\n",
      "device_id_hka-aqm-am301              uint8\n",
      "device_id_hka-aqm-am307              uint8\n",
      "device_id_hka-aqm-am308              uint8\n",
      "dtype: object\n",
      "date_time_rounded           datetime64[ns]\n",
      "tmp                                float64\n",
      "hum                                float64\n",
      "CO2                                float64\n",
      "VOC                                float64\n",
      "vis                                float64\n",
      "IR                                 float64\n",
      "WIFI                               float64\n",
      "BLE                                float64\n",
      "rssi                               float64\n",
      "channel_rssi                       float64\n",
      "channel_index                      float64\n",
      "spreading_factor                   float64\n",
      "bandwidth                          float64\n",
      "f_cnt                              float64\n",
      "isHoliday                          float64\n",
      "isExamTime                         float64\n",
      "weekday                            float64\n",
      "month                              float64\n",
      "hour_sin                           float64\n",
      "semester_SS23                      float64\n",
      "semester_WS22/23                   float64\n",
      "semester_WS23/24                   float64\n",
      "group                                int32\n",
      "device_id_hka-aqm-am001              uint8\n",
      "device_id_hka-aqm-am002              uint8\n",
      "device_id_hka-aqm-am003a             uint8\n",
      "device_id_hka-aqm-am003b             uint8\n",
      "device_id_hka-aqm-am004              uint8\n",
      "device_id_hka-aqm-am005              uint8\n",
      "device_id_hka-aqm-am107              uint8\n",
      "device_id_hka-aqm-am109              uint8\n",
      "device_id_hka-aqm-am110              uint8\n",
      "device_id_hka-aqm-am111              uint8\n",
      "device_id_hka-aqm-am115              uint8\n",
      "device_id_hka-aqm-am116              uint8\n",
      "device_id_hka-aqm-am117              uint8\n",
      "device_id_hka-aqm-am123              uint8\n",
      "device_id_hka-aqm-am124              uint8\n",
      "device_id_hka-aqm-am126              uint8\n",
      "device_id_hka-aqm-am201a             uint8\n",
      "device_id_hka-aqm-am201b             uint8\n",
      "device_id_hka-aqm-am204              uint8\n",
      "device_id_hka-aqm-am205              uint8\n",
      "device_id_hka-aqm-am209              uint8\n",
      "device_id_hka-aqm-am210              uint8\n",
      "device_id_hka-aqm-am211              uint8\n",
      "device_id_hka-aqm-am301              uint8\n",
      "device_id_hka-aqm-am307              uint8\n",
      "device_id_hka-aqm-am308              uint8\n",
      "dtype: object\n",
      "         date_time_rounded        tmp        hum         CO2         VOC  \\\n",
      "382774 2022-10-10 14:45:00  24.373333  47.616667  760.000000  487.666667   \n",
      "382775 2022-10-10 16:30:00  25.360000  44.336667  563.666667  555.000000   \n",
      "382776 2022-10-10 17:00:00  25.570000  44.940000  574.000000  579.000000   \n",
      "382777 2022-10-10 17:15:00  25.530000  45.140000  575.000000  585.000000   \n",
      "382778 2022-10-10 17:45:00  25.480000  46.590000  586.000000  620.000000   \n",
      "...                    ...        ...        ...         ...         ...   \n",
      "529479 2023-09-26 22:30:00  27.360000  37.510000  527.000000  951.000000   \n",
      "529480 2023-09-26 22:45:00  27.380000  37.580000  520.000000  950.000000   \n",
      "529481 2023-09-26 23:15:00  27.350000  37.610000  529.000000  966.000000   \n",
      "529482 2023-09-26 23:30:00  27.340000  37.650000  525.000000  944.000000   \n",
      "529483 2023-09-26 23:45:00  27.330000  37.650000  525.000000  951.000000   \n",
      "\n",
      "          vis         IR      WIFI        BLE  rssi  ...  \\\n",
      "382774  207.0  27.000000  1.666667   2.666667 -64.0  ...   \n",
      "382775  115.0  12.666667  1.000000   2.000000 -59.0  ...   \n",
      "382776  157.0  16.000000  0.000000   0.000000 -55.0  ...   \n",
      "382777  155.0  16.000000  0.000000   0.000000 -59.0  ...   \n",
      "382778  157.0  18.000000  0.000000   0.000000 -60.0  ...   \n",
      "...       ...        ...       ...        ...   ...  ...   \n",
      "529479    4.0   1.000000  2.000000   0.000000 -73.0  ...   \n",
      "529480    7.0   3.000000  2.000000   0.000000 -73.0  ...   \n",
      "529481    4.0   0.000000  6.000000  27.000000 -75.0  ...   \n",
      "529482    4.0   0.000000  0.000000   0.000000 -75.0  ...   \n",
      "529483    4.0   0.000000  0.000000   0.000000 -70.0  ...   \n",
      "\n",
      "        device_id_hka-aqm-am201a  device_id_hka-aqm-am201b  \\\n",
      "382774                         0                         0   \n",
      "382775                         0                         0   \n",
      "382776                         0                         0   \n",
      "382777                         0                         0   \n",
      "382778                         0                         0   \n",
      "...                          ...                       ...   \n",
      "529479                         0                         0   \n",
      "529480                         0                         0   \n",
      "529481                         0                         0   \n",
      "529482                         0                         0   \n",
      "529483                         0                         0   \n",
      "\n",
      "        device_id_hka-aqm-am204  device_id_hka-aqm-am205  \\\n",
      "382774                        0                        0   \n",
      "382775                        0                        0   \n",
      "382776                        0                        0   \n",
      "382777                        0                        0   \n",
      "382778                        0                        0   \n",
      "...                         ...                      ...   \n",
      "529479                        0                        0   \n",
      "529480                        0                        0   \n",
      "529481                        0                        0   \n",
      "529482                        0                        0   \n",
      "529483                        0                        0   \n",
      "\n",
      "        device_id_hka-aqm-am209  device_id_hka-aqm-am210  \\\n",
      "382774                        0                        0   \n",
      "382775                        0                        0   \n",
      "382776                        0                        0   \n",
      "382777                        0                        0   \n",
      "382778                        0                        0   \n",
      "...                         ...                      ...   \n",
      "529479                        0                        0   \n",
      "529480                        0                        0   \n",
      "529481                        0                        0   \n",
      "529482                        0                        0   \n",
      "529483                        0                        0   \n",
      "\n",
      "        device_id_hka-aqm-am211  device_id_hka-aqm-am301  \\\n",
      "382774                        0                        0   \n",
      "382775                        0                        0   \n",
      "382776                        0                        0   \n",
      "382777                        0                        0   \n",
      "382778                        0                        0   \n",
      "...                         ...                      ...   \n",
      "529479                        0                        0   \n",
      "529480                        0                        0   \n",
      "529481                        0                        0   \n",
      "529482                        0                        0   \n",
      "529483                        0                        0   \n",
      "\n",
      "        device_id_hka-aqm-am307  device_id_hka-aqm-am308  \n",
      "382774                        0                        0  \n",
      "382775                        0                        0  \n",
      "382776                        0                        0  \n",
      "382777                        0                        0  \n",
      "382778                        0                        0  \n",
      "...                         ...                      ...  \n",
      "529479                        0                        1  \n",
      "529480                        0                        1  \n",
      "529481                        0                        1  \n",
      "529482                        0                        1  \n",
      "529483                        0                        1  \n",
      "\n",
      "[146710 rows x 50 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\t-ehm\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\transformer.py:286: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
      "c:\\Users\\t-ehm\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\optim\\lr_scheduler.py:28: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\"The verbose parameter is deprecated. Please use get_last_lr() \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     actual  predicted\n",
      "0     26.09  24.851056\n",
      "1     26.01  25.083340\n",
      "2     25.98  24.923600\n",
      "3     25.95  24.892734\n",
      "4     25.92  24.970708\n",
      "..      ...        ...\n",
      "507   23.60  23.061688\n",
      "508   23.72  23.016667\n",
      "509   23.82  23.234557\n",
      "510   23.86  23.327086\n",
      "511   23.96  23.323733\n",
      "\n",
      "[512 rows x 2 columns]\n",
      "Epoch 1/20, Training Loss: 0.1072\n",
      "Epoch 1/20, Validation Loss: 0.4664\n",
      "     actual  predicted\n",
      "0     26.09  24.937464\n",
      "1     26.01  25.046444\n",
      "2     25.98  24.886654\n",
      "3     25.95  24.989815\n",
      "4     25.92  24.994359\n",
      "..      ...        ...\n",
      "507   23.60  23.055108\n",
      "508   23.72  23.081860\n",
      "509   23.82  23.154870\n",
      "510   23.86  23.264404\n",
      "511   23.96  23.245944\n",
      "\n",
      "[512 rows x 2 columns]\n",
      "Epoch 2/20, Training Loss: 0.0260\n",
      "Epoch 2/20, Validation Loss: 0.3261\n",
      "     actual  predicted\n",
      "0     26.09  25.384804\n",
      "1     26.01  25.395774\n",
      "2     25.98  25.147181\n",
      "3     25.95  25.282410\n",
      "4     25.92  25.229784\n",
      "..      ...        ...\n",
      "507   23.60  23.463388\n",
      "508   23.72  23.497841\n",
      "509   23.82  23.595515\n",
      "510   23.86  23.724181\n",
      "511   23.96  23.740094\n",
      "\n",
      "[512 rows x 2 columns]\n",
      "Epoch 3/20, Training Loss: 0.0159\n",
      "Epoch 3/20, Validation Loss: 0.1803\n",
      "     actual  predicted\n",
      "0     26.09  25.657918\n",
      "1     26.01  25.603922\n",
      "2     25.98  25.361682\n",
      "3     25.95  25.381495\n",
      "4     25.92  25.397346\n",
      "..      ...        ...\n",
      "507   23.60  23.389134\n",
      "508   23.72  23.416946\n",
      "509   23.82  23.521414\n",
      "510   23.86  23.652500\n",
      "511   23.96  23.673634\n",
      "\n",
      "[512 rows x 2 columns]\n",
      "Epoch 4/20, Training Loss: 0.0120\n",
      "Epoch 4/20, Validation Loss: 0.0892\n",
      "     actual  predicted\n",
      "0     26.09  25.889845\n",
      "1     26.01  25.875295\n",
      "2     25.98  25.669088\n",
      "3     25.95  25.673001\n",
      "4     25.92  25.703719\n",
      "..      ...        ...\n",
      "507   23.60  23.682025\n",
      "508   23.72  23.689833\n",
      "509   23.82  23.829485\n",
      "510   23.86  23.932659\n",
      "511   23.96  23.948015\n",
      "\n",
      "[512 rows x 2 columns]\n",
      "Epoch 5/20, Training Loss: 0.0095\n",
      "Epoch 5/20, Validation Loss: 0.0914\n",
      "     actual  predicted\n",
      "0     26.09  26.097895\n",
      "1     26.01  26.098448\n",
      "2     25.98  25.887092\n",
      "3     25.95  25.835174\n",
      "4     25.92  25.800149\n",
      "..      ...        ...\n",
      "507   23.60  23.638067\n",
      "508   23.72  23.675192\n",
      "509   23.82  23.833865\n",
      "510   23.86  23.982727\n",
      "511   23.96  24.013811\n",
      "\n",
      "[512 rows x 2 columns]\n",
      "Epoch 6/20, Training Loss: 0.0084\n",
      "Epoch 6/20, Validation Loss: 0.0935\n",
      "     actual  predicted\n",
      "0     26.09  25.848484\n",
      "1     26.01  25.831335\n",
      "2     25.98  25.605090\n",
      "3     25.95  25.566984\n",
      "4     25.92  25.494251\n",
      "..      ...        ...\n",
      "507   23.60  23.439892\n",
      "508   23.72  23.502978\n",
      "509   23.82  23.666403\n",
      "510   23.86  23.756763\n",
      "511   23.96  23.735075\n",
      "\n",
      "[512 rows x 2 columns]\n",
      "Epoch 7/20, Training Loss: 0.0070\n",
      "Epoch 7/20, Validation Loss: 0.1065\n",
      "     actual  predicted\n",
      "0     26.09  25.936519\n",
      "1     26.01  25.920484\n",
      "2     25.98  25.718827\n",
      "3     25.95  25.700957\n",
      "4     25.92  25.631374\n",
      "..      ...        ...\n",
      "507   23.60  23.559846\n",
      "508   23.72  23.631401\n",
      "509   23.82  23.803515\n",
      "510   23.86  23.962195\n",
      "511   23.96  23.979513\n",
      "\n",
      "[512 rows x 2 columns]\n",
      "Epoch 8/20, Training Loss: 0.0063\n",
      "Epoch 8/20, Validation Loss: 0.0754\n",
      "     actual  predicted\n",
      "0     26.09  26.110368\n",
      "1     26.01  26.092188\n",
      "2     25.98  25.928562\n",
      "3     25.95  25.874735\n",
      "4     25.92  25.761868\n",
      "..      ...        ...\n",
      "507   23.60  23.574443\n",
      "508   23.72  23.625193\n",
      "509   23.82  23.760516\n",
      "510   23.86  23.881518\n",
      "511   23.96  23.889259\n",
      "\n",
      "[512 rows x 2 columns]\n",
      "Epoch 9/20, Training Loss: 0.0058\n",
      "Epoch 9/20, Validation Loss: 0.0363\n",
      "     actual  predicted\n",
      "0     26.09  25.925325\n",
      "1     26.01  25.961583\n",
      "2     25.98  25.845435\n",
      "3     25.95  25.747855\n",
      "4     25.92  25.654919\n",
      "..      ...        ...\n",
      "507   23.60  23.718583\n",
      "508   23.72  23.756252\n",
      "509   23.82  23.860967\n",
      "510   23.86  23.963446\n",
      "511   23.96  23.997158\n",
      "\n",
      "[512 rows x 2 columns]\n",
      "Epoch 10/20, Training Loss: 0.0052\n",
      "Epoch 10/20, Validation Loss: 0.0541\n",
      "     actual  predicted\n",
      "0     26.09  25.985680\n",
      "1     26.01  26.006359\n",
      "2     25.98  25.909596\n",
      "3     25.95  25.846442\n",
      "4     25.92  25.775256\n",
      "..      ...        ...\n",
      "507   23.60  23.650735\n",
      "508   23.72  23.623521\n",
      "509   23.82  23.739189\n",
      "510   23.86  23.818724\n",
      "511   23.96  23.875879\n",
      "\n",
      "[512 rows x 2 columns]\n",
      "Epoch 11/20, Training Loss: 0.0049\n",
      "Epoch 11/20, Validation Loss: 0.0567\n",
      "     actual  predicted\n",
      "0     26.09  25.769599\n",
      "1     26.01  25.817782\n",
      "2     25.98  25.707201\n",
      "3     25.95  25.702386\n",
      "4     25.92  25.686187\n",
      "..      ...        ...\n",
      "507   23.60  23.599593\n",
      "508   23.72  23.597986\n",
      "509   23.82  23.703916\n",
      "510   23.86  23.812706\n",
      "511   23.96  23.877095\n",
      "\n",
      "[512 rows x 2 columns]\n",
      "Epoch 12/20, Training Loss: 0.0044\n",
      "Epoch 12/20, Validation Loss: 0.0406\n",
      "     actual  predicted\n",
      "0     26.09  25.964623\n",
      "1     26.01  26.029027\n",
      "2     25.98  25.913925\n",
      "3     25.95  25.834447\n",
      "4     25.92  25.791126\n",
      "..      ...        ...\n",
      "507   23.60  23.691460\n",
      "508   23.72  23.706338\n",
      "509   23.82  23.848932\n",
      "510   23.86  23.936945\n",
      "511   23.96  23.968963\n",
      "\n",
      "[512 rows x 2 columns]\n",
      "Epoch 13/20, Training Loss: 0.0043\n",
      "Epoch 13/20, Validation Loss: 0.0345\n",
      "     actual  predicted\n",
      "0     26.09  26.030585\n",
      "1     26.01  26.031862\n",
      "2     25.98  25.925788\n",
      "3     25.95  25.865143\n",
      "4     25.92  25.837976\n",
      "..      ...        ...\n",
      "507   23.60  23.563664\n",
      "508   23.72  23.569067\n",
      "509   23.82  23.690784\n",
      "510   23.86  23.775796\n",
      "511   23.96  23.829264\n",
      "\n",
      "[512 rows x 2 columns]\n",
      "Epoch 14/20, Training Loss: 0.0041\n",
      "Epoch 14/20, Validation Loss: 0.0267\n",
      "     actual  predicted\n",
      "0     26.09  25.919172\n",
      "1     26.01  25.925554\n",
      "2     25.98  25.820201\n",
      "3     25.95  25.717886\n",
      "4     25.92  25.695191\n",
      "..      ...        ...\n",
      "507   23.60  23.650735\n",
      "508   23.72  23.640872\n",
      "509   23.82  23.792629\n",
      "510   23.86  23.886258\n",
      "511   23.96  23.980225\n",
      "\n",
      "[512 rows x 2 columns]\n",
      "Epoch 15/20, Training Loss: 0.0038\n",
      "Epoch 15/20, Validation Loss: 0.0302\n",
      "     actual  predicted\n",
      "0     26.09  25.903219\n",
      "1     26.01  25.929502\n",
      "2     25.98  25.802815\n",
      "3     25.95  25.750058\n",
      "4     25.92  25.730509\n",
      "..      ...        ...\n",
      "507   23.60  23.670985\n",
      "508   23.72  23.685518\n",
      "509   23.82  23.798080\n",
      "510   23.86  23.941239\n",
      "511   23.96  24.020731\n",
      "\n",
      "[512 rows x 2 columns]\n",
      "Epoch 16/20, Training Loss: 0.0037\n",
      "Epoch 16/20, Validation Loss: 0.0221\n",
      "     actual  predicted\n",
      "0     26.09  26.038965\n",
      "1     26.01  26.072855\n",
      "2     25.98  25.938214\n",
      "3     25.95  25.857405\n",
      "4     25.92  25.780754\n",
      "..      ...        ...\n",
      "507   23.60  23.778921\n",
      "508   23.72  23.826185\n",
      "509   23.82  23.951466\n",
      "510   23.86  24.100145\n",
      "511   23.96  24.130652\n",
      "\n",
      "[512 rows x 2 columns]\n",
      "Epoch 17/20, Training Loss: 0.0035\n",
      "Epoch 17/20, Validation Loss: 0.0207\n",
      "     actual  predicted\n",
      "0     26.09  25.823060\n",
      "1     26.01  25.856436\n",
      "2     25.98  25.752117\n",
      "3     25.95  25.707720\n",
      "4     25.92  25.638404\n",
      "..      ...        ...\n",
      "507   23.60  23.642356\n",
      "508   23.72  23.657385\n",
      "509   23.82  23.757781\n",
      "510   23.86  23.890151\n",
      "511   23.96  23.941967\n",
      "\n",
      "[512 rows x 2 columns]\n",
      "Epoch 18/20, Training Loss: 0.0034\n",
      "Epoch 18/20, Validation Loss: 0.0293\n",
      "     actual  predicted\n",
      "0     26.09  26.034132\n",
      "1     26.01  26.061919\n",
      "2     25.98  25.978191\n",
      "3     25.95  25.903128\n",
      "4     25.92  25.865158\n",
      "..      ...        ...\n",
      "507   23.60  23.809862\n",
      "508   23.72  23.836961\n",
      "509   23.82  23.955051\n",
      "510   23.86  24.103988\n",
      "511   23.96  24.170935\n",
      "\n",
      "[512 rows x 2 columns]\n",
      "Epoch 19/20, Training Loss: 0.0032\n",
      "Epoch 19/20, Validation Loss: 0.0259\n",
      "     actual  predicted\n",
      "0     26.09  25.685883\n",
      "1     26.01  25.705697\n",
      "2     25.98  25.606457\n",
      "3     25.95  25.508054\n",
      "4     25.92  25.461120\n",
      "..      ...        ...\n",
      "507   23.60  23.357824\n",
      "508   23.72  23.369708\n",
      "509   23.82  23.505020\n",
      "510   23.86  23.656066\n",
      "511   23.96  23.770444\n",
      "\n",
      "[512 rows x 2 columns]\n",
      "Epoch 20/20, Training Loss: 0.0031\n",
      "Epoch 20/20, Validation Loss: 0.0322\n",
      "       actual  predicted\n",
      "0       26.09  25.685883\n",
      "1       26.01  25.705697\n",
      "2       25.98  25.606457\n",
      "3       25.95  25.508054\n",
      "4       25.92  25.461120\n",
      "...       ...        ...\n",
      "62740   27.38  26.668277\n",
      "62741   27.36  26.718531\n",
      "62742   27.35  26.709730\n",
      "62743   27.34  26.627699\n",
      "62744   27.33  26.631533\n",
      "\n",
      "[62745 rows x 2 columns]\n",
      "Score (RMSE): 0.6463\n",
      "Score (MAE): 0.5342\n",
      "Score (MAPE): 1.9249%\n",
      "training data cutoff:  2023-07-15 02:45:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Studium\\Semester_6\\IoT_Project\\utils.py:911: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_train[columns_to_scale] = scaler.fit_transform(df_train[columns_to_scale])\n",
      "c:\\Studium\\Semester_6\\IoT_Project\\utils.py:912: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_test[columns_to_scale] = scaler.transform(df_test[columns_to_scale])\n",
      "c:\\Studium\\Semester_6\\IoT_Project\\utils.py:916: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_train.drop(['date_time_rounded'], axis=1, inplace=True)\n",
      "c:\\Studium\\Semester_6\\IoT_Project\\utils.py:917: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_test.drop(['date_time_rounded'], axis=1, inplace=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tmp                         float64\n",
      "hum                         float64\n",
      "CO2                         float64\n",
      "VOC                         float64\n",
      "vis                         float64\n",
      "IR                          float64\n",
      "WIFI                        float64\n",
      "BLE                         float64\n",
      "rssi                        float64\n",
      "channel_rssi                float64\n",
      "channel_index               float64\n",
      "spreading_factor            float64\n",
      "bandwidth                   float64\n",
      "f_cnt                       float64\n",
      "isHoliday                   float64\n",
      "isExamTime                  float64\n",
      "weekday                     float64\n",
      "month                       float64\n",
      "hour_sin                    float64\n",
      "semester_SS23               float64\n",
      "semester_WS22/23            float64\n",
      "semester_WS23/24            float64\n",
      "group                       float64\n",
      "device_id_hka-aqm-am001     float64\n",
      "device_id_hka-aqm-am002     float64\n",
      "device_id_hka-aqm-am003a    float64\n",
      "device_id_hka-aqm-am003b    float64\n",
      "device_id_hka-aqm-am004     float64\n",
      "device_id_hka-aqm-am005     float64\n",
      "device_id_hka-aqm-am107     float64\n",
      "device_id_hka-aqm-am109     float64\n",
      "device_id_hka-aqm-am110     float64\n",
      "device_id_hka-aqm-am111     float64\n",
      "device_id_hka-aqm-am115     float64\n",
      "device_id_hka-aqm-am116     float64\n",
      "device_id_hka-aqm-am117     float64\n",
      "device_id_hka-aqm-am123     float64\n",
      "device_id_hka-aqm-am124     float64\n",
      "device_id_hka-aqm-am126     float64\n",
      "device_id_hka-aqm-am201a    float64\n",
      "device_id_hka-aqm-am201b    float64\n",
      "device_id_hka-aqm-am204     float64\n",
      "device_id_hka-aqm-am205     float64\n",
      "device_id_hka-aqm-am209     float64\n",
      "device_id_hka-aqm-am210     float64\n",
      "device_id_hka-aqm-am211     float64\n",
      "device_id_hka-aqm-am301     float64\n",
      "device_id_hka-aqm-am307     float64\n",
      "device_id_hka-aqm-am308     float64\n",
      "dtype: object\n",
      "feature count:  49\n",
      "feature count:  49\n",
      "Training data shape: torch.Size([244176, 20, 49]) torch.Size([244176, 1])\n",
      "Testing data shape: torch.Size([62745, 20, 49]) torch.Size([62745, 1])\n",
      "same columns\n",
      "date_time_rounded           datetime64[ns]\n",
      "tmp                                float64\n",
      "hum                                float64\n",
      "CO2                                float64\n",
      "VOC                                float64\n",
      "vis                                float64\n",
      "IR                                 float64\n",
      "WIFI                               float64\n",
      "BLE                                float64\n",
      "rssi                               float64\n",
      "channel_rssi                       float64\n",
      "channel_index                      float64\n",
      "spreading_factor                   float64\n",
      "bandwidth                          float64\n",
      "f_cnt                              float64\n",
      "isHoliday                          float64\n",
      "isExamTime                         float64\n",
      "weekday                            float64\n",
      "month                              float64\n",
      "hour_sin                           float64\n",
      "semester_SS23                      float64\n",
      "semester_WS22/23                   float64\n",
      "semester_WS23/24                   float64\n",
      "group                                int32\n",
      "device_id_hka-aqm-am001              uint8\n",
      "device_id_hka-aqm-am002              uint8\n",
      "device_id_hka-aqm-am003a             uint8\n",
      "device_id_hka-aqm-am003b             uint8\n",
      "device_id_hka-aqm-am004              uint8\n",
      "device_id_hka-aqm-am005              uint8\n",
      "device_id_hka-aqm-am107              uint8\n",
      "device_id_hka-aqm-am109              uint8\n",
      "device_id_hka-aqm-am110              uint8\n",
      "device_id_hka-aqm-am111              uint8\n",
      "device_id_hka-aqm-am115              uint8\n",
      "device_id_hka-aqm-am116              uint8\n",
      "device_id_hka-aqm-am117              uint8\n",
      "device_id_hka-aqm-am123              uint8\n",
      "device_id_hka-aqm-am124              uint8\n",
      "device_id_hka-aqm-am126              uint8\n",
      "device_id_hka-aqm-am201a             uint8\n",
      "device_id_hka-aqm-am201b             uint8\n",
      "device_id_hka-aqm-am204              uint8\n",
      "device_id_hka-aqm-am205              uint8\n",
      "device_id_hka-aqm-am209              uint8\n",
      "device_id_hka-aqm-am210              uint8\n",
      "device_id_hka-aqm-am211              uint8\n",
      "device_id_hka-aqm-am301              uint8\n",
      "device_id_hka-aqm-am307              uint8\n",
      "device_id_hka-aqm-am308              uint8\n",
      "dtype: object\n",
      "date_time_rounded           datetime64[ns]\n",
      "tmp                                float64\n",
      "hum                                float64\n",
      "CO2                                float64\n",
      "VOC                                float64\n",
      "vis                                float64\n",
      "IR                                 float64\n",
      "WIFI                               float64\n",
      "BLE                                float64\n",
      "rssi                               float64\n",
      "channel_rssi                       float64\n",
      "channel_index                      float64\n",
      "spreading_factor                   float64\n",
      "bandwidth                          float64\n",
      "f_cnt                              float64\n",
      "isHoliday                          float64\n",
      "isExamTime                         float64\n",
      "weekday                            float64\n",
      "month                              float64\n",
      "hour_sin                           float64\n",
      "semester_SS23                      float64\n",
      "semester_WS22/23                   float64\n",
      "semester_WS23/24                   float64\n",
      "group                                int32\n",
      "device_id_hka-aqm-am001              uint8\n",
      "device_id_hka-aqm-am002              uint8\n",
      "device_id_hka-aqm-am003a             uint8\n",
      "device_id_hka-aqm-am003b             uint8\n",
      "device_id_hka-aqm-am004              uint8\n",
      "device_id_hka-aqm-am005              uint8\n",
      "device_id_hka-aqm-am107              uint8\n",
      "device_id_hka-aqm-am109              uint8\n",
      "device_id_hka-aqm-am110              uint8\n",
      "device_id_hka-aqm-am111              uint8\n",
      "device_id_hka-aqm-am115              uint8\n",
      "device_id_hka-aqm-am116              uint8\n",
      "device_id_hka-aqm-am117              uint8\n",
      "device_id_hka-aqm-am123              uint8\n",
      "device_id_hka-aqm-am124              uint8\n",
      "device_id_hka-aqm-am126              uint8\n",
      "device_id_hka-aqm-am201a             uint8\n",
      "device_id_hka-aqm-am201b             uint8\n",
      "device_id_hka-aqm-am204              uint8\n",
      "device_id_hka-aqm-am205              uint8\n",
      "device_id_hka-aqm-am209              uint8\n",
      "device_id_hka-aqm-am210              uint8\n",
      "device_id_hka-aqm-am211              uint8\n",
      "device_id_hka-aqm-am301              uint8\n",
      "device_id_hka-aqm-am307              uint8\n",
      "device_id_hka-aqm-am308              uint8\n",
      "dtype: object\n",
      "         date_time_rounded        tmp        hum         CO2         VOC  \\\n",
      "382774 2022-10-10 14:45:00  24.373333  47.616667  760.000000  487.666667   \n",
      "382775 2022-10-10 16:30:00  25.360000  44.336667  563.666667  555.000000   \n",
      "382776 2022-10-10 17:00:00  25.570000  44.940000  574.000000  579.000000   \n",
      "382777 2022-10-10 17:15:00  25.530000  45.140000  575.000000  585.000000   \n",
      "382778 2022-10-10 17:45:00  25.480000  46.590000  586.000000  620.000000   \n",
      "...                    ...        ...        ...         ...         ...   \n",
      "529479 2023-09-26 22:30:00  27.360000  37.510000  527.000000  951.000000   \n",
      "529480 2023-09-26 22:45:00  27.380000  37.580000  520.000000  950.000000   \n",
      "529481 2023-09-26 23:15:00  27.350000  37.610000  529.000000  966.000000   \n",
      "529482 2023-09-26 23:30:00  27.340000  37.650000  525.000000  944.000000   \n",
      "529483 2023-09-26 23:45:00  27.330000  37.650000  525.000000  951.000000   \n",
      "\n",
      "          vis         IR      WIFI        BLE  rssi  ...  \\\n",
      "382774  207.0  27.000000  1.666667   2.666667 -64.0  ...   \n",
      "382775  115.0  12.666667  1.000000   2.000000 -59.0  ...   \n",
      "382776  157.0  16.000000  0.000000   0.000000 -55.0  ...   \n",
      "382777  155.0  16.000000  0.000000   0.000000 -59.0  ...   \n",
      "382778  157.0  18.000000  0.000000   0.000000 -60.0  ...   \n",
      "...       ...        ...       ...        ...   ...  ...   \n",
      "529479    4.0   1.000000  2.000000   0.000000 -73.0  ...   \n",
      "529480    7.0   3.000000  2.000000   0.000000 -73.0  ...   \n",
      "529481    4.0   0.000000  6.000000  27.000000 -75.0  ...   \n",
      "529482    4.0   0.000000  0.000000   0.000000 -75.0  ...   \n",
      "529483    4.0   0.000000  0.000000   0.000000 -70.0  ...   \n",
      "\n",
      "        device_id_hka-aqm-am201a  device_id_hka-aqm-am201b  \\\n",
      "382774                         0                         0   \n",
      "382775                         0                         0   \n",
      "382776                         0                         0   \n",
      "382777                         0                         0   \n",
      "382778                         0                         0   \n",
      "...                          ...                       ...   \n",
      "529479                         0                         0   \n",
      "529480                         0                         0   \n",
      "529481                         0                         0   \n",
      "529482                         0                         0   \n",
      "529483                         0                         0   \n",
      "\n",
      "        device_id_hka-aqm-am204  device_id_hka-aqm-am205  \\\n",
      "382774                        0                        0   \n",
      "382775                        0                        0   \n",
      "382776                        0                        0   \n",
      "382777                        0                        0   \n",
      "382778                        0                        0   \n",
      "...                         ...                      ...   \n",
      "529479                        0                        0   \n",
      "529480                        0                        0   \n",
      "529481                        0                        0   \n",
      "529482                        0                        0   \n",
      "529483                        0                        0   \n",
      "\n",
      "        device_id_hka-aqm-am209  device_id_hka-aqm-am210  \\\n",
      "382774                        0                        0   \n",
      "382775                        0                        0   \n",
      "382776                        0                        0   \n",
      "382777                        0                        0   \n",
      "382778                        0                        0   \n",
      "...                         ...                      ...   \n",
      "529479                        0                        0   \n",
      "529480                        0                        0   \n",
      "529481                        0                        0   \n",
      "529482                        0                        0   \n",
      "529483                        0                        0   \n",
      "\n",
      "        device_id_hka-aqm-am211  device_id_hka-aqm-am301  \\\n",
      "382774                        0                        0   \n",
      "382775                        0                        0   \n",
      "382776                        0                        0   \n",
      "382777                        0                        0   \n",
      "382778                        0                        0   \n",
      "...                         ...                      ...   \n",
      "529479                        0                        0   \n",
      "529480                        0                        0   \n",
      "529481                        0                        0   \n",
      "529482                        0                        0   \n",
      "529483                        0                        0   \n",
      "\n",
      "        device_id_hka-aqm-am307  device_id_hka-aqm-am308  \n",
      "382774                        0                        0  \n",
      "382775                        0                        0  \n",
      "382776                        0                        0  \n",
      "382777                        0                        0  \n",
      "382778                        0                        0  \n",
      "...                         ...                      ...  \n",
      "529479                        0                        1  \n",
      "529480                        0                        1  \n",
      "529481                        0                        1  \n",
      "529482                        0                        1  \n",
      "529483                        0                        1  \n",
      "\n",
      "[146710 rows x 50 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\t-ehm\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\transformer.py:286: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
      "c:\\Users\\t-ehm\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\optim\\lr_scheduler.py:28: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\"The verbose parameter is deprecated. Please use get_last_lr() \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        actual  predicted\n",
      "0    18.000003  62.833288\n",
      "1    19.999996  62.987896\n",
      "2    23.000004  92.505527\n",
      "3    31.000000  58.724376\n",
      "4    32.000002  98.735047\n",
      "..         ...        ...\n",
      "507  18.000003  27.633315\n",
      "508  19.000006  25.282905\n",
      "509  22.000001  21.659027\n",
      "510  23.000004  28.350865\n",
      "511  27.000002  55.471840\n",
      "\n",
      "[512 rows x 2 columns]\n",
      "Epoch 1/20, Training Loss: 0.6278\n",
      "Epoch 1/20, Validation Loss: 0.3158\n",
      "        actual   predicted\n",
      "0    18.000003   30.375250\n",
      "1    19.999996   29.669560\n",
      "2    23.000004   55.853946\n",
      "3    31.000000   15.319418\n",
      "4    32.000002   43.382568\n",
      "..         ...         ...\n",
      "507  18.000003   48.934176\n",
      "508  19.000006   52.556686\n",
      "509  22.000001   57.522544\n",
      "510  23.000004   81.916407\n",
      "511  27.000002  137.627730\n",
      "\n",
      "[512 rows x 2 columns]\n",
      "Epoch 2/20, Training Loss: 0.5262\n",
      "Epoch 2/20, Validation Loss: 0.2274\n",
      "        actual   predicted\n",
      "0    18.000003    1.959164\n",
      "1    19.999996    6.030810\n",
      "2    23.000004    9.080251\n",
      "3    31.000000    3.357979\n",
      "4    32.000002   13.441727\n",
      "..         ...         ...\n",
      "507  18.000003   47.099498\n",
      "508  19.000006   53.282424\n",
      "509  22.000001   57.457955\n",
      "510  23.000004   91.766573\n",
      "511  27.000002  115.849053\n",
      "\n",
      "[512 rows x 2 columns]\n",
      "Epoch 3/20, Training Loss: 0.5131\n",
      "Epoch 3/20, Validation Loss: 0.2461\n",
      "        actual  predicted\n",
      "0    18.000003  11.736433\n",
      "1    19.999996  17.691905\n",
      "2    23.000004  29.469589\n",
      "3    31.000000  11.878246\n",
      "4    32.000002  32.679362\n",
      "..         ...        ...\n",
      "507  18.000003  10.127680\n",
      "508  19.000006  10.020123\n",
      "509  22.000001  13.788323\n",
      "510  23.000004  19.794335\n",
      "511  27.000002  39.982950\n",
      "\n",
      "[512 rows x 2 columns]\n",
      "Epoch 4/20, Training Loss: 0.5010\n",
      "Epoch 4/20, Validation Loss: 0.2769\n",
      "        actual  predicted\n",
      "0    18.000003   7.463904\n",
      "1    19.999996  10.129847\n",
      "2    23.000004  25.567786\n",
      "3    31.000000  11.571265\n",
      "4    32.000002  40.390030\n",
      "..         ...        ...\n",
      "507  18.000003  16.131982\n",
      "508  19.000006  16.228090\n",
      "509  22.000001  22.685109\n",
      "510  23.000004  18.391050\n",
      "511  27.000002  34.960074\n",
      "\n",
      "[512 rows x 2 columns]\n",
      "Epoch 5/20, Training Loss: 0.5038\n",
      "Epoch 5/20, Validation Loss: 0.2474\n",
      "        actual  predicted\n",
      "0    18.000003 -30.050422\n",
      "1    19.999996 -19.564315\n",
      "2    23.000004   9.353033\n",
      "3    31.000000 -28.555659\n",
      "4    32.000002 -17.338043\n",
      "..         ...        ...\n",
      "507  18.000003 -30.279267\n",
      "508  19.000006 -30.803460\n",
      "509  22.000001 -16.242720\n",
      "510  23.000004 -16.729920\n",
      "511  27.000002  18.736335\n",
      "\n",
      "[512 rows x 2 columns]\n",
      "Epoch 6/20, Training Loss: 0.4939\n",
      "Epoch 6/20, Validation Loss: 0.2612\n",
      "        actual  predicted\n",
      "0    18.000003   8.283663\n",
      "1    19.999996  15.431388\n",
      "2    23.000004  24.192610\n",
      "3    31.000000  12.640007\n",
      "4    32.000002  29.015401\n",
      "..         ...        ...\n",
      "507  18.000003  14.678396\n",
      "508  19.000006  17.293799\n",
      "509  22.000001  18.148966\n",
      "510  23.000004  20.074940\n",
      "511  27.000002  34.606237\n",
      "\n",
      "[512 rows x 2 columns]\n",
      "Early stopping!\n",
      "          actual  predicted\n",
      "0      18.000003   8.283663\n",
      "1      19.999996  15.431388\n",
      "2      23.000004  24.192610\n",
      "3      31.000000  12.640007\n",
      "4      32.000002  29.015401\n",
      "...          ...        ...\n",
      "62740   7.000000   5.261476\n",
      "62741   4.000004   4.934836\n",
      "62742   4.000004   7.946646\n",
      "62743   4.000004   1.575677\n",
      "62744   4.000004  10.714011\n",
      "\n",
      "[62745 rows x 2 columns]\n",
      "Score (RMSE): 366.4133\n",
      "Score (MAE): 94.3700\n",
      "Score (MAPE): 143.2874%\n",
      "training data cutoff:  2023-07-15 02:45:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Studium\\Semester_6\\IoT_Project\\utils.py:911: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_train[columns_to_scale] = scaler.fit_transform(df_train[columns_to_scale])\n",
      "c:\\Studium\\Semester_6\\IoT_Project\\utils.py:912: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_test[columns_to_scale] = scaler.transform(df_test[columns_to_scale])\n",
      "c:\\Studium\\Semester_6\\IoT_Project\\utils.py:916: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_train.drop(['date_time_rounded'], axis=1, inplace=True)\n",
      "c:\\Studium\\Semester_6\\IoT_Project\\utils.py:917: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_test.drop(['date_time_rounded'], axis=1, inplace=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tmp                         float64\n",
      "hum                         float64\n",
      "CO2                         float64\n",
      "VOC                         float64\n",
      "vis                         float64\n",
      "IR                          float64\n",
      "WIFI                        float64\n",
      "BLE                         float64\n",
      "rssi                        float64\n",
      "channel_rssi                float64\n",
      "channel_index               float64\n",
      "spreading_factor            float64\n",
      "bandwidth                   float64\n",
      "f_cnt                       float64\n",
      "isHoliday                   float64\n",
      "isExamTime                  float64\n",
      "weekday                     float64\n",
      "month                       float64\n",
      "hour_sin                    float64\n",
      "semester_SS23               float64\n",
      "semester_WS22/23            float64\n",
      "semester_WS23/24            float64\n",
      "group                       float64\n",
      "device_id_hka-aqm-am001     float64\n",
      "device_id_hka-aqm-am002     float64\n",
      "device_id_hka-aqm-am003a    float64\n",
      "device_id_hka-aqm-am003b    float64\n",
      "device_id_hka-aqm-am004     float64\n",
      "device_id_hka-aqm-am005     float64\n",
      "device_id_hka-aqm-am107     float64\n",
      "device_id_hka-aqm-am109     float64\n",
      "device_id_hka-aqm-am110     float64\n",
      "device_id_hka-aqm-am111     float64\n",
      "device_id_hka-aqm-am115     float64\n",
      "device_id_hka-aqm-am116     float64\n",
      "device_id_hka-aqm-am117     float64\n",
      "device_id_hka-aqm-am123     float64\n",
      "device_id_hka-aqm-am124     float64\n",
      "device_id_hka-aqm-am126     float64\n",
      "device_id_hka-aqm-am201a    float64\n",
      "device_id_hka-aqm-am201b    float64\n",
      "device_id_hka-aqm-am204     float64\n",
      "device_id_hka-aqm-am205     float64\n",
      "device_id_hka-aqm-am209     float64\n",
      "device_id_hka-aqm-am210     float64\n",
      "device_id_hka-aqm-am211     float64\n",
      "device_id_hka-aqm-am301     float64\n",
      "device_id_hka-aqm-am307     float64\n",
      "device_id_hka-aqm-am308     float64\n",
      "dtype: object\n",
      "feature count:  49\n",
      "feature count:  49\n",
      "Training data shape: torch.Size([244176, 20, 49]) torch.Size([244176, 1])\n",
      "Testing data shape: torch.Size([62745, 20, 49]) torch.Size([62745, 1])\n",
      "same columns\n",
      "date_time_rounded           datetime64[ns]\n",
      "tmp                                float64\n",
      "hum                                float64\n",
      "CO2                                float64\n",
      "VOC                                float64\n",
      "vis                                float64\n",
      "IR                                 float64\n",
      "WIFI                               float64\n",
      "BLE                                float64\n",
      "rssi                               float64\n",
      "channel_rssi                       float64\n",
      "channel_index                      float64\n",
      "spreading_factor                   float64\n",
      "bandwidth                          float64\n",
      "f_cnt                              float64\n",
      "isHoliday                          float64\n",
      "isExamTime                         float64\n",
      "weekday                            float64\n",
      "month                              float64\n",
      "hour_sin                           float64\n",
      "semester_SS23                      float64\n",
      "semester_WS22/23                   float64\n",
      "semester_WS23/24                   float64\n",
      "group                                int32\n",
      "device_id_hka-aqm-am001              uint8\n",
      "device_id_hka-aqm-am002              uint8\n",
      "device_id_hka-aqm-am003a             uint8\n",
      "device_id_hka-aqm-am003b             uint8\n",
      "device_id_hka-aqm-am004              uint8\n",
      "device_id_hka-aqm-am005              uint8\n",
      "device_id_hka-aqm-am107              uint8\n",
      "device_id_hka-aqm-am109              uint8\n",
      "device_id_hka-aqm-am110              uint8\n",
      "device_id_hka-aqm-am111              uint8\n",
      "device_id_hka-aqm-am115              uint8\n",
      "device_id_hka-aqm-am116              uint8\n",
      "device_id_hka-aqm-am117              uint8\n",
      "device_id_hka-aqm-am123              uint8\n",
      "device_id_hka-aqm-am124              uint8\n",
      "device_id_hka-aqm-am126              uint8\n",
      "device_id_hka-aqm-am201a             uint8\n",
      "device_id_hka-aqm-am201b             uint8\n",
      "device_id_hka-aqm-am204              uint8\n",
      "device_id_hka-aqm-am205              uint8\n",
      "device_id_hka-aqm-am209              uint8\n",
      "device_id_hka-aqm-am210              uint8\n",
      "device_id_hka-aqm-am211              uint8\n",
      "device_id_hka-aqm-am301              uint8\n",
      "device_id_hka-aqm-am307              uint8\n",
      "device_id_hka-aqm-am308              uint8\n",
      "dtype: object\n",
      "date_time_rounded           datetime64[ns]\n",
      "tmp                                float64\n",
      "hum                                float64\n",
      "CO2                                float64\n",
      "VOC                                float64\n",
      "vis                                float64\n",
      "IR                                 float64\n",
      "WIFI                               float64\n",
      "BLE                                float64\n",
      "rssi                               float64\n",
      "channel_rssi                       float64\n",
      "channel_index                      float64\n",
      "spreading_factor                   float64\n",
      "bandwidth                          float64\n",
      "f_cnt                              float64\n",
      "isHoliday                          float64\n",
      "isExamTime                         float64\n",
      "weekday                            float64\n",
      "month                              float64\n",
      "hour_sin                           float64\n",
      "semester_SS23                      float64\n",
      "semester_WS22/23                   float64\n",
      "semester_WS23/24                   float64\n",
      "group                                int32\n",
      "device_id_hka-aqm-am001              uint8\n",
      "device_id_hka-aqm-am002              uint8\n",
      "device_id_hka-aqm-am003a             uint8\n",
      "device_id_hka-aqm-am003b             uint8\n",
      "device_id_hka-aqm-am004              uint8\n",
      "device_id_hka-aqm-am005              uint8\n",
      "device_id_hka-aqm-am107              uint8\n",
      "device_id_hka-aqm-am109              uint8\n",
      "device_id_hka-aqm-am110              uint8\n",
      "device_id_hka-aqm-am111              uint8\n",
      "device_id_hka-aqm-am115              uint8\n",
      "device_id_hka-aqm-am116              uint8\n",
      "device_id_hka-aqm-am117              uint8\n",
      "device_id_hka-aqm-am123              uint8\n",
      "device_id_hka-aqm-am124              uint8\n",
      "device_id_hka-aqm-am126              uint8\n",
      "device_id_hka-aqm-am201a             uint8\n",
      "device_id_hka-aqm-am201b             uint8\n",
      "device_id_hka-aqm-am204              uint8\n",
      "device_id_hka-aqm-am205              uint8\n",
      "device_id_hka-aqm-am209              uint8\n",
      "device_id_hka-aqm-am210              uint8\n",
      "device_id_hka-aqm-am211              uint8\n",
      "device_id_hka-aqm-am301              uint8\n",
      "device_id_hka-aqm-am307              uint8\n",
      "device_id_hka-aqm-am308              uint8\n",
      "dtype: object\n",
      "         date_time_rounded        tmp        hum         CO2         VOC  \\\n",
      "382774 2022-10-10 14:45:00  24.373333  47.616667  760.000000  487.666667   \n",
      "382775 2022-10-10 16:30:00  25.360000  44.336667  563.666667  555.000000   \n",
      "382776 2022-10-10 17:00:00  25.570000  44.940000  574.000000  579.000000   \n",
      "382777 2022-10-10 17:15:00  25.530000  45.140000  575.000000  585.000000   \n",
      "382778 2022-10-10 17:45:00  25.480000  46.590000  586.000000  620.000000   \n",
      "...                    ...        ...        ...         ...         ...   \n",
      "529479 2023-09-26 22:30:00  27.360000  37.510000  527.000000  951.000000   \n",
      "529480 2023-09-26 22:45:00  27.380000  37.580000  520.000000  950.000000   \n",
      "529481 2023-09-26 23:15:00  27.350000  37.610000  529.000000  966.000000   \n",
      "529482 2023-09-26 23:30:00  27.340000  37.650000  525.000000  944.000000   \n",
      "529483 2023-09-26 23:45:00  27.330000  37.650000  525.000000  951.000000   \n",
      "\n",
      "          vis         IR      WIFI        BLE  rssi  ...  \\\n",
      "382774  207.0  27.000000  1.666667   2.666667 -64.0  ...   \n",
      "382775  115.0  12.666667  1.000000   2.000000 -59.0  ...   \n",
      "382776  157.0  16.000000  0.000000   0.000000 -55.0  ...   \n",
      "382777  155.0  16.000000  0.000000   0.000000 -59.0  ...   \n",
      "382778  157.0  18.000000  0.000000   0.000000 -60.0  ...   \n",
      "...       ...        ...       ...        ...   ...  ...   \n",
      "529479    4.0   1.000000  2.000000   0.000000 -73.0  ...   \n",
      "529480    7.0   3.000000  2.000000   0.000000 -73.0  ...   \n",
      "529481    4.0   0.000000  6.000000  27.000000 -75.0  ...   \n",
      "529482    4.0   0.000000  0.000000   0.000000 -75.0  ...   \n",
      "529483    4.0   0.000000  0.000000   0.000000 -70.0  ...   \n",
      "\n",
      "        device_id_hka-aqm-am201a  device_id_hka-aqm-am201b  \\\n",
      "382774                         0                         0   \n",
      "382775                         0                         0   \n",
      "382776                         0                         0   \n",
      "382777                         0                         0   \n",
      "382778                         0                         0   \n",
      "...                          ...                       ...   \n",
      "529479                         0                         0   \n",
      "529480                         0                         0   \n",
      "529481                         0                         0   \n",
      "529482                         0                         0   \n",
      "529483                         0                         0   \n",
      "\n",
      "        device_id_hka-aqm-am204  device_id_hka-aqm-am205  \\\n",
      "382774                        0                        0   \n",
      "382775                        0                        0   \n",
      "382776                        0                        0   \n",
      "382777                        0                        0   \n",
      "382778                        0                        0   \n",
      "...                         ...                      ...   \n",
      "529479                        0                        0   \n",
      "529480                        0                        0   \n",
      "529481                        0                        0   \n",
      "529482                        0                        0   \n",
      "529483                        0                        0   \n",
      "\n",
      "        device_id_hka-aqm-am209  device_id_hka-aqm-am210  \\\n",
      "382774                        0                        0   \n",
      "382775                        0                        0   \n",
      "382776                        0                        0   \n",
      "382777                        0                        0   \n",
      "382778                        0                        0   \n",
      "...                         ...                      ...   \n",
      "529479                        0                        0   \n",
      "529480                        0                        0   \n",
      "529481                        0                        0   \n",
      "529482                        0                        0   \n",
      "529483                        0                        0   \n",
      "\n",
      "        device_id_hka-aqm-am211  device_id_hka-aqm-am301  \\\n",
      "382774                        0                        0   \n",
      "382775                        0                        0   \n",
      "382776                        0                        0   \n",
      "382777                        0                        0   \n",
      "382778                        0                        0   \n",
      "...                         ...                      ...   \n",
      "529479                        0                        0   \n",
      "529480                        0                        0   \n",
      "529481                        0                        0   \n",
      "529482                        0                        0   \n",
      "529483                        0                        0   \n",
      "\n",
      "        device_id_hka-aqm-am307  device_id_hka-aqm-am308  \n",
      "382774                        0                        0  \n",
      "382775                        0                        0  \n",
      "382776                        0                        0  \n",
      "382777                        0                        0  \n",
      "382778                        0                        0  \n",
      "...                         ...                      ...  \n",
      "529479                        0                        1  \n",
      "529480                        0                        1  \n",
      "529481                        0                        1  \n",
      "529482                        0                        1  \n",
      "529483                        0                        1  \n",
      "\n",
      "[146710 rows x 50 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\t-ehm\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\transformer.py:286: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
      "c:\\Users\\t-ehm\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\optim\\lr_scheduler.py:28: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\"The verbose parameter is deprecated. Please use get_last_lr() \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          actual   predicted\n",
      "0    1132.999985  877.954182\n",
      "1     954.999998  960.325586\n",
      "2     990.000007  746.034679\n",
      "3     811.000001  771.207534\n",
      "4     739.000000  588.825468\n",
      "..           ...         ...\n",
      "507  1017.000004  834.534656\n",
      "508  1033.999992  767.245761\n",
      "509  1121.999998  775.217987\n",
      "510  1019.999995  844.230736\n",
      "511  1023.000005  732.112472\n",
      "\n",
      "[512 rows x 2 columns]\n",
      "Epoch 1/20, Training Loss: 0.1510\n",
      "Epoch 1/20, Validation Loss: 0.1695\n",
      "          actual   predicted\n",
      "0    1132.999985  912.938098\n",
      "1     954.999998  974.630389\n",
      "2     990.000007  794.167024\n",
      "3     811.000001  826.347546\n",
      "4     739.000000  649.138048\n",
      "..           ...         ...\n",
      "507  1017.000004  878.117356\n",
      "508  1033.999992  818.650986\n",
      "509  1121.999998  835.079911\n",
      "510  1019.999995  908.594551\n",
      "511  1023.000005  801.694165\n",
      "\n",
      "[512 rows x 2 columns]\n",
      "Epoch 2/20, Training Loss: 0.0788\n",
      "Epoch 2/20, Validation Loss: 0.1307\n",
      "          actual    predicted\n",
      "0    1132.999985   950.759436\n",
      "1     954.999998  1014.300542\n",
      "2     990.000007   817.679683\n",
      "3     811.000001   843.751756\n",
      "4     739.000000   653.070539\n",
      "..           ...          ...\n",
      "507  1017.000004   898.098687\n",
      "508  1033.999992   843.682794\n",
      "509  1121.999998   861.575757\n",
      "510  1019.999995   943.944862\n",
      "511  1023.000005   829.508799\n",
      "\n",
      "[512 rows x 2 columns]\n",
      "Epoch 3/20, Training Loss: 0.0682\n",
      "Epoch 3/20, Validation Loss: 0.1908\n",
      "          actual   predicted\n",
      "0    1132.999985  927.600797\n",
      "1     954.999998  984.844052\n",
      "2     990.000007  804.609916\n",
      "3     811.000001  824.763058\n",
      "4     739.000000  662.648533\n",
      "..           ...         ...\n",
      "507  1017.000004  857.441029\n",
      "508  1033.999992  808.694698\n",
      "509  1121.999998  828.320379\n",
      "510  1019.999995  894.757044\n",
      "511  1023.000005  798.229812\n",
      "\n",
      "[512 rows x 2 columns]\n",
      "Epoch 4/20, Training Loss: 0.0632\n",
      "Epoch 4/20, Validation Loss: 0.0871\n",
      "          actual    predicted\n",
      "0    1132.999985  1056.302342\n",
      "1     954.999998  1109.062900\n",
      "2     990.000007   916.501932\n",
      "3     811.000001   950.873689\n",
      "4     739.000000   741.442432\n",
      "..           ...          ...\n",
      "507  1017.000004  1011.738613\n",
      "508  1033.999992   952.390551\n",
      "509  1121.999998   964.217691\n",
      "510  1019.999995  1042.399813\n",
      "511  1023.000005   935.202396\n",
      "\n",
      "[512 rows x 2 columns]\n",
      "Epoch 5/20, Training Loss: 0.0596\n",
      "Epoch 5/20, Validation Loss: 0.0516\n",
      "          actual    predicted\n",
      "0    1132.999985  1026.400585\n",
      "1     954.999998  1080.194002\n",
      "2     990.000007   875.551471\n",
      "3     811.000001   910.009775\n",
      "4     739.000000   720.860347\n",
      "..           ...          ...\n",
      "507  1017.000004   995.364082\n",
      "508  1033.999992   937.425477\n",
      "509  1121.999998   957.277029\n",
      "510  1019.999995  1040.625096\n",
      "511  1023.000005   921.320938\n",
      "\n",
      "[512 rows x 2 columns]\n",
      "Epoch 6/20, Training Loss: 0.0574\n",
      "Epoch 6/20, Validation Loss: 0.0601\n",
      "          actual    predicted\n",
      "0    1132.999985  1041.343887\n",
      "1     954.999998  1081.359071\n",
      "2     990.000007   908.144608\n",
      "3     811.000001   947.059480\n",
      "4     739.000000   754.208619\n",
      "..           ...          ...\n",
      "507  1017.000004   968.471188\n",
      "508  1033.999992   912.693001\n",
      "509  1121.999998   932.143858\n",
      "510  1019.999995  1005.728995\n",
      "511  1023.000005   894.709996\n",
      "\n",
      "[512 rows x 2 columns]\n",
      "Epoch 7/20, Training Loss: 0.0568\n",
      "Epoch 7/20, Validation Loss: 0.0551\n",
      "          actual    predicted\n",
      "0    1132.999985  1086.074515\n",
      "1     954.999998  1136.404167\n",
      "2     990.000007   954.035329\n",
      "3     811.000001   989.928499\n",
      "4     739.000000   786.673931\n",
      "..           ...          ...\n",
      "507  1017.000004  1028.142759\n",
      "508  1033.999992   969.966775\n",
      "509  1121.999998   971.988098\n",
      "510  1019.999995  1049.146605\n",
      "511  1023.000005   944.017701\n",
      "\n",
      "[512 rows x 2 columns]\n",
      "Epoch 8/20, Training Loss: 0.0555\n",
      "Epoch 8/20, Validation Loss: 0.0452\n",
      "          actual    predicted\n",
      "0    1132.999985  1096.777859\n",
      "1     954.999998  1152.221359\n",
      "2     990.000007   949.411728\n",
      "3     811.000001   994.910369\n",
      "4     739.000000   781.834277\n",
      "..           ...          ...\n",
      "507  1017.000004  1059.289984\n",
      "508  1033.999992   988.610796\n",
      "509  1121.999998   993.173340\n",
      "510  1019.999995  1076.349184\n",
      "511  1023.000005   965.369843\n",
      "\n",
      "[512 rows x 2 columns]\n",
      "Epoch 9/20, Training Loss: 0.0542\n",
      "Epoch 9/20, Validation Loss: 0.0539\n",
      "          actual    predicted\n",
      "0    1132.999985  1142.549686\n",
      "1     954.999998  1198.330890\n",
      "2     990.000007   997.310703\n",
      "3     811.000001  1022.512046\n",
      "4     739.000000   806.037175\n",
      "..           ...          ...\n",
      "507  1017.000004  1070.957375\n",
      "508  1033.999992  1006.337365\n",
      "509  1121.999998  1026.915036\n",
      "510  1019.999995  1109.133983\n",
      "511  1023.000005  1007.027677\n",
      "\n",
      "[512 rows x 2 columns]\n",
      "Epoch 10/20, Training Loss: 0.0543\n",
      "Epoch 10/20, Validation Loss: 0.0378\n",
      "          actual    predicted\n",
      "0    1132.999985  1163.399177\n",
      "1     954.999998  1222.076588\n",
      "2     990.000007   993.407525\n",
      "3     811.000001  1033.368981\n",
      "4     739.000000   786.933980\n",
      "..           ...          ...\n",
      "507  1017.000004  1075.132125\n",
      "508  1033.999992  1003.378752\n",
      "509  1121.999998  1013.587003\n",
      "510  1019.999995  1104.529421\n",
      "511  1023.000005   988.462066\n",
      "\n",
      "[512 rows x 2 columns]\n",
      "Epoch 11/20, Training Loss: 0.0535\n",
      "Epoch 11/20, Validation Loss: 0.0436\n",
      "          actual    predicted\n",
      "0    1132.999985  1172.954450\n",
      "1     954.999998  1224.559964\n",
      "2     990.000007  1041.649190\n",
      "3     811.000001  1073.248229\n",
      "4     739.000000   848.570957\n",
      "..           ...          ...\n",
      "507  1017.000004  1106.452265\n",
      "508  1033.999992  1041.928072\n",
      "509  1121.999998  1056.060651\n",
      "510  1019.999995  1130.996264\n",
      "511  1023.000005  1032.764444\n",
      "\n",
      "[512 rows x 2 columns]\n",
      "Epoch 12/20, Training Loss: 0.0532\n",
      "Epoch 12/20, Validation Loss: 0.0408\n",
      "          actual    predicted\n",
      "0    1132.999985  1143.217569\n",
      "1     954.999998  1205.249728\n",
      "2     990.000007   983.234052\n",
      "3     811.000001  1033.655085\n",
      "4     739.000000   803.191034\n",
      "..           ...          ...\n",
      "507  1017.000004  1088.399775\n",
      "508  1033.999992  1022.926847\n",
      "509  1121.999998  1038.686780\n",
      "510  1019.999995  1134.308390\n",
      "511  1023.000005  1016.278853\n",
      "\n",
      "[512 rows x 2 columns]\n",
      "Epoch 13/20, Training Loss: 0.0525\n",
      "Epoch 13/20, Validation Loss: 0.0341\n",
      "          actual    predicted\n",
      "0    1132.999985  1107.442130\n",
      "1     954.999998  1153.815443\n",
      "2     990.000007   972.980483\n",
      "3     811.000001  1010.151752\n",
      "4     739.000000   788.657426\n",
      "..           ...          ...\n",
      "507  1017.000004  1086.190579\n",
      "508  1033.999992  1019.857387\n",
      "509  1121.999998  1035.005845\n",
      "510  1019.999995  1126.225512\n",
      "511  1023.000005  1021.534033\n",
      "\n",
      "[512 rows x 2 columns]\n",
      "Epoch 14/20, Training Loss: 0.0521\n",
      "Epoch 14/20, Validation Loss: 0.0361\n",
      "          actual    predicted\n",
      "0    1132.999985  1094.210093\n",
      "1     954.999998  1146.347642\n",
      "2     990.000007   962.501600\n",
      "3     811.000001  1012.034370\n",
      "4     739.000000   787.206171\n",
      "..           ...          ...\n",
      "507  1017.000004  1066.171009\n",
      "508  1033.999992  1000.634682\n",
      "509  1121.999998  1012.832955\n",
      "510  1019.999995  1105.666420\n",
      "511  1023.000005  1000.489873\n",
      "\n",
      "[512 rows x 2 columns]\n",
      "Epoch 15/20, Training Loss: 0.0519\n",
      "Epoch 15/20, Validation Loss: 0.0485\n",
      "          actual    predicted\n",
      "0    1132.999985  1107.680538\n",
      "1     954.999998  1159.854427\n",
      "2     990.000007   969.608435\n",
      "3     811.000001  1015.543507\n",
      "4     739.000000   804.101409\n",
      "..           ...          ...\n",
      "507  1017.000004  1074.283590\n",
      "508  1033.999992  1009.063070\n",
      "509  1121.999998  1018.667441\n",
      "510  1019.999995  1096.587927\n",
      "511  1023.000005   991.721546\n",
      "\n",
      "[512 rows x 2 columns]\n",
      "Epoch 16/20, Training Loss: 0.0518\n",
      "Epoch 16/20, Validation Loss: 0.0462\n",
      "          actual    predicted\n",
      "0    1132.999985  1134.838438\n",
      "1     954.999998  1187.159638\n",
      "2     990.000007   992.672942\n",
      "3     811.000001  1040.079149\n",
      "4     739.000000   812.600279\n",
      "..           ...          ...\n",
      "507  1017.000004  1087.933179\n",
      "508  1033.999992  1023.311075\n",
      "509  1121.999998  1032.948502\n",
      "510  1019.999995  1124.651586\n",
      "511  1023.000005   999.659313\n",
      "\n",
      "[512 rows x 2 columns]\n",
      "Epoch 17/20, Training Loss: 0.0517\n",
      "Epoch 17/20, Validation Loss: 0.0322\n",
      "          actual    predicted\n",
      "0    1132.999985  1100.243719\n",
      "1     954.999998  1141.728779\n",
      "2     990.000007   979.659102\n",
      "3     811.000001  1016.091938\n",
      "4     739.000000   820.346576\n",
      "..           ...          ...\n",
      "507  1017.000004  1057.556185\n",
      "508  1033.999992  1007.830503\n",
      "509  1121.999998  1019.237182\n",
      "510  1019.999995  1092.843523\n",
      "511  1023.000005  1001.222256\n",
      "\n",
      "[512 rows x 2 columns]\n",
      "Epoch 18/20, Training Loss: 0.0514\n",
      "Epoch 18/20, Validation Loss: 0.0421\n",
      "          actual    predicted\n",
      "0    1132.999985  1178.947194\n",
      "1     954.999998  1241.805511\n",
      "2     990.000007  1037.030273\n",
      "3     811.000001  1080.757373\n",
      "4     739.000000   849.516897\n",
      "..           ...          ...\n",
      "507  1017.000004  1115.596126\n",
      "508  1033.999992  1052.661740\n",
      "509  1121.999998  1058.442869\n",
      "510  1019.999995  1154.691747\n",
      "511  1023.000005  1036.325021\n",
      "\n",
      "[512 rows x 2 columns]\n",
      "Epoch 19/20, Training Loss: 0.0509\n",
      "Epoch 19/20, Validation Loss: 0.0374\n",
      "          actual    predicted\n",
      "0    1132.999985  1127.534911\n",
      "1     954.999998  1171.956990\n",
      "2     990.000007   985.876414\n",
      "3     811.000001  1021.560915\n",
      "4     739.000000   801.740409\n",
      "..           ...          ...\n",
      "507  1017.000004  1071.351611\n",
      "508  1033.999992  1012.650458\n",
      "509  1121.999998  1026.769766\n",
      "510  1019.999995  1110.420066\n",
      "511  1023.000005  1009.166216\n",
      "\n",
      "[512 rows x 2 columns]\n",
      "Epoch 20/20, Training Loss: 0.0514\n",
      "Epoch 20/20, Validation Loss: 0.0386\n",
      "            actual    predicted\n",
      "0      1132.999985  1127.534911\n",
      "1       954.999998  1171.956990\n",
      "2       990.000007   985.876414\n",
      "3       811.000001  1021.560915\n",
      "4       739.000000   801.740409\n",
      "...            ...          ...\n",
      "62740   949.999994   981.297883\n",
      "62741   947.999999   979.450202\n",
      "62742   966.000003   973.652004\n",
      "62743   943.999993  1017.997109\n",
      "62744   951.000009   973.240024\n",
      "\n",
      "[62745 rows x 2 columns]\n",
      "Score (RMSE): 58.4235\n",
      "Score (MAE): 36.3309\n",
      "Score (MAPE): 4.9989%\n"
     ]
    }
   ],
   "source": [
    "importlib.reload(utils)\n",
    "for y_feature in ['CO2', 'hum', 'tmp', 'vis', 'VOC']:\n",
    "    aggregation_level = 'quarter_hour'\n",
    "    model, scaler, rmse, mae, mape = utils.create_multivariate_transformer_model_for_feature(df, d_model=128, nhead=8, num_layers=4, dropout=0.1, batch_size=512, learning_rate=0.00031, epochs=20, y_feature=y_feature, aggregation_level=aggregation_level)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training data cutoff:  2023-07-14 05:00:00\n",
      "tmp                         float64\n",
      "hum                         float64\n",
      "CO2                         float64\n",
      "VOC                         float64\n",
      "vis                         float64\n",
      "IR                          float64\n",
      "WIFI                        float64\n",
      "BLE                         float64\n",
      "rssi                        float64\n",
      "channel_rssi                float64\n",
      "channel_index               float64\n",
      "spreading_factor            float64\n",
      "bandwidth                   float64\n",
      "f_cnt                       float64\n",
      "isHoliday                   float64\n",
      "isExamTime                  float64\n",
      "weekday                     float64\n",
      "month                       float64\n",
      "hour_sin                    float64\n",
      "semester_SS23               float64\n",
      "semester_WS22/23            float64\n",
      "semester_WS23/24            float64\n",
      "group                       float64\n",
      "device_id_hka-aqm-am001     float64\n",
      "device_id_hka-aqm-am002     float64\n",
      "device_id_hka-aqm-am003a    float64\n",
      "device_id_hka-aqm-am003b    float64\n",
      "device_id_hka-aqm-am004     float64\n",
      "device_id_hka-aqm-am005     float64\n",
      "device_id_hka-aqm-am107     float64\n",
      "device_id_hka-aqm-am109     float64\n",
      "device_id_hka-aqm-am110     float64\n",
      "device_id_hka-aqm-am111     float64\n",
      "device_id_hka-aqm-am115     float64\n",
      "device_id_hka-aqm-am116     float64\n",
      "device_id_hka-aqm-am117     float64\n",
      "device_id_hka-aqm-am123     float64\n",
      "device_id_hka-aqm-am124     float64\n",
      "device_id_hka-aqm-am126     float64\n",
      "device_id_hka-aqm-am201a    float64\n",
      "device_id_hka-aqm-am201b    float64\n",
      "device_id_hka-aqm-am204     float64\n",
      "device_id_hka-aqm-am205     float64\n",
      "device_id_hka-aqm-am209     float64\n",
      "device_id_hka-aqm-am210     float64\n",
      "device_id_hka-aqm-am211     float64\n",
      "device_id_hka-aqm-am301     float64\n",
      "device_id_hka-aqm-am307     float64\n",
      "device_id_hka-aqm-am308     float64\n",
      "dtype: object\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Studium\\Semester_6\\IoT_Project\\utils.py:911: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_train[columns_to_scale] = scaler.fit_transform(df_train[columns_to_scale])\n",
      "c:\\Studium\\Semester_6\\IoT_Project\\utils.py:912: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_test[columns_to_scale] = scaler.transform(df_test[columns_to_scale])\n",
      "c:\\Studium\\Semester_6\\IoT_Project\\utils.py:916: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_train.drop(['date_time_rounded'], axis=1, inplace=True)\n",
      "c:\\Studium\\Semester_6\\IoT_Project\\utils.py:917: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_test.drop(['date_time_rounded'], axis=1, inplace=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "feature count:  49\n",
      "feature count:  49\n",
      "Training data shape: torch.Size([75940, 20, 49]) torch.Size([75940, 1])\n",
      "Testing data shape: torch.Size([19215, 20, 49]) torch.Size([19215, 1])\n",
      "same columns\n",
      "date_time_rounded           datetime64[ns]\n",
      "tmp                                float64\n",
      "hum                                float64\n",
      "CO2                                float64\n",
      "VOC                                float64\n",
      "vis                                float64\n",
      "IR                                 float64\n",
      "WIFI                               float64\n",
      "BLE                                float64\n",
      "rssi                               float64\n",
      "channel_rssi                       float64\n",
      "channel_index                      float64\n",
      "spreading_factor                   float64\n",
      "bandwidth                          float64\n",
      "f_cnt                              float64\n",
      "isHoliday                          float64\n",
      "isExamTime                         float64\n",
      "weekday                            float64\n",
      "month                              float64\n",
      "hour_sin                           float64\n",
      "semester_SS23                      float64\n",
      "semester_WS22/23                   float64\n",
      "semester_WS23/24                   float64\n",
      "group                                int32\n",
      "device_id_hka-aqm-am001              uint8\n",
      "device_id_hka-aqm-am002              uint8\n",
      "device_id_hka-aqm-am003a             uint8\n",
      "device_id_hka-aqm-am003b             uint8\n",
      "device_id_hka-aqm-am004              uint8\n",
      "device_id_hka-aqm-am005              uint8\n",
      "device_id_hka-aqm-am107              uint8\n",
      "device_id_hka-aqm-am109              uint8\n",
      "device_id_hka-aqm-am110              uint8\n",
      "device_id_hka-aqm-am111              uint8\n",
      "device_id_hka-aqm-am115              uint8\n",
      "device_id_hka-aqm-am116              uint8\n",
      "device_id_hka-aqm-am117              uint8\n",
      "device_id_hka-aqm-am123              uint8\n",
      "device_id_hka-aqm-am124              uint8\n",
      "device_id_hka-aqm-am126              uint8\n",
      "device_id_hka-aqm-am201a             uint8\n",
      "device_id_hka-aqm-am201b             uint8\n",
      "device_id_hka-aqm-am204              uint8\n",
      "device_id_hka-aqm-am205              uint8\n",
      "device_id_hka-aqm-am209              uint8\n",
      "device_id_hka-aqm-am210              uint8\n",
      "device_id_hka-aqm-am211              uint8\n",
      "device_id_hka-aqm-am301              uint8\n",
      "device_id_hka-aqm-am307              uint8\n",
      "device_id_hka-aqm-am308              uint8\n",
      "dtype: object\n",
      "date_time_rounded           datetime64[ns]\n",
      "tmp                                float64\n",
      "hum                                float64\n",
      "CO2                                float64\n",
      "VOC                                float64\n",
      "vis                                float64\n",
      "IR                                 float64\n",
      "WIFI                               float64\n",
      "BLE                                float64\n",
      "rssi                               float64\n",
      "channel_rssi                       float64\n",
      "channel_index                      float64\n",
      "spreading_factor                   float64\n",
      "bandwidth                          float64\n",
      "f_cnt                              float64\n",
      "isHoliday                          float64\n",
      "isExamTime                         float64\n",
      "weekday                            float64\n",
      "month                              float64\n",
      "hour_sin                           float64\n",
      "semester_SS23                      float64\n",
      "semester_WS22/23                   float64\n",
      "semester_WS23/24                   float64\n",
      "group                                int32\n",
      "device_id_hka-aqm-am001              uint8\n",
      "device_id_hka-aqm-am002              uint8\n",
      "device_id_hka-aqm-am003a             uint8\n",
      "device_id_hka-aqm-am003b             uint8\n",
      "device_id_hka-aqm-am004              uint8\n",
      "device_id_hka-aqm-am005              uint8\n",
      "device_id_hka-aqm-am107              uint8\n",
      "device_id_hka-aqm-am109              uint8\n",
      "device_id_hka-aqm-am110              uint8\n",
      "device_id_hka-aqm-am111              uint8\n",
      "device_id_hka-aqm-am115              uint8\n",
      "device_id_hka-aqm-am116              uint8\n",
      "device_id_hka-aqm-am117              uint8\n",
      "device_id_hka-aqm-am123              uint8\n",
      "device_id_hka-aqm-am124              uint8\n",
      "device_id_hka-aqm-am126              uint8\n",
      "device_id_hka-aqm-am201a             uint8\n",
      "device_id_hka-aqm-am201b             uint8\n",
      "device_id_hka-aqm-am204              uint8\n",
      "device_id_hka-aqm-am205              uint8\n",
      "device_id_hka-aqm-am209              uint8\n",
      "device_id_hka-aqm-am210              uint8\n",
      "device_id_hka-aqm-am211              uint8\n",
      "device_id_hka-aqm-am301              uint8\n",
      "device_id_hka-aqm-am307              uint8\n",
      "device_id_hka-aqm-am308              uint8\n",
      "dtype: object\n",
      "         date_time_rounded        tmp        hum         CO2         VOC  \\\n",
      "100258 2022-10-10 15:00:00  24.310909  47.668182  754.000000  485.090909   \n",
      "100259 2022-10-10 17:00:00  25.455000  44.930000  589.500000  585.833333   \n",
      "100260 2022-10-10 20:00:00  25.072500  50.062500  613.250000  601.750000   \n",
      "100261 2022-10-10 21:00:00  24.945000  51.042500  598.500000  568.250000   \n",
      "100262 2022-10-11 01:00:00  24.865000  49.527500  583.750000  562.000000   \n",
      "...                    ...        ...        ...         ...         ...   \n",
      "148552 2023-09-26 13:00:00  27.807500  36.012500  472.500000  962.250000   \n",
      "148553 2023-09-26 14:00:00  28.415714  35.207143  473.714286  952.857143   \n",
      "148554 2023-09-26 17:00:00  27.802500  36.237500  504.000000  925.500000   \n",
      "148555 2023-09-26 19:00:00  27.620000  36.787500  512.500000  932.500000   \n",
      "148556 2023-09-26 20:00:00  27.545000  37.025000  518.500000  954.750000   \n",
      "\n",
      "                vis          IR      WIFI        BLE        rssi  ...  \\\n",
      "100258   198.363636   25.000000  1.090909   1.363636  -68.090909  ...   \n",
      "100259   132.833333   14.166667  0.500000   0.500000  -58.000000  ...   \n",
      "100260     9.000000    1.000000  0.500000   0.000000  -62.250000  ...   \n",
      "100261     9.000000    1.000000  0.750000   0.000000  -61.750000  ...   \n",
      "100262     9.500000    1.500000  0.750000   0.000000  -59.000000  ...   \n",
      "...             ...         ...       ...        ...         ...  ...   \n",
      "148552  1127.250000  257.250000  1.000000   0.500000 -101.750000  ...   \n",
      "148553   608.285714  143.142857  1.857143  17.142857  -90.142857  ...   \n",
      "148554    49.750000   13.000000  3.000000  13.750000  -72.250000  ...   \n",
      "148555     6.000000    1.250000  2.250000   6.750000  -87.750000  ...   \n",
      "148556     5.500000    1.250000  3.500000  13.500000  -72.750000  ...   \n",
      "\n",
      "        device_id_hka-aqm-am201a  device_id_hka-aqm-am201b  \\\n",
      "100258                         0                         0   \n",
      "100259                         0                         0   \n",
      "100260                         0                         0   \n",
      "100261                         0                         0   \n",
      "100262                         0                         0   \n",
      "...                          ...                       ...   \n",
      "148552                         0                         0   \n",
      "148553                         0                         0   \n",
      "148554                         0                         0   \n",
      "148555                         0                         0   \n",
      "148556                         0                         0   \n",
      "\n",
      "        device_id_hka-aqm-am204  device_id_hka-aqm-am205  \\\n",
      "100258                        0                        0   \n",
      "100259                        0                        0   \n",
      "100260                        0                        0   \n",
      "100261                        0                        0   \n",
      "100262                        0                        0   \n",
      "...                         ...                      ...   \n",
      "148552                        0                        0   \n",
      "148553                        0                        0   \n",
      "148554                        0                        0   \n",
      "148555                        0                        0   \n",
      "148556                        0                        0   \n",
      "\n",
      "        device_id_hka-aqm-am209  device_id_hka-aqm-am210  \\\n",
      "100258                        0                        0   \n",
      "100259                        0                        0   \n",
      "100260                        0                        0   \n",
      "100261                        0                        0   \n",
      "100262                        0                        0   \n",
      "...                         ...                      ...   \n",
      "148552                        0                        0   \n",
      "148553                        0                        0   \n",
      "148554                        0                        0   \n",
      "148555                        0                        0   \n",
      "148556                        0                        0   \n",
      "\n",
      "        device_id_hka-aqm-am211  device_id_hka-aqm-am301  \\\n",
      "100258                        0                        0   \n",
      "100259                        0                        0   \n",
      "100260                        0                        0   \n",
      "100261                        0                        0   \n",
      "100262                        0                        0   \n",
      "...                         ...                      ...   \n",
      "148552                        0                        0   \n",
      "148553                        0                        0   \n",
      "148554                        0                        0   \n",
      "148555                        0                        0   \n",
      "148556                        0                        0   \n",
      "\n",
      "        device_id_hka-aqm-am307  device_id_hka-aqm-am308  \n",
      "100258                        0                        0  \n",
      "100259                        0                        0  \n",
      "100260                        0                        0  \n",
      "100261                        0                        0  \n",
      "100262                        0                        0  \n",
      "...                         ...                      ...  \n",
      "148552                        0                        1  \n",
      "148553                        0                        1  \n",
      "148554                        0                        1  \n",
      "148555                        0                        1  \n",
      "148556                        0                        1  \n",
      "\n",
      "[48299 rows x 50 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\t-ehm\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\transformer.py:286: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
      "c:\\Users\\t-ehm\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\optim\\lr_scheduler.py:28: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\"The verbose parameter is deprecated. Please use get_last_lr() \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         actual   predicted\n",
      "0    408.166663  478.762511\n",
      "1    406.750003  476.468135\n",
      "2    416.250001  478.674079\n",
      "3    437.333332  491.187812\n",
      "4    503.000000  508.027337\n",
      "..          ...         ...\n",
      "507  452.249999  491.632530\n",
      "508  444.999998  484.226118\n",
      "509  440.249999  475.998404\n",
      "510  434.500002  477.252333\n",
      "511  429.999998  480.146462\n",
      "\n",
      "[512 rows x 2 columns]\n",
      "Epoch 1/25, Training Loss: 0.5054\n",
      "Epoch 1/25, Validation Loss: 0.1601\n",
      "         actual   predicted\n",
      "0    408.166663  464.444041\n",
      "1    406.750003  464.838835\n",
      "2    416.250001  461.922068\n",
      "3    437.333332  474.372694\n",
      "4    503.000000  485.195404\n",
      "..          ...         ...\n",
      "507  452.249999  450.896063\n",
      "508  444.999998  451.213721\n",
      "509  440.249999  445.025941\n",
      "510  434.500002  447.355616\n",
      "511  429.999998  450.255400\n",
      "\n",
      "[512 rows x 2 columns]\n",
      "Epoch 2/25, Training Loss: 0.3970\n",
      "Epoch 2/25, Validation Loss: 0.0885\n",
      "         actual   predicted\n",
      "0    408.166663  444.186263\n",
      "1    406.750003  441.876761\n",
      "2    416.250001  440.858521\n",
      "3    437.333332  455.791817\n",
      "4    503.000000  469.264979\n",
      "..          ...         ...\n",
      "507  452.249999  472.002850\n",
      "508  444.999998  470.853676\n",
      "509  440.249999  455.987680\n",
      "510  434.500002  451.633646\n",
      "511  429.999998  452.598843\n",
      "\n",
      "[512 rows x 2 columns]\n",
      "Epoch 3/25, Training Loss: 0.3709\n",
      "Epoch 3/25, Validation Loss: 0.0841\n",
      "         actual   predicted\n",
      "0    408.166663  442.491180\n",
      "1    406.750003  438.429282\n",
      "2    416.250001  436.063448\n",
      "3    437.333332  453.138053\n",
      "4    503.000000  474.758205\n",
      "..          ...         ...\n",
      "507  452.249999  480.508588\n",
      "508  444.999998  480.483713\n",
      "509  440.249999  465.960848\n",
      "510  434.500002  467.527493\n",
      "511  429.999998  469.471067\n",
      "\n",
      "[512 rows x 2 columns]\n",
      "Epoch 4/25, Training Loss: 0.3678\n",
      "Epoch 4/25, Validation Loss: 0.0859\n",
      "         actual   predicted\n",
      "0    408.166663  440.704477\n",
      "1    406.750003  441.259934\n",
      "2    416.250001  435.836605\n",
      "3    437.333332  455.468760\n",
      "4    503.000000  475.209675\n",
      "..          ...         ...\n",
      "507  452.249999  454.495375\n",
      "508  444.999998  457.573130\n",
      "509  440.249999  445.611336\n",
      "510  434.500002  446.925871\n",
      "511  429.999998  448.648605\n",
      "\n",
      "[512 rows x 2 columns]\n",
      "Epoch 5/25, Training Loss: 0.3542\n",
      "Epoch 5/25, Validation Loss: 0.0640\n",
      "         actual   predicted\n",
      "0    408.166663  465.952197\n",
      "1    406.750003  463.293511\n",
      "2    416.250001  459.080595\n",
      "3    437.333332  478.355315\n",
      "4    503.000000  502.004896\n",
      "..          ...         ...\n",
      "507  452.249999  481.119688\n",
      "508  444.999998  480.631052\n",
      "509  440.249999  466.288793\n",
      "510  434.500002  465.563428\n",
      "511  429.999998  465.405333\n",
      "\n",
      "[512 rows x 2 columns]\n",
      "Epoch 6/25, Training Loss: 0.3469\n",
      "Epoch 6/25, Validation Loss: 0.0880\n",
      "         actual   predicted\n",
      "0    408.166663  456.008084\n",
      "1    406.750003  452.691441\n",
      "2    416.250001  450.166147\n",
      "3    437.333332  466.917222\n",
      "4    503.000000  491.208704\n",
      "..          ...         ...\n",
      "507  452.249999  471.772613\n",
      "508  444.999998  468.191841\n",
      "509  440.249999  455.909808\n",
      "510  434.500002  459.455334\n",
      "511  429.999998  464.225464\n",
      "\n",
      "[512 rows x 2 columns]\n",
      "Epoch 7/25, Training Loss: 0.3490\n",
      "Epoch 7/25, Validation Loss: 0.0828\n",
      "         actual   predicted\n",
      "0    408.166663  458.585794\n",
      "1    406.750003  455.858842\n",
      "2    416.250001  453.407335\n",
      "3    437.333332  468.754206\n",
      "4    503.000000  495.588004\n",
      "..          ...         ...\n",
      "507  452.249999  485.119346\n",
      "508  444.999998  477.492899\n",
      "509  440.249999  467.922066\n",
      "510  434.500002  470.430264\n",
      "511  429.999998  469.812293\n",
      "\n",
      "[512 rows x 2 columns]\n",
      "Epoch 8/25, Training Loss: 0.3383\n",
      "Epoch 8/25, Validation Loss: 0.1093\n",
      "         actual   predicted\n",
      "0    408.166663  444.713121\n",
      "1    406.750003  442.295114\n",
      "2    416.250001  437.735244\n",
      "3    437.333332  445.275234\n",
      "4    503.000000  463.015634\n",
      "..          ...         ...\n",
      "507  452.249999  476.555083\n",
      "508  444.999998  473.548719\n",
      "509  440.249999  467.147364\n",
      "510  434.500002  471.278055\n",
      "511  429.999998  469.814088\n",
      "\n",
      "[512 rows x 2 columns]\n",
      "Epoch 9/25, Training Loss: 0.3322\n",
      "Epoch 9/25, Validation Loss: 0.0680\n",
      "         actual   predicted\n",
      "0    408.166663  436.858793\n",
      "1    406.750003  434.131927\n",
      "2    416.250001  431.551709\n",
      "3    437.333332  446.675764\n",
      "4    503.000000  473.600231\n",
      "..          ...         ...\n",
      "507  452.249999  491.833839\n",
      "508  444.999998  484.315777\n",
      "509  440.249999  471.522409\n",
      "510  434.500002  472.414393\n",
      "511  429.999998  469.420842\n",
      "\n",
      "[512 rows x 2 columns]\n",
      "Early stopping!\n",
      "           actual   predicted\n",
      "0      408.166663  436.858793\n",
      "1      406.750003  434.131927\n",
      "2      416.250001  431.551709\n",
      "3      437.333332  446.675764\n",
      "4      503.000000  473.600231\n",
      "...           ...         ...\n",
      "19210  518.500000  566.440512\n",
      "19211  520.999999  589.313857\n",
      "19212  523.750000  588.102935\n",
      "19213  526.250000  595.436045\n",
      "19214  525.000001  600.269321\n",
      "\n",
      "[19215 rows x 2 columns]\n",
      "Score (RMSE): 40.8651\n",
      "Score (MAE): 29.5941\n",
      "Score (MAPE): 6.3662%\n",
      "training data cutoff:  2023-07-14 05:00:00\n",
      "tmp                         float64\n",
      "hum                         float64\n",
      "CO2                         float64\n",
      "VOC                         float64\n",
      "vis                         float64\n",
      "IR                          float64\n",
      "WIFI                        float64\n",
      "BLE                         float64\n",
      "rssi                        float64\n",
      "channel_rssi                float64\n",
      "channel_index               float64\n",
      "spreading_factor            float64\n",
      "bandwidth                   float64\n",
      "f_cnt                       float64\n",
      "isHoliday                   float64\n",
      "isExamTime                  float64\n",
      "weekday                     float64\n",
      "month                       float64\n",
      "hour_sin                    float64\n",
      "semester_SS23               float64\n",
      "semester_WS22/23            float64\n",
      "semester_WS23/24            float64\n",
      "group                       float64\n",
      "device_id_hka-aqm-am001     float64\n",
      "device_id_hka-aqm-am002     float64\n",
      "device_id_hka-aqm-am003a    float64\n",
      "device_id_hka-aqm-am003b    float64\n",
      "device_id_hka-aqm-am004     float64\n",
      "device_id_hka-aqm-am005     float64\n",
      "device_id_hka-aqm-am107     float64\n",
      "device_id_hka-aqm-am109     float64\n",
      "device_id_hka-aqm-am110     float64\n",
      "device_id_hka-aqm-am111     float64\n",
      "device_id_hka-aqm-am115     float64\n",
      "device_id_hka-aqm-am116     float64\n",
      "device_id_hka-aqm-am117     float64\n",
      "device_id_hka-aqm-am123     float64\n",
      "device_id_hka-aqm-am124     float64\n",
      "device_id_hka-aqm-am126     float64\n",
      "device_id_hka-aqm-am201a    float64\n",
      "device_id_hka-aqm-am201b    float64\n",
      "device_id_hka-aqm-am204     float64\n",
      "device_id_hka-aqm-am205     float64\n",
      "device_id_hka-aqm-am209     float64\n",
      "device_id_hka-aqm-am210     float64\n",
      "device_id_hka-aqm-am211     float64\n",
      "device_id_hka-aqm-am301     float64\n",
      "device_id_hka-aqm-am307     float64\n",
      "device_id_hka-aqm-am308     float64\n",
      "dtype: object\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Studium\\Semester_6\\IoT_Project\\utils.py:911: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_train[columns_to_scale] = scaler.fit_transform(df_train[columns_to_scale])\n",
      "c:\\Studium\\Semester_6\\IoT_Project\\utils.py:912: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_test[columns_to_scale] = scaler.transform(df_test[columns_to_scale])\n",
      "c:\\Studium\\Semester_6\\IoT_Project\\utils.py:916: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_train.drop(['date_time_rounded'], axis=1, inplace=True)\n",
      "c:\\Studium\\Semester_6\\IoT_Project\\utils.py:917: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_test.drop(['date_time_rounded'], axis=1, inplace=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "feature count:  49\n",
      "feature count:  49\n",
      "Training data shape: torch.Size([75940, 20, 49]) torch.Size([75940, 1])\n",
      "Testing data shape: torch.Size([19215, 20, 49]) torch.Size([19215, 1])\n",
      "same columns\n",
      "date_time_rounded           datetime64[ns]\n",
      "tmp                                float64\n",
      "hum                                float64\n",
      "CO2                                float64\n",
      "VOC                                float64\n",
      "vis                                float64\n",
      "IR                                 float64\n",
      "WIFI                               float64\n",
      "BLE                                float64\n",
      "rssi                               float64\n",
      "channel_rssi                       float64\n",
      "channel_index                      float64\n",
      "spreading_factor                   float64\n",
      "bandwidth                          float64\n",
      "f_cnt                              float64\n",
      "isHoliday                          float64\n",
      "isExamTime                         float64\n",
      "weekday                            float64\n",
      "month                              float64\n",
      "hour_sin                           float64\n",
      "semester_SS23                      float64\n",
      "semester_WS22/23                   float64\n",
      "semester_WS23/24                   float64\n",
      "group                                int32\n",
      "device_id_hka-aqm-am001              uint8\n",
      "device_id_hka-aqm-am002              uint8\n",
      "device_id_hka-aqm-am003a             uint8\n",
      "device_id_hka-aqm-am003b             uint8\n",
      "device_id_hka-aqm-am004              uint8\n",
      "device_id_hka-aqm-am005              uint8\n",
      "device_id_hka-aqm-am107              uint8\n",
      "device_id_hka-aqm-am109              uint8\n",
      "device_id_hka-aqm-am110              uint8\n",
      "device_id_hka-aqm-am111              uint8\n",
      "device_id_hka-aqm-am115              uint8\n",
      "device_id_hka-aqm-am116              uint8\n",
      "device_id_hka-aqm-am117              uint8\n",
      "device_id_hka-aqm-am123              uint8\n",
      "device_id_hka-aqm-am124              uint8\n",
      "device_id_hka-aqm-am126              uint8\n",
      "device_id_hka-aqm-am201a             uint8\n",
      "device_id_hka-aqm-am201b             uint8\n",
      "device_id_hka-aqm-am204              uint8\n",
      "device_id_hka-aqm-am205              uint8\n",
      "device_id_hka-aqm-am209              uint8\n",
      "device_id_hka-aqm-am210              uint8\n",
      "device_id_hka-aqm-am211              uint8\n",
      "device_id_hka-aqm-am301              uint8\n",
      "device_id_hka-aqm-am307              uint8\n",
      "device_id_hka-aqm-am308              uint8\n",
      "dtype: object\n",
      "date_time_rounded           datetime64[ns]\n",
      "tmp                                float64\n",
      "hum                                float64\n",
      "CO2                                float64\n",
      "VOC                                float64\n",
      "vis                                float64\n",
      "IR                                 float64\n",
      "WIFI                               float64\n",
      "BLE                                float64\n",
      "rssi                               float64\n",
      "channel_rssi                       float64\n",
      "channel_index                      float64\n",
      "spreading_factor                   float64\n",
      "bandwidth                          float64\n",
      "f_cnt                              float64\n",
      "isHoliday                          float64\n",
      "isExamTime                         float64\n",
      "weekday                            float64\n",
      "month                              float64\n",
      "hour_sin                           float64\n",
      "semester_SS23                      float64\n",
      "semester_WS22/23                   float64\n",
      "semester_WS23/24                   float64\n",
      "group                                int32\n",
      "device_id_hka-aqm-am001              uint8\n",
      "device_id_hka-aqm-am002              uint8\n",
      "device_id_hka-aqm-am003a             uint8\n",
      "device_id_hka-aqm-am003b             uint8\n",
      "device_id_hka-aqm-am004              uint8\n",
      "device_id_hka-aqm-am005              uint8\n",
      "device_id_hka-aqm-am107              uint8\n",
      "device_id_hka-aqm-am109              uint8\n",
      "device_id_hka-aqm-am110              uint8\n",
      "device_id_hka-aqm-am111              uint8\n",
      "device_id_hka-aqm-am115              uint8\n",
      "device_id_hka-aqm-am116              uint8\n",
      "device_id_hka-aqm-am117              uint8\n",
      "device_id_hka-aqm-am123              uint8\n",
      "device_id_hka-aqm-am124              uint8\n",
      "device_id_hka-aqm-am126              uint8\n",
      "device_id_hka-aqm-am201a             uint8\n",
      "device_id_hka-aqm-am201b             uint8\n",
      "device_id_hka-aqm-am204              uint8\n",
      "device_id_hka-aqm-am205              uint8\n",
      "device_id_hka-aqm-am209              uint8\n",
      "device_id_hka-aqm-am210              uint8\n",
      "device_id_hka-aqm-am211              uint8\n",
      "device_id_hka-aqm-am301              uint8\n",
      "device_id_hka-aqm-am307              uint8\n",
      "device_id_hka-aqm-am308              uint8\n",
      "dtype: object\n",
      "         date_time_rounded        tmp        hum         CO2         VOC  \\\n",
      "100258 2022-10-10 15:00:00  24.310909  47.668182  754.000000  485.090909   \n",
      "100259 2022-10-10 17:00:00  25.455000  44.930000  589.500000  585.833333   \n",
      "100260 2022-10-10 20:00:00  25.072500  50.062500  613.250000  601.750000   \n",
      "100261 2022-10-10 21:00:00  24.945000  51.042500  598.500000  568.250000   \n",
      "100262 2022-10-11 01:00:00  24.865000  49.527500  583.750000  562.000000   \n",
      "...                    ...        ...        ...         ...         ...   \n",
      "148552 2023-09-26 13:00:00  27.807500  36.012500  472.500000  962.250000   \n",
      "148553 2023-09-26 14:00:00  28.415714  35.207143  473.714286  952.857143   \n",
      "148554 2023-09-26 17:00:00  27.802500  36.237500  504.000000  925.500000   \n",
      "148555 2023-09-26 19:00:00  27.620000  36.787500  512.500000  932.500000   \n",
      "148556 2023-09-26 20:00:00  27.545000  37.025000  518.500000  954.750000   \n",
      "\n",
      "                vis          IR      WIFI        BLE        rssi  ...  \\\n",
      "100258   198.363636   25.000000  1.090909   1.363636  -68.090909  ...   \n",
      "100259   132.833333   14.166667  0.500000   0.500000  -58.000000  ...   \n",
      "100260     9.000000    1.000000  0.500000   0.000000  -62.250000  ...   \n",
      "100261     9.000000    1.000000  0.750000   0.000000  -61.750000  ...   \n",
      "100262     9.500000    1.500000  0.750000   0.000000  -59.000000  ...   \n",
      "...             ...         ...       ...        ...         ...  ...   \n",
      "148552  1127.250000  257.250000  1.000000   0.500000 -101.750000  ...   \n",
      "148553   608.285714  143.142857  1.857143  17.142857  -90.142857  ...   \n",
      "148554    49.750000   13.000000  3.000000  13.750000  -72.250000  ...   \n",
      "148555     6.000000    1.250000  2.250000   6.750000  -87.750000  ...   \n",
      "148556     5.500000    1.250000  3.500000  13.500000  -72.750000  ...   \n",
      "\n",
      "        device_id_hka-aqm-am201a  device_id_hka-aqm-am201b  \\\n",
      "100258                         0                         0   \n",
      "100259                         0                         0   \n",
      "100260                         0                         0   \n",
      "100261                         0                         0   \n",
      "100262                         0                         0   \n",
      "...                          ...                       ...   \n",
      "148552                         0                         0   \n",
      "148553                         0                         0   \n",
      "148554                         0                         0   \n",
      "148555                         0                         0   \n",
      "148556                         0                         0   \n",
      "\n",
      "        device_id_hka-aqm-am204  device_id_hka-aqm-am205  \\\n",
      "100258                        0                        0   \n",
      "100259                        0                        0   \n",
      "100260                        0                        0   \n",
      "100261                        0                        0   \n",
      "100262                        0                        0   \n",
      "...                         ...                      ...   \n",
      "148552                        0                        0   \n",
      "148553                        0                        0   \n",
      "148554                        0                        0   \n",
      "148555                        0                        0   \n",
      "148556                        0                        0   \n",
      "\n",
      "        device_id_hka-aqm-am209  device_id_hka-aqm-am210  \\\n",
      "100258                        0                        0   \n",
      "100259                        0                        0   \n",
      "100260                        0                        0   \n",
      "100261                        0                        0   \n",
      "100262                        0                        0   \n",
      "...                         ...                      ...   \n",
      "148552                        0                        0   \n",
      "148553                        0                        0   \n",
      "148554                        0                        0   \n",
      "148555                        0                        0   \n",
      "148556                        0                        0   \n",
      "\n",
      "        device_id_hka-aqm-am211  device_id_hka-aqm-am301  \\\n",
      "100258                        0                        0   \n",
      "100259                        0                        0   \n",
      "100260                        0                        0   \n",
      "100261                        0                        0   \n",
      "100262                        0                        0   \n",
      "...                         ...                      ...   \n",
      "148552                        0                        0   \n",
      "148553                        0                        0   \n",
      "148554                        0                        0   \n",
      "148555                        0                        0   \n",
      "148556                        0                        0   \n",
      "\n",
      "        device_id_hka-aqm-am307  device_id_hka-aqm-am308  \n",
      "100258                        0                        0  \n",
      "100259                        0                        0  \n",
      "100260                        0                        0  \n",
      "100261                        0                        0  \n",
      "100262                        0                        0  \n",
      "...                         ...                      ...  \n",
      "148552                        0                        1  \n",
      "148553                        0                        1  \n",
      "148554                        0                        1  \n",
      "148555                        0                        1  \n",
      "148556                        0                        1  \n",
      "\n",
      "[48299 rows x 50 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\t-ehm\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\transformer.py:286: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
      "c:\\Users\\t-ehm\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\optim\\lr_scheduler.py:28: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\"The verbose parameter is deprecated. Please use get_last_lr() \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        actual  predicted\n",
      "0    52.691111  40.523037\n",
      "1    52.932500  42.793013\n",
      "2    57.667500  43.880071\n",
      "3    57.013332  48.009819\n",
      "4    53.677500  47.241797\n",
      "..         ...        ...\n",
      "507  45.732501  35.539000\n",
      "508  45.482500  35.662758\n",
      "509  46.620000  35.768425\n",
      "510  47.890000  36.513280\n",
      "511  47.519999  37.321802\n",
      "\n",
      "[512 rows x 2 columns]\n",
      "Epoch 1/25, Training Loss: 0.2315\n",
      "Epoch 1/25, Validation Loss: 0.3978\n",
      "        actual  predicted\n",
      "0    52.691111  39.019359\n",
      "1    52.932500  40.846000\n",
      "2    57.667500  42.046781\n",
      "3    57.013332  46.061603\n",
      "4    53.677500  45.524775\n",
      "..         ...        ...\n",
      "507  45.732501  32.974972\n",
      "508  45.482500  32.934060\n",
      "509  46.620000  32.933723\n",
      "510  47.890000  33.701900\n",
      "511  47.519999  34.586379\n",
      "\n",
      "[512 rows x 2 columns]\n",
      "Epoch 2/25, Training Loss: 0.0720\n",
      "Epoch 2/25, Validation Loss: 0.6814\n",
      "        actual  predicted\n",
      "0    52.691111  39.050691\n",
      "1    52.932500  40.971600\n",
      "2    57.667500  41.862891\n",
      "3    57.013332  46.180064\n",
      "4    53.677500  45.545427\n",
      "..         ...        ...\n",
      "507  45.732501  33.497702\n",
      "508  45.482500  33.466428\n",
      "509  46.620000  33.231083\n",
      "510  47.890000  33.820806\n",
      "511  47.519999  34.602230\n",
      "\n",
      "[512 rows x 2 columns]\n",
      "Epoch 3/25, Training Loss: 0.0528\n",
      "Epoch 3/25, Validation Loss: 0.6529\n",
      "        actual  predicted\n",
      "0    52.691111  39.491111\n",
      "1    52.932500  41.418185\n",
      "2    57.667500  42.180359\n",
      "3    57.013332  45.876822\n",
      "4    53.677500  44.958601\n",
      "..         ...        ...\n",
      "507  45.732501  34.665476\n",
      "508  45.482500  34.870040\n",
      "509  46.620000  34.834620\n",
      "510  47.890000  35.619247\n",
      "511  47.519999  36.506711\n",
      "\n",
      "[512 rows x 2 columns]\n",
      "Epoch 4/25, Training Loss: 0.0429\n",
      "Epoch 4/25, Validation Loss: 0.5348\n",
      "        actual  predicted\n",
      "0    52.691111  40.787360\n",
      "1    52.932500  42.610693\n",
      "2    57.667500  43.283764\n",
      "3    57.013332  47.195133\n",
      "4    53.677500  46.281086\n",
      "..         ...        ...\n",
      "507  45.732501  33.822058\n",
      "508  45.482500  33.682123\n",
      "509  46.620000  33.567990\n",
      "510  47.890000  34.454434\n",
      "511  47.519999  35.476937\n",
      "\n",
      "[512 rows x 2 columns]\n",
      "Epoch 5/25, Training Loss: 0.0403\n",
      "Epoch 5/25, Validation Loss: 0.5175\n",
      "        actual  predicted\n",
      "0    52.691111  41.796994\n",
      "1    52.932500  43.670081\n",
      "2    57.667500  44.599542\n",
      "3    57.013332  48.605047\n",
      "4    53.677500  47.815868\n",
      "..         ...        ...\n",
      "507  45.732501  36.337173\n",
      "508  45.482500  36.376707\n",
      "509  46.620000  36.277947\n",
      "510  47.890000  37.066056\n",
      "511  47.519999  37.938959\n",
      "\n",
      "[512 rows x 2 columns]\n",
      "Epoch 6/25, Training Loss: 0.0309\n",
      "Epoch 6/25, Validation Loss: 0.3611\n",
      "        actual  predicted\n",
      "0    52.691111  42.392524\n",
      "1    52.932500  44.034041\n",
      "2    57.667500  44.923627\n",
      "3    57.013332  48.606963\n",
      "4    53.677500  48.000337\n",
      "..         ...        ...\n",
      "507  45.732501  37.121169\n",
      "508  45.482500  37.124231\n",
      "509  46.620000  36.971519\n",
      "510  47.890000  37.701339\n",
      "511  47.519999  38.611832\n",
      "\n",
      "[512 rows x 2 columns]\n",
      "Epoch 7/25, Training Loss: 0.0290\n",
      "Epoch 7/25, Validation Loss: 0.3199\n",
      "        actual  predicted\n",
      "0    52.691111  42.503053\n",
      "1    52.932500  44.407498\n",
      "2    57.667500  45.315980\n",
      "3    57.013332  49.316645\n",
      "4    53.677500  48.567409\n",
      "..         ...        ...\n",
      "507  45.732501  36.719802\n",
      "508  45.482500  36.871433\n",
      "509  46.620000  36.743899\n",
      "510  47.890000  37.529136\n",
      "511  47.519999  38.448312\n",
      "\n",
      "[512 rows x 2 columns]\n",
      "Epoch 8/25, Training Loss: 0.0276\n",
      "Epoch 8/25, Validation Loss: 0.3237\n",
      "        actual  predicted\n",
      "0    52.691111  43.372232\n",
      "1    52.932500  45.055544\n",
      "2    57.667500  45.941217\n",
      "3    57.013332  49.344832\n",
      "4    53.677500  48.647024\n",
      "..         ...        ...\n",
      "507  45.732501  38.448001\n",
      "508  45.482500  38.300716\n",
      "509  46.620000  38.150115\n",
      "510  47.890000  38.946826\n",
      "511  47.519999  39.967477\n",
      "\n",
      "[512 rows x 2 columns]\n",
      "Epoch 9/25, Training Loss: 0.0256\n",
      "Epoch 9/25, Validation Loss: 0.2148\n",
      "        actual  predicted\n",
      "0    52.691111  44.826134\n",
      "1    52.932500  46.550562\n",
      "2    57.667500  47.333264\n",
      "3    57.013332  50.692727\n",
      "4    53.677500  50.059199\n",
      "..         ...        ...\n",
      "507  45.732501  39.164819\n",
      "508  45.482500  39.127750\n",
      "509  46.620000  38.944635\n",
      "510  47.890000  39.685120\n",
      "511  47.519999  40.705548\n",
      "\n",
      "[512 rows x 2 columns]\n",
      "Epoch 10/25, Training Loss: 0.0243\n",
      "Epoch 10/25, Validation Loss: 0.1849\n",
      "        actual  predicted\n",
      "0    52.691111  45.016643\n",
      "1    52.932500  46.713058\n",
      "2    57.667500  47.480777\n",
      "3    57.013332  50.496436\n",
      "4    53.677500  49.741394\n",
      "..         ...        ...\n",
      "507  45.732501  39.821247\n",
      "508  45.482500  39.677463\n",
      "509  46.620000  39.461409\n",
      "510  47.890000  40.262961\n",
      "511  47.519999  41.305307\n",
      "\n",
      "[512 rows x 2 columns]\n",
      "Epoch 11/25, Training Loss: 0.0231\n",
      "Epoch 11/25, Validation Loss: 0.1435\n",
      "        actual  predicted\n",
      "0    52.691111  44.979863\n",
      "1    52.932500  46.551062\n",
      "2    57.667500  47.263451\n",
      "3    57.013332  50.047320\n",
      "4    53.677500  49.407018\n",
      "..         ...        ...\n",
      "507  45.732501  39.709614\n",
      "508  45.482500  39.576525\n",
      "509  46.620000  39.304194\n",
      "510  47.890000  40.016587\n",
      "511  47.519999  41.011292\n",
      "\n",
      "[512 rows x 2 columns]\n",
      "Epoch 12/25, Training Loss: 0.0224\n",
      "Epoch 12/25, Validation Loss: 0.1988\n",
      "        actual  predicted\n",
      "0    52.691111  47.004412\n",
      "1    52.932500  48.638270\n",
      "2    57.667500  49.351732\n",
      "3    57.013332  52.566023\n",
      "4    53.677500  51.890288\n",
      "..         ...        ...\n",
      "507  45.732501  41.621518\n",
      "508  45.482500  41.562411\n",
      "509  46.620000  41.263187\n",
      "510  47.890000  42.070802\n",
      "511  47.519999  43.047459\n",
      "\n",
      "[512 rows x 2 columns]\n",
      "Epoch 13/25, Training Loss: 0.0213\n",
      "Epoch 13/25, Validation Loss: 0.0842\n",
      "        actual  predicted\n",
      "0    52.691111  46.151116\n",
      "1    52.932500  48.036335\n",
      "2    57.667500  48.913209\n",
      "3    57.013332  51.938532\n",
      "4    53.677500  51.275280\n",
      "..         ...        ...\n",
      "507  45.732501  40.997711\n",
      "508  45.482500  40.892518\n",
      "509  46.620000  40.577017\n",
      "510  47.890000  41.334214\n",
      "511  47.519999  42.269084\n",
      "\n",
      "[512 rows x 2 columns]\n",
      "Epoch 14/25, Training Loss: 0.0206\n",
      "Epoch 14/25, Validation Loss: 0.1131\n",
      "        actual  predicted\n",
      "0    52.691111  47.593042\n",
      "1    52.932500  49.603204\n",
      "2    57.667500  50.526444\n",
      "3    57.013332  53.991347\n",
      "4    53.677500  53.300630\n",
      "..         ...        ...\n",
      "507  45.732501  42.249257\n",
      "508  45.482500  42.185240\n",
      "509  46.620000  41.837964\n",
      "510  47.890000  42.526694\n",
      "511  47.519999  43.399863\n",
      "\n",
      "[512 rows x 2 columns]\n",
      "Epoch 15/25, Training Loss: 0.0204\n",
      "Epoch 15/25, Validation Loss: 0.0724\n",
      "        actual  predicted\n",
      "0    52.691111  47.221350\n",
      "1    52.932500  48.931256\n",
      "2    57.667500  49.775228\n",
      "3    57.013332  53.053092\n",
      "4    53.677500  52.472754\n",
      "..         ...        ...\n",
      "507  45.732501  41.386636\n",
      "508  45.482500  41.269991\n",
      "509  46.620000  41.055852\n",
      "510  47.890000  41.841202\n",
      "511  47.519999  42.715003\n",
      "\n",
      "[512 rows x 2 columns]\n",
      "Epoch 16/25, Training Loss: 0.0197\n",
      "Epoch 16/25, Validation Loss: 0.1009\n",
      "        actual  predicted\n",
      "0    52.691111  47.377408\n",
      "1    52.932500  49.280394\n",
      "2    57.667500  50.035945\n",
      "3    57.013332  53.297129\n",
      "4    53.677500  52.557769\n",
      "..         ...        ...\n",
      "507  45.732501  42.182153\n",
      "508  45.482500  42.252324\n",
      "509  46.620000  41.927210\n",
      "510  47.890000  42.586576\n",
      "511  47.519999  43.347978\n",
      "\n",
      "[512 rows x 2 columns]\n",
      "Epoch 17/25, Training Loss: 0.0191\n",
      "Epoch 17/25, Validation Loss: 0.0868\n",
      "        actual  predicted\n",
      "0    52.691111  47.243330\n",
      "1    52.932500  48.982914\n",
      "2    57.667500  49.652921\n",
      "3    57.013332  53.020712\n",
      "4    53.677500  52.306392\n",
      "..         ...        ...\n",
      "507  45.732501  41.684634\n",
      "508  45.482500  41.600588\n",
      "509  46.620000  41.361210\n",
      "510  47.890000  42.076874\n",
      "511  47.519999  42.928205\n",
      "\n",
      "[512 rows x 2 columns]\n",
      "Epoch 18/25, Training Loss: 0.0184\n",
      "Epoch 18/25, Validation Loss: 0.0900\n",
      "        actual  predicted\n",
      "0    52.691111  47.170228\n",
      "1    52.932500  48.960332\n",
      "2    57.667500  49.617269\n",
      "3    57.013332  52.730341\n",
      "4    53.677500  51.935471\n",
      "..         ...        ...\n",
      "507  45.732501  41.504946\n",
      "508  45.482500  41.433751\n",
      "509  46.620000  41.138930\n",
      "510  47.890000  41.814981\n",
      "511  47.519999  42.677345\n",
      "\n",
      "[512 rows x 2 columns]\n",
      "Epoch 19/25, Training Loss: 0.0182\n",
      "Epoch 19/25, Validation Loss: 0.0945\n",
      "        actual  predicted\n",
      "0    52.691111  47.830850\n",
      "1    52.932500  49.773399\n",
      "2    57.667500  50.558177\n",
      "3    57.013332  53.850410\n",
      "4    53.677500  53.087845\n",
      "..         ...        ...\n",
      "507  45.732501  42.255836\n",
      "508  45.482500  42.163081\n",
      "509  46.620000  41.857058\n",
      "510  47.890000  42.531500\n",
      "511  47.519999  43.406729\n",
      "\n",
      "[512 rows x 2 columns]\n",
      "Early stopping!\n",
      "          actual  predicted\n",
      "0      52.691111  47.830850\n",
      "1      52.932500  49.773399\n",
      "2      57.667500  50.558177\n",
      "3      57.013332  53.850410\n",
      "4      53.677500  53.087845\n",
      "...          ...        ...\n",
      "19210  37.025000  35.107200\n",
      "19211  37.250000  35.325234\n",
      "19212  37.430000  35.574599\n",
      "19213  37.570000  35.711195\n",
      "19214  37.650000  35.842336\n",
      "\n",
      "[19215 rows x 2 columns]\n",
      "Score (RMSE): 2.6274\n",
      "Score (MAE): 2.1281\n",
      "Score (MAPE): 4.7133%\n",
      "training data cutoff:  2023-07-14 05:00:00\n",
      "tmp                         float64\n",
      "hum                         float64\n",
      "CO2                         float64\n",
      "VOC                         float64\n",
      "vis                         float64\n",
      "IR                          float64\n",
      "WIFI                        float64\n",
      "BLE                         float64\n",
      "rssi                        float64\n",
      "channel_rssi                float64\n",
      "channel_index               float64\n",
      "spreading_factor            float64\n",
      "bandwidth                   float64\n",
      "f_cnt                       float64\n",
      "isHoliday                   float64\n",
      "isExamTime                  float64\n",
      "weekday                     float64\n",
      "month                       float64\n",
      "hour_sin                    float64\n",
      "semester_SS23               float64\n",
      "semester_WS22/23            float64\n",
      "semester_WS23/24            float64\n",
      "group                       float64\n",
      "device_id_hka-aqm-am001     float64\n",
      "device_id_hka-aqm-am002     float64\n",
      "device_id_hka-aqm-am003a    float64\n",
      "device_id_hka-aqm-am003b    float64\n",
      "device_id_hka-aqm-am004     float64\n",
      "device_id_hka-aqm-am005     float64\n",
      "device_id_hka-aqm-am107     float64\n",
      "device_id_hka-aqm-am109     float64\n",
      "device_id_hka-aqm-am110     float64\n",
      "device_id_hka-aqm-am111     float64\n",
      "device_id_hka-aqm-am115     float64\n",
      "device_id_hka-aqm-am116     float64\n",
      "device_id_hka-aqm-am117     float64\n",
      "device_id_hka-aqm-am123     float64\n",
      "device_id_hka-aqm-am124     float64\n",
      "device_id_hka-aqm-am126     float64\n",
      "device_id_hka-aqm-am201a    float64\n",
      "device_id_hka-aqm-am201b    float64\n",
      "device_id_hka-aqm-am204     float64\n",
      "device_id_hka-aqm-am205     float64\n",
      "device_id_hka-aqm-am209     float64\n",
      "device_id_hka-aqm-am210     float64\n",
      "device_id_hka-aqm-am211     float64\n",
      "device_id_hka-aqm-am301     float64\n",
      "device_id_hka-aqm-am307     float64\n",
      "device_id_hka-aqm-am308     float64\n",
      "dtype: object\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Studium\\Semester_6\\IoT_Project\\utils.py:911: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_train[columns_to_scale] = scaler.fit_transform(df_train[columns_to_scale])\n",
      "c:\\Studium\\Semester_6\\IoT_Project\\utils.py:912: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_test[columns_to_scale] = scaler.transform(df_test[columns_to_scale])\n",
      "c:\\Studium\\Semester_6\\IoT_Project\\utils.py:916: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_train.drop(['date_time_rounded'], axis=1, inplace=True)\n",
      "c:\\Studium\\Semester_6\\IoT_Project\\utils.py:917: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_test.drop(['date_time_rounded'], axis=1, inplace=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "feature count:  49\n",
      "feature count:  49\n",
      "Training data shape: torch.Size([75940, 20, 49]) torch.Size([75940, 1])\n",
      "Testing data shape: torch.Size([19215, 20, 49]) torch.Size([19215, 1])\n",
      "same columns\n",
      "date_time_rounded           datetime64[ns]\n",
      "tmp                                float64\n",
      "hum                                float64\n",
      "CO2                                float64\n",
      "VOC                                float64\n",
      "vis                                float64\n",
      "IR                                 float64\n",
      "WIFI                               float64\n",
      "BLE                                float64\n",
      "rssi                               float64\n",
      "channel_rssi                       float64\n",
      "channel_index                      float64\n",
      "spreading_factor                   float64\n",
      "bandwidth                          float64\n",
      "f_cnt                              float64\n",
      "isHoliday                          float64\n",
      "isExamTime                         float64\n",
      "weekday                            float64\n",
      "month                              float64\n",
      "hour_sin                           float64\n",
      "semester_SS23                      float64\n",
      "semester_WS22/23                   float64\n",
      "semester_WS23/24                   float64\n",
      "group                                int32\n",
      "device_id_hka-aqm-am001              uint8\n",
      "device_id_hka-aqm-am002              uint8\n",
      "device_id_hka-aqm-am003a             uint8\n",
      "device_id_hka-aqm-am003b             uint8\n",
      "device_id_hka-aqm-am004              uint8\n",
      "device_id_hka-aqm-am005              uint8\n",
      "device_id_hka-aqm-am107              uint8\n",
      "device_id_hka-aqm-am109              uint8\n",
      "device_id_hka-aqm-am110              uint8\n",
      "device_id_hka-aqm-am111              uint8\n",
      "device_id_hka-aqm-am115              uint8\n",
      "device_id_hka-aqm-am116              uint8\n",
      "device_id_hka-aqm-am117              uint8\n",
      "device_id_hka-aqm-am123              uint8\n",
      "device_id_hka-aqm-am124              uint8\n",
      "device_id_hka-aqm-am126              uint8\n",
      "device_id_hka-aqm-am201a             uint8\n",
      "device_id_hka-aqm-am201b             uint8\n",
      "device_id_hka-aqm-am204              uint8\n",
      "device_id_hka-aqm-am205              uint8\n",
      "device_id_hka-aqm-am209              uint8\n",
      "device_id_hka-aqm-am210              uint8\n",
      "device_id_hka-aqm-am211              uint8\n",
      "device_id_hka-aqm-am301              uint8\n",
      "device_id_hka-aqm-am307              uint8\n",
      "device_id_hka-aqm-am308              uint8\n",
      "dtype: object\n",
      "date_time_rounded           datetime64[ns]\n",
      "tmp                                float64\n",
      "hum                                float64\n",
      "CO2                                float64\n",
      "VOC                                float64\n",
      "vis                                float64\n",
      "IR                                 float64\n",
      "WIFI                               float64\n",
      "BLE                                float64\n",
      "rssi                               float64\n",
      "channel_rssi                       float64\n",
      "channel_index                      float64\n",
      "spreading_factor                   float64\n",
      "bandwidth                          float64\n",
      "f_cnt                              float64\n",
      "isHoliday                          float64\n",
      "isExamTime                         float64\n",
      "weekday                            float64\n",
      "month                              float64\n",
      "hour_sin                           float64\n",
      "semester_SS23                      float64\n",
      "semester_WS22/23                   float64\n",
      "semester_WS23/24                   float64\n",
      "group                                int32\n",
      "device_id_hka-aqm-am001              uint8\n",
      "device_id_hka-aqm-am002              uint8\n",
      "device_id_hka-aqm-am003a             uint8\n",
      "device_id_hka-aqm-am003b             uint8\n",
      "device_id_hka-aqm-am004              uint8\n",
      "device_id_hka-aqm-am005              uint8\n",
      "device_id_hka-aqm-am107              uint8\n",
      "device_id_hka-aqm-am109              uint8\n",
      "device_id_hka-aqm-am110              uint8\n",
      "device_id_hka-aqm-am111              uint8\n",
      "device_id_hka-aqm-am115              uint8\n",
      "device_id_hka-aqm-am116              uint8\n",
      "device_id_hka-aqm-am117              uint8\n",
      "device_id_hka-aqm-am123              uint8\n",
      "device_id_hka-aqm-am124              uint8\n",
      "device_id_hka-aqm-am126              uint8\n",
      "device_id_hka-aqm-am201a             uint8\n",
      "device_id_hka-aqm-am201b             uint8\n",
      "device_id_hka-aqm-am204              uint8\n",
      "device_id_hka-aqm-am205              uint8\n",
      "device_id_hka-aqm-am209              uint8\n",
      "device_id_hka-aqm-am210              uint8\n",
      "device_id_hka-aqm-am211              uint8\n",
      "device_id_hka-aqm-am301              uint8\n",
      "device_id_hka-aqm-am307              uint8\n",
      "device_id_hka-aqm-am308              uint8\n",
      "dtype: object\n",
      "         date_time_rounded        tmp        hum         CO2         VOC  \\\n",
      "100258 2022-10-10 15:00:00  24.310909  47.668182  754.000000  485.090909   \n",
      "100259 2022-10-10 17:00:00  25.455000  44.930000  589.500000  585.833333   \n",
      "100260 2022-10-10 20:00:00  25.072500  50.062500  613.250000  601.750000   \n",
      "100261 2022-10-10 21:00:00  24.945000  51.042500  598.500000  568.250000   \n",
      "100262 2022-10-11 01:00:00  24.865000  49.527500  583.750000  562.000000   \n",
      "...                    ...        ...        ...         ...         ...   \n",
      "148552 2023-09-26 13:00:00  27.807500  36.012500  472.500000  962.250000   \n",
      "148553 2023-09-26 14:00:00  28.415714  35.207143  473.714286  952.857143   \n",
      "148554 2023-09-26 17:00:00  27.802500  36.237500  504.000000  925.500000   \n",
      "148555 2023-09-26 19:00:00  27.620000  36.787500  512.500000  932.500000   \n",
      "148556 2023-09-26 20:00:00  27.545000  37.025000  518.500000  954.750000   \n",
      "\n",
      "                vis          IR      WIFI        BLE        rssi  ...  \\\n",
      "100258   198.363636   25.000000  1.090909   1.363636  -68.090909  ...   \n",
      "100259   132.833333   14.166667  0.500000   0.500000  -58.000000  ...   \n",
      "100260     9.000000    1.000000  0.500000   0.000000  -62.250000  ...   \n",
      "100261     9.000000    1.000000  0.750000   0.000000  -61.750000  ...   \n",
      "100262     9.500000    1.500000  0.750000   0.000000  -59.000000  ...   \n",
      "...             ...         ...       ...        ...         ...  ...   \n",
      "148552  1127.250000  257.250000  1.000000   0.500000 -101.750000  ...   \n",
      "148553   608.285714  143.142857  1.857143  17.142857  -90.142857  ...   \n",
      "148554    49.750000   13.000000  3.000000  13.750000  -72.250000  ...   \n",
      "148555     6.000000    1.250000  2.250000   6.750000  -87.750000  ...   \n",
      "148556     5.500000    1.250000  3.500000  13.500000  -72.750000  ...   \n",
      "\n",
      "        device_id_hka-aqm-am201a  device_id_hka-aqm-am201b  \\\n",
      "100258                         0                         0   \n",
      "100259                         0                         0   \n",
      "100260                         0                         0   \n",
      "100261                         0                         0   \n",
      "100262                         0                         0   \n",
      "...                          ...                       ...   \n",
      "148552                         0                         0   \n",
      "148553                         0                         0   \n",
      "148554                         0                         0   \n",
      "148555                         0                         0   \n",
      "148556                         0                         0   \n",
      "\n",
      "        device_id_hka-aqm-am204  device_id_hka-aqm-am205  \\\n",
      "100258                        0                        0   \n",
      "100259                        0                        0   \n",
      "100260                        0                        0   \n",
      "100261                        0                        0   \n",
      "100262                        0                        0   \n",
      "...                         ...                      ...   \n",
      "148552                        0                        0   \n",
      "148553                        0                        0   \n",
      "148554                        0                        0   \n",
      "148555                        0                        0   \n",
      "148556                        0                        0   \n",
      "\n",
      "        device_id_hka-aqm-am209  device_id_hka-aqm-am210  \\\n",
      "100258                        0                        0   \n",
      "100259                        0                        0   \n",
      "100260                        0                        0   \n",
      "100261                        0                        0   \n",
      "100262                        0                        0   \n",
      "...                         ...                      ...   \n",
      "148552                        0                        0   \n",
      "148553                        0                        0   \n",
      "148554                        0                        0   \n",
      "148555                        0                        0   \n",
      "148556                        0                        0   \n",
      "\n",
      "        device_id_hka-aqm-am211  device_id_hka-aqm-am301  \\\n",
      "100258                        0                        0   \n",
      "100259                        0                        0   \n",
      "100260                        0                        0   \n",
      "100261                        0                        0   \n",
      "100262                        0                        0   \n",
      "...                         ...                      ...   \n",
      "148552                        0                        0   \n",
      "148553                        0                        0   \n",
      "148554                        0                        0   \n",
      "148555                        0                        0   \n",
      "148556                        0                        0   \n",
      "\n",
      "        device_id_hka-aqm-am307  device_id_hka-aqm-am308  \n",
      "100258                        0                        0  \n",
      "100259                        0                        0  \n",
      "100260                        0                        0  \n",
      "100261                        0                        0  \n",
      "100262                        0                        0  \n",
      "...                         ...                      ...  \n",
      "148552                        0                        1  \n",
      "148553                        0                        1  \n",
      "148554                        0                        1  \n",
      "148555                        0                        1  \n",
      "148556                        0                        1  \n",
      "\n",
      "[48299 rows x 50 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\t-ehm\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\transformer.py:286: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
      "c:\\Users\\t-ehm\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\optim\\lr_scheduler.py:28: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\"The verbose parameter is deprecated. Please use get_last_lr() \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        actual  predicted\n",
      "0    25.911111  23.781095\n",
      "1    26.005000  23.956531\n",
      "2    26.232500  24.156866\n",
      "3    26.666667  24.491824\n",
      "4    27.037500  24.951624\n",
      "..         ...        ...\n",
      "507  24.112500  22.125041\n",
      "508  24.205000  22.309106\n",
      "509  24.405000  22.482258\n",
      "510  24.587500  22.707183\n",
      "511  25.057500  22.702921\n",
      "\n",
      "[512 rows x 2 columns]\n",
      "Epoch 1/25, Training Loss: 0.2618\n",
      "Epoch 1/25, Validation Loss: 0.7938\n",
      "        actual  predicted\n",
      "0    25.911111  24.655018\n",
      "1    26.005000  24.758970\n",
      "2    26.232500  24.758181\n",
      "3    26.666667  24.935274\n",
      "4    27.037500  25.392012\n",
      "..         ...        ...\n",
      "507  24.112500  22.848509\n",
      "508  24.205000  22.968874\n",
      "509  24.405000  23.215886\n",
      "510  24.587500  23.528451\n",
      "511  25.057500  23.592301\n",
      "\n",
      "[512 rows x 2 columns]\n",
      "Epoch 2/25, Training Loss: 0.0616\n",
      "Epoch 2/25, Validation Loss: 0.6070\n",
      "        actual  predicted\n",
      "0    25.911111  24.972962\n",
      "1    26.005000  25.082504\n",
      "2    26.232500  25.200027\n",
      "3    26.666667  25.440856\n",
      "4    27.037500  25.892507\n",
      "..         ...        ...\n",
      "507  24.112500  23.659009\n",
      "508  24.205000  23.744091\n",
      "509  24.405000  23.888618\n",
      "510  24.587500  24.095733\n",
      "511  25.057500  24.210874\n",
      "\n",
      "[512 rows x 2 columns]\n",
      "Epoch 3/25, Training Loss: 0.0470\n",
      "Epoch 3/25, Validation Loss: 0.2964\n",
      "        actual  predicted\n",
      "0    25.911111  25.443379\n",
      "1    26.005000  25.499409\n",
      "2    26.232500  25.543327\n",
      "3    26.666667  25.761574\n",
      "4    27.037500  26.330441\n",
      "..         ...        ...\n",
      "507  24.112500  23.587133\n",
      "508  24.205000  23.700227\n",
      "509  24.405000  23.845716\n",
      "510  24.587500  24.091308\n",
      "511  25.057500  24.253510\n",
      "\n",
      "[512 rows x 2 columns]\n",
      "Epoch 4/25, Training Loss: 0.0379\n",
      "Epoch 4/25, Validation Loss: 0.2780\n",
      "        actual  predicted\n",
      "0    25.911111  25.154085\n",
      "1    26.005000  25.225837\n",
      "2    26.232500  25.354680\n",
      "3    26.666667  25.643716\n",
      "4    27.037500  26.232521\n",
      "..         ...        ...\n",
      "507  24.112500  23.458591\n",
      "508  24.205000  23.547416\n",
      "509  24.405000  23.699157\n",
      "510  24.587500  24.013895\n",
      "511  25.057500  24.215066\n",
      "\n",
      "[512 rows x 2 columns]\n",
      "Epoch 5/25, Training Loss: 0.0352\n",
      "Epoch 5/25, Validation Loss: 0.2781\n",
      "        actual  predicted\n",
      "0    25.911111  24.893260\n",
      "1    26.005000  24.978426\n",
      "2    26.232500  25.036482\n",
      "3    26.666667  25.329515\n",
      "4    27.037500  25.888603\n",
      "..         ...        ...\n",
      "507  24.112500  23.424127\n",
      "508  24.205000  23.468292\n",
      "509  24.405000  23.576582\n",
      "510  24.587500  23.833731\n",
      "511  25.057500  24.005816\n",
      "\n",
      "[512 rows x 2 columns]\n",
      "Epoch 6/25, Training Loss: 0.0297\n",
      "Epoch 6/25, Validation Loss: 0.3372\n",
      "        actual  predicted\n",
      "0    25.911111  25.384431\n",
      "1    26.005000  25.476933\n",
      "2    26.232500  25.545884\n",
      "3    26.666667  25.788383\n",
      "4    27.037500  26.260150\n",
      "..         ...        ...\n",
      "507  24.112500  23.400029\n",
      "508  24.205000  23.463179\n",
      "509  24.405000  23.611764\n",
      "510  24.587500  23.993581\n",
      "511  25.057500  24.249238\n",
      "\n",
      "[512 rows x 2 columns]\n",
      "Epoch 7/25, Training Loss: 0.0271\n",
      "Epoch 7/25, Validation Loss: 0.1896\n",
      "        actual  predicted\n",
      "0    25.911111  25.338030\n",
      "1    26.005000  25.436824\n",
      "2    26.232500  25.545939\n",
      "3    26.666667  25.862103\n",
      "4    27.037500  26.359515\n",
      "..         ...        ...\n",
      "507  24.112500  23.825739\n",
      "508  24.205000  23.912840\n",
      "509  24.405000  24.084455\n",
      "510  24.587500  24.390665\n",
      "511  25.057500  24.574685\n",
      "\n",
      "[512 rows x 2 columns]\n",
      "Epoch 8/25, Training Loss: 0.0255\n",
      "Epoch 8/25, Validation Loss: 0.1080\n",
      "        actual  predicted\n",
      "0    25.911111  25.179417\n",
      "1    26.005000  25.306008\n",
      "2    26.232500  25.403089\n",
      "3    26.666667  25.735885\n",
      "4    27.037500  26.206049\n",
      "..         ...        ...\n",
      "507  24.112500  23.665965\n",
      "508  24.205000  23.741109\n",
      "509  24.405000  23.870819\n",
      "510  24.587500  24.154463\n",
      "511  25.057500  24.320534\n",
      "\n",
      "[512 rows x 2 columns]\n",
      "Epoch 9/25, Training Loss: 0.0226\n",
      "Epoch 9/25, Validation Loss: 0.1818\n",
      "        actual  predicted\n",
      "0    25.911111  25.084134\n",
      "1    26.005000  25.276003\n",
      "2    26.232500  25.406689\n",
      "3    26.666667  25.737517\n",
      "4    27.037500  26.169581\n",
      "..         ...        ...\n",
      "507  24.112500  23.755150\n",
      "508  24.205000  23.812451\n",
      "509  24.405000  23.956041\n",
      "510  24.587500  24.216870\n",
      "511  25.057500  24.382137\n",
      "\n",
      "[512 rows x 2 columns]\n",
      "Epoch 10/25, Training Loss: 0.0212\n",
      "Epoch 10/25, Validation Loss: 0.1100\n",
      "        actual  predicted\n",
      "0    25.911111  25.435564\n",
      "1    26.005000  25.649603\n",
      "2    26.232500  25.761435\n",
      "3    26.666667  26.086841\n",
      "4    27.037500  26.500530\n",
      "..         ...        ...\n",
      "507  24.112500  24.151955\n",
      "508  24.205000  24.180091\n",
      "509  24.405000  24.311339\n",
      "510  24.587500  24.577040\n",
      "511  25.057500  24.762642\n",
      "\n",
      "[512 rows x 2 columns]\n",
      "Epoch 11/25, Training Loss: 0.0200\n",
      "Epoch 11/25, Validation Loss: 0.0805\n",
      "        actual  predicted\n",
      "0    25.911111  25.229359\n",
      "1    26.005000  25.434267\n",
      "2    26.232500  25.527097\n",
      "3    26.666667  25.813662\n",
      "4    27.037500  26.206130\n",
      "..         ...        ...\n",
      "507  24.112500  23.709311\n",
      "508  24.205000  23.761896\n",
      "509  24.405000  23.887292\n",
      "510  24.587500  24.160278\n",
      "511  25.057500  24.329896\n",
      "\n",
      "[512 rows x 2 columns]\n",
      "Epoch 12/25, Training Loss: 0.0196\n",
      "Epoch 12/25, Validation Loss: 0.1439\n",
      "        actual  predicted\n",
      "0    25.911111  25.170461\n",
      "1    26.005000  25.308280\n",
      "2    26.232500  25.300349\n",
      "3    26.666667  25.572370\n",
      "4    27.037500  26.014533\n",
      "..         ...        ...\n",
      "507  24.112500  23.610537\n",
      "508  24.205000  23.670853\n",
      "509  24.405000  23.811020\n",
      "510  24.587500  24.088896\n",
      "511  25.057500  24.304969\n",
      "\n",
      "[512 rows x 2 columns]\n",
      "Epoch 13/25, Training Loss: 0.0187\n",
      "Epoch 13/25, Validation Loss: 0.1202\n",
      "        actual  predicted\n",
      "0    25.911111  25.488527\n",
      "1    26.005000  25.698670\n",
      "2    26.232500  25.755829\n",
      "3    26.666667  26.015253\n",
      "4    27.037500  26.458023\n",
      "..         ...        ...\n",
      "507  24.112500  24.058368\n",
      "508  24.205000  24.113874\n",
      "509  24.405000  24.246960\n",
      "510  24.587500  24.500771\n",
      "511  25.057500  24.692612\n",
      "\n",
      "[512 rows x 2 columns]\n",
      "Epoch 14/25, Training Loss: 0.0181\n",
      "Epoch 14/25, Validation Loss: 0.0704\n",
      "        actual  predicted\n",
      "0    25.911111  25.290727\n",
      "1    26.005000  25.441343\n",
      "2    26.232500  25.497717\n",
      "3    26.666667  25.780595\n",
      "4    27.037500  26.286347\n",
      "..         ...        ...\n",
      "507  24.112500  23.817792\n",
      "508  24.205000  23.811428\n",
      "509  24.405000  23.914498\n",
      "510  24.587500  24.152911\n",
      "511  25.057500  24.306824\n",
      "\n",
      "[512 rows x 2 columns]\n",
      "Epoch 15/25, Training Loss: 0.0174\n",
      "Epoch 15/25, Validation Loss: 0.0704\n",
      "        actual  predicted\n",
      "0    25.911111  24.875001\n",
      "1    26.005000  25.057635\n",
      "2    26.232500  25.160825\n",
      "3    26.666667  25.403222\n",
      "4    27.037500  25.892177\n",
      "..         ...        ...\n",
      "507  24.112500  23.416832\n",
      "508  24.205000  23.473820\n",
      "509  24.405000  23.637481\n",
      "510  24.587500  23.874336\n",
      "511  25.057500  24.013849\n",
      "\n",
      "[512 rows x 2 columns]\n",
      "Epoch 16/25, Training Loss: 0.0167\n",
      "Epoch 16/25, Validation Loss: 0.1682\n",
      "        actual  predicted\n",
      "0    25.911111  25.265159\n",
      "1    26.005000  25.412268\n",
      "2    26.232500  25.486398\n",
      "3    26.666667  25.699826\n",
      "4    27.037500  26.123518\n",
      "..         ...        ...\n",
      "507  24.112500  23.723098\n",
      "508  24.205000  23.811652\n",
      "509  24.405000  23.951192\n",
      "510  24.587500  24.188747\n",
      "511  25.057500  24.363323\n",
      "\n",
      "[512 rows x 2 columns]\n",
      "Epoch 17/25, Training Loss: 0.0172\n",
      "Epoch 17/25, Validation Loss: 0.1184\n",
      "        actual  predicted\n",
      "0    25.911111  25.646023\n",
      "1    26.005000  25.838899\n",
      "2    26.232500  25.917945\n",
      "3    26.666667  26.185566\n",
      "4    27.037500  26.643692\n",
      "..         ...        ...\n",
      "507  24.112500  23.852007\n",
      "508  24.205000  23.947581\n",
      "509  24.405000  24.087232\n",
      "510  24.587500  24.347746\n",
      "511  25.057500  24.541119\n",
      "\n",
      "[512 rows x 2 columns]\n",
      "Epoch 18/25, Training Loss: 0.0157\n",
      "Epoch 18/25, Validation Loss: 0.0589\n",
      "        actual  predicted\n",
      "0    25.911111  25.517961\n",
      "1    26.005000  25.693210\n",
      "2    26.232500  25.751860\n",
      "3    26.666667  25.997941\n",
      "4    27.037500  26.422986\n",
      "..         ...        ...\n",
      "507  24.112500  23.827894\n",
      "508  24.205000  23.869443\n",
      "509  24.405000  23.996746\n",
      "510  24.587500  24.268162\n",
      "511  25.057500  24.444713\n",
      "\n",
      "[512 rows x 2 columns]\n",
      "Epoch 19/25, Training Loss: 0.0158\n",
      "Epoch 19/25, Validation Loss: 0.0806\n",
      "        actual  predicted\n",
      "0    25.911111  25.438192\n",
      "1    26.005000  25.622628\n",
      "2    26.232500  25.693095\n",
      "3    26.666667  25.982558\n",
      "4    27.037500  26.391624\n",
      "..         ...        ...\n",
      "507  24.112500  23.789608\n",
      "508  24.205000  23.875417\n",
      "509  24.405000  23.976706\n",
      "510  24.587500  24.222791\n",
      "511  25.057500  24.408621\n",
      "\n",
      "[512 rows x 2 columns]\n",
      "Epoch 20/25, Training Loss: 0.0157\n",
      "Epoch 20/25, Validation Loss: 0.0778\n",
      "        actual  predicted\n",
      "0    25.911111  25.559058\n",
      "1    26.005000  25.731132\n",
      "2    26.232500  25.823815\n",
      "3    26.666667  26.104136\n",
      "4    27.037500  26.562097\n",
      "..         ...        ...\n",
      "507  24.112500  23.743925\n",
      "508  24.205000  23.798900\n",
      "509  24.405000  23.896070\n",
      "510  24.587500  24.119993\n",
      "511  25.057500  24.306668\n",
      "\n",
      "[512 rows x 2 columns]\n",
      "Epoch 21/25, Training Loss: 0.0154\n",
      "Epoch 21/25, Validation Loss: 0.1253\n",
      "        actual  predicted\n",
      "0    25.911111  25.371824\n",
      "1    26.005000  25.517357\n",
      "2    26.232500  25.603984\n",
      "3    26.666667  25.864982\n",
      "4    27.037500  26.358015\n",
      "..         ...        ...\n",
      "507  24.112500  23.906870\n",
      "508  24.205000  23.952283\n",
      "509  24.405000  24.089022\n",
      "510  24.587500  24.367889\n",
      "511  25.057500  24.590031\n",
      "\n",
      "[512 rows x 2 columns]\n",
      "Epoch 22/25, Training Loss: 0.0148\n",
      "Epoch 22/25, Validation Loss: 0.0970\n",
      "        actual  predicted\n",
      "0    25.911111  25.540531\n",
      "1    26.005000  25.763636\n",
      "2    26.232500  25.852039\n",
      "3    26.666667  26.148503\n",
      "4    27.037500  26.582755\n",
      "..         ...        ...\n",
      "507  24.112500  24.250702\n",
      "508  24.205000  24.328885\n",
      "509  24.405000  24.421474\n",
      "510  24.587500  24.683176\n",
      "511  25.057500  24.896813\n",
      "\n",
      "[512 rows x 2 columns]\n",
      "Early stopping!\n",
      "          actual  predicted\n",
      "0      25.911111  25.540531\n",
      "1      26.005000  25.763636\n",
      "2      26.232500  25.852039\n",
      "3      26.666667  26.148503\n",
      "4      27.037500  26.582755\n",
      "...          ...        ...\n",
      "19210  27.545000  26.741068\n",
      "19211  27.482500  26.741578\n",
      "19212  27.435000  26.708981\n",
      "19213  27.362500  26.747320\n",
      "19214  27.335000  26.815713\n",
      "\n",
      "[19215 rows x 2 columns]\n",
      "Score (RMSE): 0.9016\n",
      "Score (MAE): 0.7016\n",
      "Score (MAPE): 2.5326%\n",
      "training data cutoff:  2023-07-14 05:00:00\n",
      "tmp                         float64\n",
      "hum                         float64\n",
      "CO2                         float64\n",
      "VOC                         float64\n",
      "vis                         float64\n",
      "IR                          float64\n",
      "WIFI                        float64\n",
      "BLE                         float64\n",
      "rssi                        float64\n",
      "channel_rssi                float64\n",
      "channel_index               float64\n",
      "spreading_factor            float64\n",
      "bandwidth                   float64\n",
      "f_cnt                       float64\n",
      "isHoliday                   float64\n",
      "isExamTime                  float64\n",
      "weekday                     float64\n",
      "month                       float64\n",
      "hour_sin                    float64\n",
      "semester_SS23               float64\n",
      "semester_WS22/23            float64\n",
      "semester_WS23/24            float64\n",
      "group                       float64\n",
      "device_id_hka-aqm-am001     float64\n",
      "device_id_hka-aqm-am002     float64\n",
      "device_id_hka-aqm-am003a    float64\n",
      "device_id_hka-aqm-am003b    float64\n",
      "device_id_hka-aqm-am004     float64\n",
      "device_id_hka-aqm-am005     float64\n",
      "device_id_hka-aqm-am107     float64\n",
      "device_id_hka-aqm-am109     float64\n",
      "device_id_hka-aqm-am110     float64\n",
      "device_id_hka-aqm-am111     float64\n",
      "device_id_hka-aqm-am115     float64\n",
      "device_id_hka-aqm-am116     float64\n",
      "device_id_hka-aqm-am117     float64\n",
      "device_id_hka-aqm-am123     float64\n",
      "device_id_hka-aqm-am124     float64\n",
      "device_id_hka-aqm-am126     float64\n",
      "device_id_hka-aqm-am201a    float64\n",
      "device_id_hka-aqm-am201b    float64\n",
      "device_id_hka-aqm-am204     float64\n",
      "device_id_hka-aqm-am205     float64\n",
      "device_id_hka-aqm-am209     float64\n",
      "device_id_hka-aqm-am210     float64\n",
      "device_id_hka-aqm-am211     float64\n",
      "device_id_hka-aqm-am301     float64\n",
      "device_id_hka-aqm-am307     float64\n",
      "device_id_hka-aqm-am308     float64\n",
      "dtype: object\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Studium\\Semester_6\\IoT_Project\\utils.py:911: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_train[columns_to_scale] = scaler.fit_transform(df_train[columns_to_scale])\n",
      "c:\\Studium\\Semester_6\\IoT_Project\\utils.py:912: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_test[columns_to_scale] = scaler.transform(df_test[columns_to_scale])\n",
      "c:\\Studium\\Semester_6\\IoT_Project\\utils.py:916: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_train.drop(['date_time_rounded'], axis=1, inplace=True)\n",
      "c:\\Studium\\Semester_6\\IoT_Project\\utils.py:917: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_test.drop(['date_time_rounded'], axis=1, inplace=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "feature count:  49\n",
      "feature count:  49\n",
      "Training data shape: torch.Size([75940, 20, 49]) torch.Size([75940, 1])\n",
      "Testing data shape: torch.Size([19215, 20, 49]) torch.Size([19215, 1])\n",
      "same columns\n",
      "date_time_rounded           datetime64[ns]\n",
      "tmp                                float64\n",
      "hum                                float64\n",
      "CO2                                float64\n",
      "VOC                                float64\n",
      "vis                                float64\n",
      "IR                                 float64\n",
      "WIFI                               float64\n",
      "BLE                                float64\n",
      "rssi                               float64\n",
      "channel_rssi                       float64\n",
      "channel_index                      float64\n",
      "spreading_factor                   float64\n",
      "bandwidth                          float64\n",
      "f_cnt                              float64\n",
      "isHoliday                          float64\n",
      "isExamTime                         float64\n",
      "weekday                            float64\n",
      "month                              float64\n",
      "hour_sin                           float64\n",
      "semester_SS23                      float64\n",
      "semester_WS22/23                   float64\n",
      "semester_WS23/24                   float64\n",
      "group                                int32\n",
      "device_id_hka-aqm-am001              uint8\n",
      "device_id_hka-aqm-am002              uint8\n",
      "device_id_hka-aqm-am003a             uint8\n",
      "device_id_hka-aqm-am003b             uint8\n",
      "device_id_hka-aqm-am004              uint8\n",
      "device_id_hka-aqm-am005              uint8\n",
      "device_id_hka-aqm-am107              uint8\n",
      "device_id_hka-aqm-am109              uint8\n",
      "device_id_hka-aqm-am110              uint8\n",
      "device_id_hka-aqm-am111              uint8\n",
      "device_id_hka-aqm-am115              uint8\n",
      "device_id_hka-aqm-am116              uint8\n",
      "device_id_hka-aqm-am117              uint8\n",
      "device_id_hka-aqm-am123              uint8\n",
      "device_id_hka-aqm-am124              uint8\n",
      "device_id_hka-aqm-am126              uint8\n",
      "device_id_hka-aqm-am201a             uint8\n",
      "device_id_hka-aqm-am201b             uint8\n",
      "device_id_hka-aqm-am204              uint8\n",
      "device_id_hka-aqm-am205              uint8\n",
      "device_id_hka-aqm-am209              uint8\n",
      "device_id_hka-aqm-am210              uint8\n",
      "device_id_hka-aqm-am211              uint8\n",
      "device_id_hka-aqm-am301              uint8\n",
      "device_id_hka-aqm-am307              uint8\n",
      "device_id_hka-aqm-am308              uint8\n",
      "dtype: object\n",
      "date_time_rounded           datetime64[ns]\n",
      "tmp                                float64\n",
      "hum                                float64\n",
      "CO2                                float64\n",
      "VOC                                float64\n",
      "vis                                float64\n",
      "IR                                 float64\n",
      "WIFI                               float64\n",
      "BLE                                float64\n",
      "rssi                               float64\n",
      "channel_rssi                       float64\n",
      "channel_index                      float64\n",
      "spreading_factor                   float64\n",
      "bandwidth                          float64\n",
      "f_cnt                              float64\n",
      "isHoliday                          float64\n",
      "isExamTime                         float64\n",
      "weekday                            float64\n",
      "month                              float64\n",
      "hour_sin                           float64\n",
      "semester_SS23                      float64\n",
      "semester_WS22/23                   float64\n",
      "semester_WS23/24                   float64\n",
      "group                                int32\n",
      "device_id_hka-aqm-am001              uint8\n",
      "device_id_hka-aqm-am002              uint8\n",
      "device_id_hka-aqm-am003a             uint8\n",
      "device_id_hka-aqm-am003b             uint8\n",
      "device_id_hka-aqm-am004              uint8\n",
      "device_id_hka-aqm-am005              uint8\n",
      "device_id_hka-aqm-am107              uint8\n",
      "device_id_hka-aqm-am109              uint8\n",
      "device_id_hka-aqm-am110              uint8\n",
      "device_id_hka-aqm-am111              uint8\n",
      "device_id_hka-aqm-am115              uint8\n",
      "device_id_hka-aqm-am116              uint8\n",
      "device_id_hka-aqm-am117              uint8\n",
      "device_id_hka-aqm-am123              uint8\n",
      "device_id_hka-aqm-am124              uint8\n",
      "device_id_hka-aqm-am126              uint8\n",
      "device_id_hka-aqm-am201a             uint8\n",
      "device_id_hka-aqm-am201b             uint8\n",
      "device_id_hka-aqm-am204              uint8\n",
      "device_id_hka-aqm-am205              uint8\n",
      "device_id_hka-aqm-am209              uint8\n",
      "device_id_hka-aqm-am210              uint8\n",
      "device_id_hka-aqm-am211              uint8\n",
      "device_id_hka-aqm-am301              uint8\n",
      "device_id_hka-aqm-am307              uint8\n",
      "device_id_hka-aqm-am308              uint8\n",
      "dtype: object\n",
      "         date_time_rounded        tmp        hum         CO2         VOC  \\\n",
      "100258 2022-10-10 15:00:00  24.310909  47.668182  754.000000  485.090909   \n",
      "100259 2022-10-10 17:00:00  25.455000  44.930000  589.500000  585.833333   \n",
      "100260 2022-10-10 20:00:00  25.072500  50.062500  613.250000  601.750000   \n",
      "100261 2022-10-10 21:00:00  24.945000  51.042500  598.500000  568.250000   \n",
      "100262 2022-10-11 01:00:00  24.865000  49.527500  583.750000  562.000000   \n",
      "...                    ...        ...        ...         ...         ...   \n",
      "148552 2023-09-26 13:00:00  27.807500  36.012500  472.500000  962.250000   \n",
      "148553 2023-09-26 14:00:00  28.415714  35.207143  473.714286  952.857143   \n",
      "148554 2023-09-26 17:00:00  27.802500  36.237500  504.000000  925.500000   \n",
      "148555 2023-09-26 19:00:00  27.620000  36.787500  512.500000  932.500000   \n",
      "148556 2023-09-26 20:00:00  27.545000  37.025000  518.500000  954.750000   \n",
      "\n",
      "                vis          IR      WIFI        BLE        rssi  ...  \\\n",
      "100258   198.363636   25.000000  1.090909   1.363636  -68.090909  ...   \n",
      "100259   132.833333   14.166667  0.500000   0.500000  -58.000000  ...   \n",
      "100260     9.000000    1.000000  0.500000   0.000000  -62.250000  ...   \n",
      "100261     9.000000    1.000000  0.750000   0.000000  -61.750000  ...   \n",
      "100262     9.500000    1.500000  0.750000   0.000000  -59.000000  ...   \n",
      "...             ...         ...       ...        ...         ...  ...   \n",
      "148552  1127.250000  257.250000  1.000000   0.500000 -101.750000  ...   \n",
      "148553   608.285714  143.142857  1.857143  17.142857  -90.142857  ...   \n",
      "148554    49.750000   13.000000  3.000000  13.750000  -72.250000  ...   \n",
      "148555     6.000000    1.250000  2.250000   6.750000  -87.750000  ...   \n",
      "148556     5.500000    1.250000  3.500000  13.500000  -72.750000  ...   \n",
      "\n",
      "        device_id_hka-aqm-am201a  device_id_hka-aqm-am201b  \\\n",
      "100258                         0                         0   \n",
      "100259                         0                         0   \n",
      "100260                         0                         0   \n",
      "100261                         0                         0   \n",
      "100262                         0                         0   \n",
      "...                          ...                       ...   \n",
      "148552                         0                         0   \n",
      "148553                         0                         0   \n",
      "148554                         0                         0   \n",
      "148555                         0                         0   \n",
      "148556                         0                         0   \n",
      "\n",
      "        device_id_hka-aqm-am204  device_id_hka-aqm-am205  \\\n",
      "100258                        0                        0   \n",
      "100259                        0                        0   \n",
      "100260                        0                        0   \n",
      "100261                        0                        0   \n",
      "100262                        0                        0   \n",
      "...                         ...                      ...   \n",
      "148552                        0                        0   \n",
      "148553                        0                        0   \n",
      "148554                        0                        0   \n",
      "148555                        0                        0   \n",
      "148556                        0                        0   \n",
      "\n",
      "        device_id_hka-aqm-am209  device_id_hka-aqm-am210  \\\n",
      "100258                        0                        0   \n",
      "100259                        0                        0   \n",
      "100260                        0                        0   \n",
      "100261                        0                        0   \n",
      "100262                        0                        0   \n",
      "...                         ...                      ...   \n",
      "148552                        0                        0   \n",
      "148553                        0                        0   \n",
      "148554                        0                        0   \n",
      "148555                        0                        0   \n",
      "148556                        0                        0   \n",
      "\n",
      "        device_id_hka-aqm-am211  device_id_hka-aqm-am301  \\\n",
      "100258                        0                        0   \n",
      "100259                        0                        0   \n",
      "100260                        0                        0   \n",
      "100261                        0                        0   \n",
      "100262                        0                        0   \n",
      "...                         ...                      ...   \n",
      "148552                        0                        0   \n",
      "148553                        0                        0   \n",
      "148554                        0                        0   \n",
      "148555                        0                        0   \n",
      "148556                        0                        0   \n",
      "\n",
      "        device_id_hka-aqm-am307  device_id_hka-aqm-am308  \n",
      "100258                        0                        0  \n",
      "100259                        0                        0  \n",
      "100260                        0                        0  \n",
      "100261                        0                        0  \n",
      "100262                        0                        0  \n",
      "...                         ...                      ...  \n",
      "148552                        0                        1  \n",
      "148553                        0                        1  \n",
      "148554                        0                        1  \n",
      "148555                        0                        1  \n",
      "148556                        0                        1  \n",
      "\n",
      "[48299 rows x 50 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\t-ehm\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\transformer.py:286: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
      "c:\\Users\\t-ehm\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\optim\\lr_scheduler.py:28: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\"The verbose parameter is deprecated. Please use get_last_lr() \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        actual   predicted\n",
      "0    76.388886  181.946139\n",
      "1    26.250005  171.634590\n",
      "2    22.499999  144.561277\n",
      "3    15.666664  130.864455\n",
      "4    15.000004  126.167211\n",
      "..         ...         ...\n",
      "507  11.500002  139.329610\n",
      "508  20.249999  142.229391\n",
      "509  59.249995  137.079170\n",
      "510  76.500001  137.196976\n",
      "511  84.749999  126.039905\n",
      "\n",
      "[512 rows x 2 columns]\n",
      "Epoch 1/25, Training Loss: 1.0357\n",
      "Epoch 1/25, Validation Loss: 0.2762\n",
      "        actual   predicted\n",
      "0    76.388886  119.324708\n",
      "1    26.250005  115.105778\n",
      "2    22.499999   90.518638\n",
      "3    15.666664   88.452795\n",
      "4    15.000004   84.497225\n",
      "..         ...         ...\n",
      "507  11.500002  175.095889\n",
      "508  20.249999  205.690073\n",
      "509  59.249995  189.719647\n",
      "510  76.500001  176.267600\n",
      "511  84.749999  146.898182\n",
      "\n",
      "[512 rows x 2 columns]\n",
      "Epoch 2/25, Training Loss: 0.8221\n",
      "Epoch 2/25, Validation Loss: 0.2708\n",
      "        actual   predicted\n",
      "0    76.388886  130.951218\n",
      "1    26.250005  132.227900\n",
      "2    22.499999  121.141679\n",
      "3    15.666664  116.612426\n",
      "4    15.000004  111.780449\n",
      "..         ...         ...\n",
      "507  11.500002  160.928658\n",
      "508  20.249999  171.195231\n",
      "509  59.249995  159.695947\n",
      "510  76.500001  153.002585\n",
      "511  84.749999  140.305909\n",
      "\n",
      "[512 rows x 2 columns]\n",
      "Epoch 3/25, Training Loss: 0.7739\n",
      "Epoch 3/25, Validation Loss: 0.2791\n",
      "        actual   predicted\n",
      "0    76.388886  178.913900\n",
      "1    26.250005  182.306767\n",
      "2    22.499999  157.852185\n",
      "3    15.666664  151.110933\n",
      "4    15.000004  139.762904\n",
      "..         ...         ...\n",
      "507  11.500002  177.810096\n",
      "508  20.249999  192.103472\n",
      "509  59.249995  180.959538\n",
      "510  76.500001  176.044235\n",
      "511  84.749999  162.372132\n",
      "\n",
      "[512 rows x 2 columns]\n",
      "Epoch 4/25, Training Loss: 0.7840\n",
      "Epoch 4/25, Validation Loss: 0.2688\n",
      "        actual   predicted\n",
      "0    76.388886  186.291878\n",
      "1    26.250005  178.749095\n",
      "2    22.499999  150.265190\n",
      "3    15.666664  138.926943\n",
      "4    15.000004  135.534497\n",
      "..         ...         ...\n",
      "507  11.500002  263.409422\n",
      "508  20.249999  261.049106\n",
      "509  59.249995  250.040915\n",
      "510  76.500001  252.474590\n",
      "511  84.749999  224.842233\n",
      "\n",
      "[512 rows x 2 columns]\n",
      "Epoch 5/25, Training Loss: 0.7615\n",
      "Epoch 5/25, Validation Loss: 0.2838\n",
      "        actual  predicted\n",
      "0    76.388886   4.620638\n",
      "1    26.250005  10.931861\n",
      "2    22.499999 -21.713114\n",
      "3    15.666664 -22.190906\n",
      "4    15.000004 -29.455402\n",
      "..         ...        ...\n",
      "507  11.500002  36.923900\n",
      "508  20.249999  60.675945\n",
      "509  59.249995  45.903348\n",
      "510  76.500001  43.890810\n",
      "511  84.749999  18.731896\n",
      "\n",
      "[512 rows x 2 columns]\n",
      "Epoch 6/25, Training Loss: 0.7631\n",
      "Epoch 6/25, Validation Loss: 0.2886\n",
      "        actual   predicted\n",
      "0    76.388886   71.251764\n",
      "1    26.250005   70.343286\n",
      "2    22.499999   48.752697\n",
      "3    15.666664   43.659396\n",
      "4    15.000004   38.350308\n",
      "..         ...         ...\n",
      "507  11.500002  136.239080\n",
      "508  20.249999  136.530410\n",
      "509  59.249995  120.139583\n",
      "510  76.500001  117.651431\n",
      "511  84.749999   92.635252\n",
      "\n",
      "[512 rows x 2 columns]\n",
      "Epoch 7/25, Training Loss: 0.7832\n",
      "Epoch 7/25, Validation Loss: 0.2649\n",
      "        actual   predicted\n",
      "0    76.388886  111.479024\n",
      "1    26.250005  109.357027\n",
      "2    22.499999   86.357383\n",
      "3    15.666664   87.242165\n",
      "4    15.000004   85.967058\n",
      "..         ...         ...\n",
      "507  11.500002  133.457223\n",
      "508  20.249999  148.567679\n",
      "509  59.249995  142.756621\n",
      "510  76.500001  138.829726\n",
      "511  84.749999  121.025156\n",
      "\n",
      "[512 rows x 2 columns]\n",
      "Epoch 8/25, Training Loss: 0.7343\n",
      "Epoch 8/25, Validation Loss: 0.2792\n",
      "        actual   predicted\n",
      "0    76.388886  209.130695\n",
      "1    26.250005  207.539361\n",
      "2    22.499999  183.954153\n",
      "3    15.666664  179.675329\n",
      "4    15.000004  173.828141\n",
      "..         ...         ...\n",
      "507  11.500002  225.103643\n",
      "508  20.249999  228.139249\n",
      "509  59.249995  219.614412\n",
      "510  76.500001  220.323571\n",
      "511  84.749999  205.499404\n",
      "\n",
      "[512 rows x 2 columns]\n",
      "Epoch 9/25, Training Loss: 0.7315\n",
      "Epoch 9/25, Validation Loss: 0.2968\n",
      "        actual   predicted\n",
      "0    76.388886  -38.441547\n",
      "1    26.250005  -42.783334\n",
      "2    22.499999  -63.023945\n",
      "3    15.666664  -62.276547\n",
      "4    15.000004  -65.216674\n",
      "..         ...         ...\n",
      "507  11.500002   95.586264\n",
      "508  20.249999  115.343019\n",
      "509  59.249995   84.543389\n",
      "510  76.500001   72.969701\n",
      "511  84.749999   27.815104\n",
      "\n",
      "[512 rows x 2 columns]\n",
      "Epoch 10/25, Training Loss: 0.7216\n",
      "Epoch 10/25, Validation Loss: 0.2755\n",
      "        actual   predicted\n",
      "0    76.388886   21.002987\n",
      "1    26.250005   20.336770\n",
      "2    22.499999    6.884620\n",
      "3    15.666664    6.271684\n",
      "4    15.000004    3.197032\n",
      "..         ...         ...\n",
      "507  11.500002   91.387918\n",
      "508  20.249999  116.758392\n",
      "509  59.249995   99.669101\n",
      "510  76.500001   90.380478\n",
      "511  84.749999   66.248543\n",
      "\n",
      "[512 rows x 2 columns]\n",
      "Epoch 11/25, Training Loss: 0.7276\n",
      "Epoch 11/25, Validation Loss: 0.2903\n",
      "        actual  predicted\n",
      "0    76.388886  67.366172\n",
      "1    26.250005  64.192303\n",
      "2    22.499999  45.770801\n",
      "3    15.666664  41.727739\n",
      "4    15.000004  37.273246\n",
      "..         ...        ...\n",
      "507  11.500002  78.687275\n",
      "508  20.249999  83.863436\n",
      "509  59.249995  75.161685\n",
      "510  76.500001  71.732153\n",
      "511  84.749999  60.105255\n",
      "\n",
      "[512 rows x 2 columns]\n",
      "Early stopping!\n",
      "          actual  predicted\n",
      "0      76.388886  67.366172\n",
      "1      26.250005  64.192303\n",
      "2      22.499999  45.770801\n",
      "3      15.666664  41.727739\n",
      "4      15.000004  37.273246\n",
      "...          ...        ...\n",
      "19210   5.499997  31.457469\n",
      "19211   4.750002  30.923546\n",
      "19212   4.750002  31.877705\n",
      "19213   4.750002  33.485397\n",
      "19214   4.000007  30.204998\n",
      "\n",
      "[19215 rows x 2 columns]\n",
      "Score (RMSE): 563.7551\n",
      "Score (MAE): 141.2552\n",
      "Score (MAPE): 383.4883%\n",
      "training data cutoff:  2023-07-14 05:00:00\n",
      "tmp                         float64\n",
      "hum                         float64\n",
      "CO2                         float64\n",
      "VOC                         float64\n",
      "vis                         float64\n",
      "IR                          float64\n",
      "WIFI                        float64\n",
      "BLE                         float64\n",
      "rssi                        float64\n",
      "channel_rssi                float64\n",
      "channel_index               float64\n",
      "spreading_factor            float64\n",
      "bandwidth                   float64\n",
      "f_cnt                       float64\n",
      "isHoliday                   float64\n",
      "isExamTime                  float64\n",
      "weekday                     float64\n",
      "month                       float64\n",
      "hour_sin                    float64\n",
      "semester_SS23               float64\n",
      "semester_WS22/23            float64\n",
      "semester_WS23/24            float64\n",
      "group                       float64\n",
      "device_id_hka-aqm-am001     float64\n",
      "device_id_hka-aqm-am002     float64\n",
      "device_id_hka-aqm-am003a    float64\n",
      "device_id_hka-aqm-am003b    float64\n",
      "device_id_hka-aqm-am004     float64\n",
      "device_id_hka-aqm-am005     float64\n",
      "device_id_hka-aqm-am107     float64\n",
      "device_id_hka-aqm-am109     float64\n",
      "device_id_hka-aqm-am110     float64\n",
      "device_id_hka-aqm-am111     float64\n",
      "device_id_hka-aqm-am115     float64\n",
      "device_id_hka-aqm-am116     float64\n",
      "device_id_hka-aqm-am117     float64\n",
      "device_id_hka-aqm-am123     float64\n",
      "device_id_hka-aqm-am124     float64\n",
      "device_id_hka-aqm-am126     float64\n",
      "device_id_hka-aqm-am201a    float64\n",
      "device_id_hka-aqm-am201b    float64\n",
      "device_id_hka-aqm-am204     float64\n",
      "device_id_hka-aqm-am205     float64\n",
      "device_id_hka-aqm-am209     float64\n",
      "device_id_hka-aqm-am210     float64\n",
      "device_id_hka-aqm-am211     float64\n",
      "device_id_hka-aqm-am301     float64\n",
      "device_id_hka-aqm-am307     float64\n",
      "device_id_hka-aqm-am308     float64\n",
      "dtype: object\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Studium\\Semester_6\\IoT_Project\\utils.py:911: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_train[columns_to_scale] = scaler.fit_transform(df_train[columns_to_scale])\n",
      "c:\\Studium\\Semester_6\\IoT_Project\\utils.py:912: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_test[columns_to_scale] = scaler.transform(df_test[columns_to_scale])\n",
      "c:\\Studium\\Semester_6\\IoT_Project\\utils.py:916: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_train.drop(['date_time_rounded'], axis=1, inplace=True)\n",
      "c:\\Studium\\Semester_6\\IoT_Project\\utils.py:917: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_test.drop(['date_time_rounded'], axis=1, inplace=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "feature count:  49\n",
      "feature count:  49\n",
      "Training data shape: torch.Size([75940, 20, 49]) torch.Size([75940, 1])\n",
      "Testing data shape: torch.Size([19215, 20, 49]) torch.Size([19215, 1])\n",
      "same columns\n",
      "date_time_rounded           datetime64[ns]\n",
      "tmp                                float64\n",
      "hum                                float64\n",
      "CO2                                float64\n",
      "VOC                                float64\n",
      "vis                                float64\n",
      "IR                                 float64\n",
      "WIFI                               float64\n",
      "BLE                                float64\n",
      "rssi                               float64\n",
      "channel_rssi                       float64\n",
      "channel_index                      float64\n",
      "spreading_factor                   float64\n",
      "bandwidth                          float64\n",
      "f_cnt                              float64\n",
      "isHoliday                          float64\n",
      "isExamTime                         float64\n",
      "weekday                            float64\n",
      "month                              float64\n",
      "hour_sin                           float64\n",
      "semester_SS23                      float64\n",
      "semester_WS22/23                   float64\n",
      "semester_WS23/24                   float64\n",
      "group                                int32\n",
      "device_id_hka-aqm-am001              uint8\n",
      "device_id_hka-aqm-am002              uint8\n",
      "device_id_hka-aqm-am003a             uint8\n",
      "device_id_hka-aqm-am003b             uint8\n",
      "device_id_hka-aqm-am004              uint8\n",
      "device_id_hka-aqm-am005              uint8\n",
      "device_id_hka-aqm-am107              uint8\n",
      "device_id_hka-aqm-am109              uint8\n",
      "device_id_hka-aqm-am110              uint8\n",
      "device_id_hka-aqm-am111              uint8\n",
      "device_id_hka-aqm-am115              uint8\n",
      "device_id_hka-aqm-am116              uint8\n",
      "device_id_hka-aqm-am117              uint8\n",
      "device_id_hka-aqm-am123              uint8\n",
      "device_id_hka-aqm-am124              uint8\n",
      "device_id_hka-aqm-am126              uint8\n",
      "device_id_hka-aqm-am201a             uint8\n",
      "device_id_hka-aqm-am201b             uint8\n",
      "device_id_hka-aqm-am204              uint8\n",
      "device_id_hka-aqm-am205              uint8\n",
      "device_id_hka-aqm-am209              uint8\n",
      "device_id_hka-aqm-am210              uint8\n",
      "device_id_hka-aqm-am211              uint8\n",
      "device_id_hka-aqm-am301              uint8\n",
      "device_id_hka-aqm-am307              uint8\n",
      "device_id_hka-aqm-am308              uint8\n",
      "dtype: object\n",
      "date_time_rounded           datetime64[ns]\n",
      "tmp                                float64\n",
      "hum                                float64\n",
      "CO2                                float64\n",
      "VOC                                float64\n",
      "vis                                float64\n",
      "IR                                 float64\n",
      "WIFI                               float64\n",
      "BLE                                float64\n",
      "rssi                               float64\n",
      "channel_rssi                       float64\n",
      "channel_index                      float64\n",
      "spreading_factor                   float64\n",
      "bandwidth                          float64\n",
      "f_cnt                              float64\n",
      "isHoliday                          float64\n",
      "isExamTime                         float64\n",
      "weekday                            float64\n",
      "month                              float64\n",
      "hour_sin                           float64\n",
      "semester_SS23                      float64\n",
      "semester_WS22/23                   float64\n",
      "semester_WS23/24                   float64\n",
      "group                                int32\n",
      "device_id_hka-aqm-am001              uint8\n",
      "device_id_hka-aqm-am002              uint8\n",
      "device_id_hka-aqm-am003a             uint8\n",
      "device_id_hka-aqm-am003b             uint8\n",
      "device_id_hka-aqm-am004              uint8\n",
      "device_id_hka-aqm-am005              uint8\n",
      "device_id_hka-aqm-am107              uint8\n",
      "device_id_hka-aqm-am109              uint8\n",
      "device_id_hka-aqm-am110              uint8\n",
      "device_id_hka-aqm-am111              uint8\n",
      "device_id_hka-aqm-am115              uint8\n",
      "device_id_hka-aqm-am116              uint8\n",
      "device_id_hka-aqm-am117              uint8\n",
      "device_id_hka-aqm-am123              uint8\n",
      "device_id_hka-aqm-am124              uint8\n",
      "device_id_hka-aqm-am126              uint8\n",
      "device_id_hka-aqm-am201a             uint8\n",
      "device_id_hka-aqm-am201b             uint8\n",
      "device_id_hka-aqm-am204              uint8\n",
      "device_id_hka-aqm-am205              uint8\n",
      "device_id_hka-aqm-am209              uint8\n",
      "device_id_hka-aqm-am210              uint8\n",
      "device_id_hka-aqm-am211              uint8\n",
      "device_id_hka-aqm-am301              uint8\n",
      "device_id_hka-aqm-am307              uint8\n",
      "device_id_hka-aqm-am308              uint8\n",
      "dtype: object\n",
      "         date_time_rounded        tmp        hum         CO2         VOC  \\\n",
      "100258 2022-10-10 15:00:00  24.310909  47.668182  754.000000  485.090909   \n",
      "100259 2022-10-10 17:00:00  25.455000  44.930000  589.500000  585.833333   \n",
      "100260 2022-10-10 20:00:00  25.072500  50.062500  613.250000  601.750000   \n",
      "100261 2022-10-10 21:00:00  24.945000  51.042500  598.500000  568.250000   \n",
      "100262 2022-10-11 01:00:00  24.865000  49.527500  583.750000  562.000000   \n",
      "...                    ...        ...        ...         ...         ...   \n",
      "148552 2023-09-26 13:00:00  27.807500  36.012500  472.500000  962.250000   \n",
      "148553 2023-09-26 14:00:00  28.415714  35.207143  473.714286  952.857143   \n",
      "148554 2023-09-26 17:00:00  27.802500  36.237500  504.000000  925.500000   \n",
      "148555 2023-09-26 19:00:00  27.620000  36.787500  512.500000  932.500000   \n",
      "148556 2023-09-26 20:00:00  27.545000  37.025000  518.500000  954.750000   \n",
      "\n",
      "                vis          IR      WIFI        BLE        rssi  ...  \\\n",
      "100258   198.363636   25.000000  1.090909   1.363636  -68.090909  ...   \n",
      "100259   132.833333   14.166667  0.500000   0.500000  -58.000000  ...   \n",
      "100260     9.000000    1.000000  0.500000   0.000000  -62.250000  ...   \n",
      "100261     9.000000    1.000000  0.750000   0.000000  -61.750000  ...   \n",
      "100262     9.500000    1.500000  0.750000   0.000000  -59.000000  ...   \n",
      "...             ...         ...       ...        ...         ...  ...   \n",
      "148552  1127.250000  257.250000  1.000000   0.500000 -101.750000  ...   \n",
      "148553   608.285714  143.142857  1.857143  17.142857  -90.142857  ...   \n",
      "148554    49.750000   13.000000  3.000000  13.750000  -72.250000  ...   \n",
      "148555     6.000000    1.250000  2.250000   6.750000  -87.750000  ...   \n",
      "148556     5.500000    1.250000  3.500000  13.500000  -72.750000  ...   \n",
      "\n",
      "        device_id_hka-aqm-am201a  device_id_hka-aqm-am201b  \\\n",
      "100258                         0                         0   \n",
      "100259                         0                         0   \n",
      "100260                         0                         0   \n",
      "100261                         0                         0   \n",
      "100262                         0                         0   \n",
      "...                          ...                       ...   \n",
      "148552                         0                         0   \n",
      "148553                         0                         0   \n",
      "148554                         0                         0   \n",
      "148555                         0                         0   \n",
      "148556                         0                         0   \n",
      "\n",
      "        device_id_hka-aqm-am204  device_id_hka-aqm-am205  \\\n",
      "100258                        0                        0   \n",
      "100259                        0                        0   \n",
      "100260                        0                        0   \n",
      "100261                        0                        0   \n",
      "100262                        0                        0   \n",
      "...                         ...                      ...   \n",
      "148552                        0                        0   \n",
      "148553                        0                        0   \n",
      "148554                        0                        0   \n",
      "148555                        0                        0   \n",
      "148556                        0                        0   \n",
      "\n",
      "        device_id_hka-aqm-am209  device_id_hka-aqm-am210  \\\n",
      "100258                        0                        0   \n",
      "100259                        0                        0   \n",
      "100260                        0                        0   \n",
      "100261                        0                        0   \n",
      "100262                        0                        0   \n",
      "...                         ...                      ...   \n",
      "148552                        0                        0   \n",
      "148553                        0                        0   \n",
      "148554                        0                        0   \n",
      "148555                        0                        0   \n",
      "148556                        0                        0   \n",
      "\n",
      "        device_id_hka-aqm-am211  device_id_hka-aqm-am301  \\\n",
      "100258                        0                        0   \n",
      "100259                        0                        0   \n",
      "100260                        0                        0   \n",
      "100261                        0                        0   \n",
      "100262                        0                        0   \n",
      "...                         ...                      ...   \n",
      "148552                        0                        0   \n",
      "148553                        0                        0   \n",
      "148554                        0                        0   \n",
      "148555                        0                        0   \n",
      "148556                        0                        0   \n",
      "\n",
      "        device_id_hka-aqm-am307  device_id_hka-aqm-am308  \n",
      "100258                        0                        0  \n",
      "100259                        0                        0  \n",
      "100260                        0                        0  \n",
      "100261                        0                        0  \n",
      "100262                        0                        0  \n",
      "...                         ...                      ...  \n",
      "148552                        0                        1  \n",
      "148553                        0                        1  \n",
      "148554                        0                        1  \n",
      "148555                        0                        1  \n",
      "148556                        0                        1  \n",
      "\n",
      "[48299 rows x 50 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\t-ehm\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\transformer.py:286: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
      "c:\\Users\\t-ehm\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\optim\\lr_scheduler.py:28: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\"The verbose parameter is deprecated. Please use get_last_lr() \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          actual    predicted\n",
      "0     804.611111   617.086950\n",
      "1     909.750003   683.702757\n",
      "2    1168.999987   771.495875\n",
      "3    1379.333333  1104.664693\n",
      "4    1967.749974  1363.614622\n",
      "..           ...          ...\n",
      "507  1009.999999   863.405301\n",
      "508   960.249993   883.828806\n",
      "509   871.250002   856.103809\n",
      "510   707.750000   811.737021\n",
      "511   649.500003   733.702563\n",
      "\n",
      "[512 rows x 2 columns]\n",
      "Epoch 1/25, Training Loss: 0.4525\n",
      "Epoch 1/25, Validation Loss: 0.1968\n",
      "          actual    predicted\n",
      "0     804.611111   587.487740\n",
      "1     909.750003   679.603526\n",
      "2    1168.999987   786.924428\n",
      "3    1379.333333  1105.309129\n",
      "4    1967.749974  1366.648507\n",
      "..           ...          ...\n",
      "507  1009.999999   805.581582\n",
      "508   960.249993   829.036141\n",
      "509   871.250002   794.797348\n",
      "510   707.750000   746.563433\n",
      "511   649.500003   655.051162\n",
      "\n",
      "[512 rows x 2 columns]\n",
      "Epoch 2/25, Training Loss: 0.1707\n",
      "Epoch 2/25, Validation Loss: 0.1493\n",
      "          actual    predicted\n",
      "0     804.611111   634.189222\n",
      "1     909.750003   733.763557\n",
      "2    1168.999987   867.039948\n",
      "3    1379.333333  1202.502200\n",
      "4    1967.749974  1454.294982\n",
      "..           ...          ...\n",
      "507  1009.999999   932.371914\n",
      "508   960.249993   957.989185\n",
      "509   871.250002   920.887447\n",
      "510   707.750000   860.713291\n",
      "511   649.500003   741.606687\n",
      "\n",
      "[512 rows x 2 columns]\n",
      "Epoch 3/25, Training Loss: 0.1588\n",
      "Epoch 3/25, Validation Loss: 0.1925\n",
      "          actual    predicted\n",
      "0     804.611111   626.321229\n",
      "1     909.750003   749.967442\n",
      "2    1168.999987   890.092802\n",
      "3    1379.333333  1263.516448\n",
      "4    1967.749974  1547.392597\n",
      "..           ...          ...\n",
      "507  1009.999999   897.632573\n",
      "508   960.249993   945.866761\n",
      "509   871.250002   899.724724\n",
      "510   707.750000   823.380062\n",
      "511   649.500003   696.745761\n",
      "\n",
      "[512 rows x 2 columns]\n",
      "Epoch 4/25, Training Loss: 0.1528\n",
      "Epoch 4/25, Validation Loss: 0.2084\n",
      "          actual    predicted\n",
      "0     804.611111   608.541589\n",
      "1     909.750003   743.511032\n",
      "2    1168.999987   878.363824\n",
      "3    1379.333333  1240.378357\n",
      "4    1967.749974  1524.109574\n",
      "..           ...          ...\n",
      "507  1009.999999   816.050850\n",
      "508   960.249993   857.884608\n",
      "509   871.250002   817.362998\n",
      "510   707.750000   756.957277\n",
      "511   649.500003   648.846905\n",
      "\n",
      "[512 rows x 2 columns]\n",
      "Epoch 5/25, Training Loss: 0.1463\n",
      "Epoch 5/25, Validation Loss: 0.1368\n",
      "          actual    predicted\n",
      "0     804.611111   592.297061\n",
      "1     909.750003   702.400344\n",
      "2    1168.999987   819.651260\n",
      "3    1379.333333  1121.265320\n",
      "4    1967.749974  1360.300915\n",
      "..           ...          ...\n",
      "507  1009.999999   812.285658\n",
      "508   960.249993   857.183265\n",
      "509   871.250002   805.811062\n",
      "510   707.750000   731.826757\n",
      "511   649.500003   627.653021\n",
      "\n",
      "[512 rows x 2 columns]\n",
      "Epoch 6/25, Training Loss: 0.1413\n",
      "Epoch 6/25, Validation Loss: 0.1356\n",
      "          actual    predicted\n",
      "0     804.611111   613.252235\n",
      "1     909.750003   754.836813\n",
      "2    1168.999987   884.954672\n",
      "3    1379.333333  1214.730146\n",
      "4    1967.749974  1484.648993\n",
      "..           ...          ...\n",
      "507  1009.999999   884.762114\n",
      "508   960.249993   934.749689\n",
      "509   871.250002   880.589724\n",
      "510   707.750000   792.786082\n",
      "511   649.500003   652.976874\n",
      "\n",
      "[512 rows x 2 columns]\n",
      "Epoch 7/25, Training Loss: 0.1374\n",
      "Epoch 7/25, Validation Loss: 0.1453\n",
      "          actual    predicted\n",
      "0     804.611111   639.320110\n",
      "1     909.750003   761.011462\n",
      "2    1168.999987   863.617726\n",
      "3    1379.333333  1125.876921\n",
      "4    1967.749974  1336.502554\n",
      "..           ...          ...\n",
      "507  1009.999999   856.420888\n",
      "508   960.249993   887.891277\n",
      "509   871.250002   844.229065\n",
      "510   707.750000   780.950184\n",
      "511   649.500003   676.289880\n",
      "\n",
      "[512 rows x 2 columns]\n",
      "Epoch 8/25, Training Loss: 0.1353\n",
      "Epoch 8/25, Validation Loss: 0.1431\n",
      "          actual    predicted\n",
      "0     804.611111   612.998516\n",
      "1     909.750003   737.938742\n",
      "2    1168.999987   843.571143\n",
      "3    1379.333333  1122.637400\n",
      "4    1967.749974  1340.972734\n",
      "..           ...          ...\n",
      "507  1009.999999   815.053612\n",
      "508   960.249993   849.108907\n",
      "509   871.250002   806.941868\n",
      "510   707.750000   744.107653\n",
      "511   649.500003   634.002386\n",
      "\n",
      "[512 rows x 2 columns]\n",
      "Epoch 9/25, Training Loss: 0.1353\n",
      "Epoch 9/25, Validation Loss: 0.1411\n",
      "          actual    predicted\n",
      "0     804.611111   656.678287\n",
      "1     909.750003   794.102520\n",
      "2    1168.999987   909.248446\n",
      "3    1379.333333  1222.945459\n",
      "4    1967.749974  1472.464794\n",
      "..           ...          ...\n",
      "507  1009.999999   901.211226\n",
      "508   960.249993   935.670577\n",
      "509   871.250002   895.440896\n",
      "510   707.750000   830.094461\n",
      "511   649.500003   702.301493\n",
      "\n",
      "[512 rows x 2 columns]\n",
      "Epoch 10/25, Training Loss: 0.1313\n",
      "Epoch 10/25, Validation Loss: 0.1340\n",
      "          actual    predicted\n",
      "0     804.611111   649.775052\n",
      "1     909.750003   785.168184\n",
      "2    1168.999987   905.637431\n",
      "3    1379.333333  1283.843776\n",
      "4    1967.749974  1583.173418\n",
      "..           ...          ...\n",
      "507  1009.999999   832.883062\n",
      "508   960.249993   873.554512\n",
      "509   871.250002   834.255664\n",
      "510   707.750000   765.266633\n",
      "511   649.500003   648.849740\n",
      "\n",
      "[512 rows x 2 columns]\n",
      "Epoch 11/25, Training Loss: 0.1306\n",
      "Epoch 11/25, Validation Loss: 0.1177\n",
      "          actual    predicted\n",
      "0     804.611111   631.151106\n",
      "1     909.750003   764.468741\n",
      "2    1168.999987   894.843692\n",
      "3    1379.333333  1212.407967\n",
      "4    1967.749974  1436.836629\n",
      "..           ...          ...\n",
      "507  1009.999999   837.983080\n",
      "508   960.249993   864.918771\n",
      "509   871.250002   825.279139\n",
      "510   707.750000   764.021164\n",
      "511   649.500003   656.455675\n",
      "\n",
      "[512 rows x 2 columns]\n",
      "Epoch 12/25, Training Loss: 0.1287\n",
      "Epoch 12/25, Validation Loss: 0.1272\n",
      "          actual    predicted\n",
      "0     804.611111   663.546544\n",
      "1     909.750003   844.775848\n",
      "2    1168.999987   974.254393\n",
      "3    1379.333333  1255.636396\n",
      "4    1967.749974  1440.969371\n",
      "..           ...          ...\n",
      "507  1009.999999   883.029292\n",
      "508   960.249993   924.298926\n",
      "509   871.250002   886.946462\n",
      "510   707.750000   820.784663\n",
      "511   649.500003   681.333425\n",
      "\n",
      "[512 rows x 2 columns]\n",
      "Epoch 13/25, Training Loss: 0.1286\n",
      "Epoch 13/25, Validation Loss: 0.1540\n",
      "          actual    predicted\n",
      "0     804.611111   655.860147\n",
      "1     909.750003   816.740943\n",
      "2    1168.999987   935.227126\n",
      "3    1379.333333  1239.866636\n",
      "4    1967.749974  1449.572750\n",
      "..           ...          ...\n",
      "507  1009.999999   887.076587\n",
      "508   960.249993   926.714049\n",
      "509   871.250002   876.100954\n",
      "510   707.750000   802.365024\n",
      "511   649.500003   664.733027\n",
      "\n",
      "[512 rows x 2 columns]\n",
      "Epoch 14/25, Training Loss: 0.1278\n",
      "Epoch 14/25, Validation Loss: 0.1371\n",
      "          actual    predicted\n",
      "0     804.611111   685.118654\n",
      "1     909.750003   830.923147\n",
      "2    1168.999987   957.457416\n",
      "3    1379.333333  1258.404396\n",
      "4    1967.749974  1474.039035\n",
      "..           ...          ...\n",
      "507  1009.999999   861.046621\n",
      "508   960.249993   897.795253\n",
      "509   871.250002   855.175526\n",
      "510   707.750000   790.978880\n",
      "511   649.500003   676.627028\n",
      "\n",
      "[512 rows x 2 columns]\n",
      "Epoch 15/25, Training Loss: 0.1267\n",
      "Epoch 15/25, Validation Loss: 0.1166\n",
      "          actual    predicted\n",
      "0     804.611111   664.548561\n",
      "1     909.750003   854.167014\n",
      "2    1168.999987  1003.424073\n",
      "3    1379.333333  1317.185679\n",
      "4    1967.749974  1504.672237\n",
      "..           ...          ...\n",
      "507  1009.999999   851.364949\n",
      "508   960.249993   893.644816\n",
      "509   871.250002   850.645300\n",
      "510   707.750000   776.113487\n",
      "511   649.500003   639.998584\n",
      "\n",
      "[512 rows x 2 columns]\n",
      "Epoch 16/25, Training Loss: 0.1259\n",
      "Epoch 16/25, Validation Loss: 0.1349\n",
      "          actual    predicted\n",
      "0     804.611111   687.846716\n",
      "1     909.750003   845.099979\n",
      "2    1168.999987   985.288159\n",
      "3    1379.333333  1290.045207\n",
      "4    1967.749974  1497.600125\n",
      "..           ...          ...\n",
      "507  1009.999999   865.585124\n",
      "508   960.249993   902.007176\n",
      "509   871.250002   861.597625\n",
      "510   707.750000   796.905238\n",
      "511   649.500003   673.087979\n",
      "\n",
      "[512 rows x 2 columns]\n",
      "Epoch 17/25, Training Loss: 0.1262\n",
      "Epoch 17/25, Validation Loss: 0.1198\n",
      "          actual    predicted\n",
      "0     804.611111   652.454681\n",
      "1     909.750003   800.834850\n",
      "2    1168.999987   950.792118\n",
      "3    1379.333333  1308.366727\n",
      "4    1967.749974  1546.830985\n",
      "..           ...          ...\n",
      "507  1009.999999   828.722387\n",
      "508   960.249993   882.132358\n",
      "509   871.250002   835.351687\n",
      "510   707.750000   767.567402\n",
      "511   649.500003   656.299604\n",
      "\n",
      "[512 rows x 2 columns]\n",
      "Epoch 18/25, Training Loss: 0.1237\n",
      "Epoch 18/25, Validation Loss: 0.0920\n",
      "          actual    predicted\n",
      "0     804.611111   696.671487\n",
      "1     909.750003   860.128612\n",
      "2    1168.999987   988.023999\n",
      "3    1379.333333  1280.784753\n",
      "4    1967.749974  1483.417983\n",
      "..           ...          ...\n",
      "507  1009.999999   865.977543\n",
      "508   960.249993   900.000974\n",
      "509   871.250002   865.998310\n",
      "510   707.750000   813.226589\n",
      "511   649.500003   691.332847\n",
      "\n",
      "[512 rows x 2 columns]\n",
      "Epoch 19/25, Training Loss: 0.1222\n",
      "Epoch 19/25, Validation Loss: 0.1163\n",
      "          actual    predicted\n",
      "0     804.611111   667.917575\n",
      "1     909.750003   868.286214\n",
      "2    1168.999987  1039.242812\n",
      "3    1379.333333  1366.229018\n",
      "4    1967.749974  1569.272854\n",
      "..           ...          ...\n",
      "507  1009.999999   882.429639\n",
      "508   960.249993   917.482174\n",
      "509   871.250002   871.435793\n",
      "510   707.750000   804.207798\n",
      "511   649.500003   662.563776\n",
      "\n",
      "[512 rows x 2 columns]\n",
      "Epoch 20/25, Training Loss: 0.1237\n",
      "Epoch 20/25, Validation Loss: 0.1131\n",
      "          actual    predicted\n",
      "0     804.611111   657.234623\n",
      "1     909.750003   819.090769\n",
      "2    1168.999987   970.312243\n",
      "3    1379.333333  1301.315470\n",
      "4    1967.749974  1512.308559\n",
      "..           ...          ...\n",
      "507  1009.999999   817.163853\n",
      "508   960.249993   845.012034\n",
      "509   871.250002   808.216098\n",
      "510   707.750000   751.658440\n",
      "511   649.500003   646.510699\n",
      "\n",
      "[512 rows x 2 columns]\n",
      "Epoch 21/25, Training Loss: 0.1231\n",
      "Epoch 21/25, Validation Loss: 0.1073\n",
      "          actual    predicted\n",
      "0     804.611111   649.710055\n",
      "1     909.750003   810.687784\n",
      "2    1168.999987   960.774793\n",
      "3    1379.333333  1251.722456\n",
      "4    1967.749974  1460.155464\n",
      "..           ...          ...\n",
      "507  1009.999999   812.855315\n",
      "508   960.249993   845.943016\n",
      "509   871.250002   804.726815\n",
      "510   707.750000   742.661606\n",
      "511   649.500003   634.167173\n",
      "\n",
      "[512 rows x 2 columns]\n",
      "Epoch 22/25, Training Loss: 0.1205\n",
      "Epoch 22/25, Validation Loss: 0.1238\n",
      "          actual    predicted\n",
      "0     804.611111   676.553202\n",
      "1     909.750003   878.807038\n",
      "2    1168.999987  1032.538086\n",
      "3    1379.333333  1330.409857\n",
      "4    1967.749974  1503.727861\n",
      "..           ...          ...\n",
      "507  1009.999999   853.410979\n",
      "508   960.249993   888.482776\n",
      "509   871.250002   853.742272\n",
      "510   707.750000   797.214811\n",
      "511   649.500003   669.331892\n",
      "\n",
      "[512 rows x 2 columns]\n",
      "Early stopping!\n",
      "            actual    predicted\n",
      "0       804.611111   676.553202\n",
      "1       909.750003   878.807038\n",
      "2      1168.999987  1032.538086\n",
      "3      1379.333333  1330.409857\n",
      "4      1967.749974  1503.727861\n",
      "...            ...          ...\n",
      "19210   954.749998  1015.883707\n",
      "19211   951.749994  1027.800108\n",
      "19212   956.749995  1026.563340\n",
      "19213   953.750008  1036.824608\n",
      "19214   947.500003  1026.301019\n",
      "\n",
      "[19215 rows x 2 columns]\n",
      "Score (RMSE): 96.0864\n",
      "Score (MAE): 54.0275\n",
      "Score (MAPE): 6.9902%\n",
      "training data cutoff:  2023-07-14 07:30:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Studium\\Semester_6\\IoT_Project\\utils.py:911: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_train[columns_to_scale] = scaler.fit_transform(df_train[columns_to_scale])\n",
      "c:\\Studium\\Semester_6\\IoT_Project\\utils.py:912: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_test[columns_to_scale] = scaler.transform(df_test[columns_to_scale])\n",
      "c:\\Studium\\Semester_6\\IoT_Project\\utils.py:916: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_train.drop(['date_time_rounded'], axis=1, inplace=True)\n",
      "c:\\Studium\\Semester_6\\IoT_Project\\utils.py:917: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_test.drop(['date_time_rounded'], axis=1, inplace=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tmp                         float64\n",
      "hum                         float64\n",
      "CO2                         float64\n",
      "VOC                         float64\n",
      "vis                         float64\n",
      "IR                          float64\n",
      "WIFI                        float64\n",
      "BLE                         float64\n",
      "rssi                        float64\n",
      "channel_rssi                float64\n",
      "channel_index               float64\n",
      "spreading_factor            float64\n",
      "bandwidth                   float64\n",
      "f_cnt                       float64\n",
      "isHoliday                   float64\n",
      "isExamTime                  float64\n",
      "weekday                     float64\n",
      "month                       float64\n",
      "hour_sin                    float64\n",
      "semester_SS23               float64\n",
      "semester_WS22/23            float64\n",
      "semester_WS23/24            float64\n",
      "group                       float64\n",
      "device_id_hka-aqm-am001     float64\n",
      "device_id_hka-aqm-am002     float64\n",
      "device_id_hka-aqm-am003a    float64\n",
      "device_id_hka-aqm-am003b    float64\n",
      "device_id_hka-aqm-am004     float64\n",
      "device_id_hka-aqm-am005     float64\n",
      "device_id_hka-aqm-am107     float64\n",
      "device_id_hka-aqm-am109     float64\n",
      "device_id_hka-aqm-am110     float64\n",
      "device_id_hka-aqm-am111     float64\n",
      "device_id_hka-aqm-am115     float64\n",
      "device_id_hka-aqm-am116     float64\n",
      "device_id_hka-aqm-am117     float64\n",
      "device_id_hka-aqm-am123     float64\n",
      "device_id_hka-aqm-am124     float64\n",
      "device_id_hka-aqm-am126     float64\n",
      "device_id_hka-aqm-am201a    float64\n",
      "device_id_hka-aqm-am201b    float64\n",
      "device_id_hka-aqm-am204     float64\n",
      "device_id_hka-aqm-am205     float64\n",
      "device_id_hka-aqm-am209     float64\n",
      "device_id_hka-aqm-am210     float64\n",
      "device_id_hka-aqm-am211     float64\n",
      "device_id_hka-aqm-am301     float64\n",
      "device_id_hka-aqm-am307     float64\n",
      "device_id_hka-aqm-am308     float64\n",
      "dtype: object\n",
      "feature count:  49\n",
      "feature count:  49\n",
      "Training data shape: torch.Size([152512, 20, 49]) torch.Size([152512, 1])\n",
      "Testing data shape: torch.Size([38893, 20, 49]) torch.Size([38893, 1])\n",
      "same columns\n",
      "date_time_rounded           datetime64[ns]\n",
      "tmp                                float64\n",
      "hum                                float64\n",
      "CO2                                float64\n",
      "VOC                                float64\n",
      "vis                                float64\n",
      "IR                                 float64\n",
      "WIFI                               float64\n",
      "BLE                                float64\n",
      "rssi                               float64\n",
      "channel_rssi                       float64\n",
      "channel_index                      float64\n",
      "spreading_factor                   float64\n",
      "bandwidth                          float64\n",
      "f_cnt                              float64\n",
      "isHoliday                          float64\n",
      "isExamTime                         float64\n",
      "weekday                            float64\n",
      "month                              float64\n",
      "hour_sin                           float64\n",
      "semester_SS23                      float64\n",
      "semester_WS22/23                   float64\n",
      "semester_WS23/24                   float64\n",
      "group                                int32\n",
      "device_id_hka-aqm-am001              uint8\n",
      "device_id_hka-aqm-am002              uint8\n",
      "device_id_hka-aqm-am003a             uint8\n",
      "device_id_hka-aqm-am003b             uint8\n",
      "device_id_hka-aqm-am004              uint8\n",
      "device_id_hka-aqm-am005              uint8\n",
      "device_id_hka-aqm-am107              uint8\n",
      "device_id_hka-aqm-am109              uint8\n",
      "device_id_hka-aqm-am110              uint8\n",
      "device_id_hka-aqm-am111              uint8\n",
      "device_id_hka-aqm-am115              uint8\n",
      "device_id_hka-aqm-am116              uint8\n",
      "device_id_hka-aqm-am117              uint8\n",
      "device_id_hka-aqm-am123              uint8\n",
      "device_id_hka-aqm-am124              uint8\n",
      "device_id_hka-aqm-am126              uint8\n",
      "device_id_hka-aqm-am201a             uint8\n",
      "device_id_hka-aqm-am201b             uint8\n",
      "device_id_hka-aqm-am204              uint8\n",
      "device_id_hka-aqm-am205              uint8\n",
      "device_id_hka-aqm-am209              uint8\n",
      "device_id_hka-aqm-am210              uint8\n",
      "device_id_hka-aqm-am211              uint8\n",
      "device_id_hka-aqm-am301              uint8\n",
      "device_id_hka-aqm-am307              uint8\n",
      "device_id_hka-aqm-am308              uint8\n",
      "dtype: object\n",
      "date_time_rounded           datetime64[ns]\n",
      "tmp                                float64\n",
      "hum                                float64\n",
      "CO2                                float64\n",
      "VOC                                float64\n",
      "vis                                float64\n",
      "IR                                 float64\n",
      "WIFI                               float64\n",
      "BLE                                float64\n",
      "rssi                               float64\n",
      "channel_rssi                       float64\n",
      "channel_index                      float64\n",
      "spreading_factor                   float64\n",
      "bandwidth                          float64\n",
      "f_cnt                              float64\n",
      "isHoliday                          float64\n",
      "isExamTime                         float64\n",
      "weekday                            float64\n",
      "month                              float64\n",
      "hour_sin                           float64\n",
      "semester_SS23                      float64\n",
      "semester_WS22/23                   float64\n",
      "semester_WS23/24                   float64\n",
      "group                                int32\n",
      "device_id_hka-aqm-am001              uint8\n",
      "device_id_hka-aqm-am002              uint8\n",
      "device_id_hka-aqm-am003a             uint8\n",
      "device_id_hka-aqm-am003b             uint8\n",
      "device_id_hka-aqm-am004              uint8\n",
      "device_id_hka-aqm-am005              uint8\n",
      "device_id_hka-aqm-am107              uint8\n",
      "device_id_hka-aqm-am109              uint8\n",
      "device_id_hka-aqm-am110              uint8\n",
      "device_id_hka-aqm-am111              uint8\n",
      "device_id_hka-aqm-am115              uint8\n",
      "device_id_hka-aqm-am116              uint8\n",
      "device_id_hka-aqm-am117              uint8\n",
      "device_id_hka-aqm-am123              uint8\n",
      "device_id_hka-aqm-am124              uint8\n",
      "device_id_hka-aqm-am126              uint8\n",
      "device_id_hka-aqm-am201a             uint8\n",
      "device_id_hka-aqm-am201b             uint8\n",
      "device_id_hka-aqm-am204              uint8\n",
      "device_id_hka-aqm-am205              uint8\n",
      "device_id_hka-aqm-am209              uint8\n",
      "device_id_hka-aqm-am210              uint8\n",
      "device_id_hka-aqm-am211              uint8\n",
      "device_id_hka-aqm-am301              uint8\n",
      "device_id_hka-aqm-am307              uint8\n",
      "device_id_hka-aqm-am308              uint8\n",
      "dtype: object\n",
      "         date_time_rounded        tmp        hum         CO2         VOC  \\\n",
      "199592 2022-10-10 14:30:00  23.435455  51.505000  917.954545  459.636364   \n",
      "199593 2022-10-10 16:30:00  25.360000  44.336667  563.666667  555.000000   \n",
      "199594 2022-10-10 17:00:00  25.486667  45.230000  612.333333  607.333333   \n",
      "199595 2022-10-10 18:30:00  25.510000  48.355000  596.000000  657.000000   \n",
      "199596 2022-10-10 19:30:00  25.240000  49.470000  603.000000  599.000000   \n",
      "...                    ...        ...        ...         ...         ...   \n",
      "308834 2023-09-26 19:00:00  27.620000  36.770000  513.000000  919.000000   \n",
      "308835 2023-09-26 22:00:00  27.435000  37.415000  522.500000  957.500000   \n",
      "308836 2023-09-26 22:30:00  27.380000  37.510000  527.500000  958.500000   \n",
      "308837 2023-09-26 23:00:00  27.370000  37.580000  524.500000  949.000000   \n",
      "308838 2023-09-26 23:30:00  27.345000  37.630000  527.000000  955.000000   \n",
      "\n",
      "               vis         IR      WIFI        BLE       rssi  ...  \\\n",
      "199592  249.136364  30.272727  0.954545   1.272727 -72.136364  ...   \n",
      "199593  115.000000  12.666667  1.000000   2.000000 -59.000000  ...   \n",
      "199594  151.333333  16.000000  0.333333   0.000000 -56.333333  ...   \n",
      "199595  153.500000  16.000000  1.000000   0.000000 -61.000000  ...   \n",
      "199596    9.000000   1.000000  0.000000   0.000000 -62.500000  ...   \n",
      "...            ...        ...       ...        ...        ...  ...   \n",
      "308834    5.000000   0.000000  3.500000  13.500000 -74.000000  ...   \n",
      "308835    4.000000   1.000000  3.500000  13.500000 -74.000000  ...   \n",
      "308836    5.500000   2.000000  1.000000   0.000000 -73.000000  ...   \n",
      "308837    5.500000   2.500000  1.500000   0.000000 -72.500000  ...   \n",
      "308838    4.000000   0.000000  3.000000  13.500000 -75.000000  ...   \n",
      "\n",
      "        device_id_hka-aqm-am201a  device_id_hka-aqm-am201b  \\\n",
      "199592                         0                         0   \n",
      "199593                         0                         0   \n",
      "199594                         0                         0   \n",
      "199595                         0                         0   \n",
      "199596                         0                         0   \n",
      "...                          ...                       ...   \n",
      "308834                         0                         0   \n",
      "308835                         0                         0   \n",
      "308836                         0                         0   \n",
      "308837                         0                         0   \n",
      "308838                         0                         0   \n",
      "\n",
      "        device_id_hka-aqm-am204  device_id_hka-aqm-am205  \\\n",
      "199592                        0                        0   \n",
      "199593                        0                        0   \n",
      "199594                        0                        0   \n",
      "199595                        0                        0   \n",
      "199596                        0                        0   \n",
      "...                         ...                      ...   \n",
      "308834                        0                        0   \n",
      "308835                        0                        0   \n",
      "308836                        0                        0   \n",
      "308837                        0                        0   \n",
      "308838                        0                        0   \n",
      "\n",
      "        device_id_hka-aqm-am209  device_id_hka-aqm-am210  \\\n",
      "199592                        0                        0   \n",
      "199593                        0                        0   \n",
      "199594                        0                        0   \n",
      "199595                        0                        0   \n",
      "199596                        0                        0   \n",
      "...                         ...                      ...   \n",
      "308834                        0                        0   \n",
      "308835                        0                        0   \n",
      "308836                        0                        0   \n",
      "308837                        0                        0   \n",
      "308838                        0                        0   \n",
      "\n",
      "        device_id_hka-aqm-am211  device_id_hka-aqm-am301  \\\n",
      "199592                        0                        0   \n",
      "199593                        0                        0   \n",
      "199594                        0                        0   \n",
      "199595                        0                        0   \n",
      "199596                        0                        0   \n",
      "...                         ...                      ...   \n",
      "308834                        0                        0   \n",
      "308835                        0                        0   \n",
      "308836                        0                        0   \n",
      "308837                        0                        0   \n",
      "308838                        0                        0   \n",
      "\n",
      "        device_id_hka-aqm-am307  device_id_hka-aqm-am308  \n",
      "199592                        0                        0  \n",
      "199593                        0                        0  \n",
      "199594                        0                        0  \n",
      "199595                        0                        0  \n",
      "199596                        0                        0  \n",
      "...                         ...                      ...  \n",
      "308834                        0                        1  \n",
      "308835                        0                        1  \n",
      "308836                        0                        1  \n",
      "308837                        0                        1  \n",
      "308838                        0                        1  \n",
      "\n",
      "[109247 rows x 50 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\t-ehm\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\transformer.py:286: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
      "c:\\Users\\t-ehm\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\optim\\lr_scheduler.py:28: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\"The verbose parameter is deprecated. Please use get_last_lr() \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         actual   predicted\n",
      "0    468.499999  469.854551\n",
      "1    479.500000  470.181315\n",
      "2    454.000001  480.026152\n",
      "3    452.000001  460.981380\n",
      "4    466.499999  458.665080\n",
      "..          ...         ...\n",
      "507  435.500001  462.903282\n",
      "508  437.500001  460.041315\n",
      "509  441.000001  462.760123\n",
      "510  440.500001  462.068615\n",
      "511  439.000001  462.571166\n",
      "\n",
      "[512 rows x 2 columns]\n",
      "Epoch 1/25, Training Loss: 0.3842\n",
      "Epoch 1/25, Validation Loss: 0.0626\n",
      "         actual   predicted\n",
      "0    468.499999  459.084411\n",
      "1    479.500000  468.182577\n",
      "2    454.000001  482.506188\n",
      "3    452.000001  455.639416\n",
      "4    466.499999  459.921674\n",
      "..          ...         ...\n",
      "507  435.500001  448.083796\n",
      "508  437.500001  447.200503\n",
      "509  441.000001  447.930822\n",
      "510  440.500001  447.816836\n",
      "511  439.000001  447.036334\n",
      "\n",
      "[512 rows x 2 columns]\n",
      "Epoch 2/25, Training Loss: 0.2623\n",
      "Epoch 2/25, Validation Loss: 0.0505\n",
      "         actual   predicted\n",
      "0    468.499999  492.886371\n",
      "1    479.500000  503.422807\n",
      "2    454.000001  515.083086\n",
      "3    452.000001  488.041660\n",
      "4    466.499999  486.865903\n",
      "..          ...         ...\n",
      "507  435.500001  485.941759\n",
      "508  437.500001  485.546598\n",
      "509  441.000001  485.901219\n",
      "510  440.500001  483.902586\n",
      "511  439.000001  481.360514\n",
      "\n",
      "[512 rows x 2 columns]\n",
      "Epoch 3/25, Training Loss: 0.2486\n",
      "Epoch 3/25, Validation Loss: 0.1142\n",
      "         actual   predicted\n",
      "0    468.499999  476.934205\n",
      "1    479.500000  493.406893\n",
      "2    454.000001  514.889528\n",
      "3    452.000001  474.138016\n",
      "4    466.499999  475.500559\n",
      "..          ...         ...\n",
      "507  435.500001  465.168896\n",
      "508  437.500001  466.237611\n",
      "509  441.000001  467.975757\n",
      "510  440.500001  466.872521\n",
      "511  439.000001  465.462621\n",
      "\n",
      "[512 rows x 2 columns]\n",
      "Epoch 4/25, Training Loss: 0.2403\n",
      "Epoch 4/25, Validation Loss: 0.0662\n",
      "         actual   predicted\n",
      "0    468.499999  491.107810\n",
      "1    479.500000  509.023705\n",
      "2    454.000001  517.535187\n",
      "3    452.000001  487.296936\n",
      "4    466.499999  478.170594\n",
      "..          ...         ...\n",
      "507  435.500001  460.232951\n",
      "508  437.500001  456.077412\n",
      "509  441.000001  460.529858\n",
      "510  440.500001  465.074346\n",
      "511  439.000001  463.362448\n",
      "\n",
      "[512 rows x 2 columns]\n",
      "Epoch 5/25, Training Loss: 0.2312\n",
      "Epoch 5/25, Validation Loss: 0.0591\n",
      "         actual   predicted\n",
      "0    468.499999  500.321615\n",
      "1    479.500000  510.239640\n",
      "2    454.000001  518.562780\n",
      "3    452.000001  488.272845\n",
      "4    466.499999  486.387366\n",
      "..          ...         ...\n",
      "507  435.500001  461.962297\n",
      "508  437.500001  461.229322\n",
      "509  441.000001  462.502010\n",
      "510  440.500001  463.414309\n",
      "511  439.000001  460.386436\n",
      "\n",
      "[512 rows x 2 columns]\n",
      "Epoch 6/25, Training Loss: 0.2271\n",
      "Epoch 6/25, Validation Loss: 0.0697\n",
      "         actual   predicted\n",
      "0    468.499999  479.050560\n",
      "1    479.500000  494.848352\n",
      "2    454.000001  506.409422\n",
      "3    452.000001  473.466745\n",
      "4    466.499999  471.109582\n",
      "..          ...         ...\n",
      "507  435.500001  456.224941\n",
      "508  437.500001  452.366765\n",
      "509  441.000001  455.608499\n",
      "510  440.500001  459.819279\n",
      "511  439.000001  459.593605\n",
      "\n",
      "[512 rows x 2 columns]\n",
      "Early stopping!\n",
      "           actual   predicted\n",
      "0      468.499999  479.050560\n",
      "1      479.500000  494.848352\n",
      "2      454.000001  506.409422\n",
      "3      452.000001  473.466745\n",
      "4      466.499999  471.109582\n",
      "...           ...         ...\n",
      "38888  522.500000  552.098817\n",
      "38889  527.500002  559.362158\n",
      "38890  524.500000  558.787887\n",
      "38891  527.000002  555.939218\n",
      "38892  525.000000  565.164116\n",
      "\n",
      "[38893 rows x 2 columns]\n",
      "Score (RMSE): 31.9813\n",
      "Score (MAE): 22.4110\n",
      "Score (MAPE): 4.8942%\n",
      "training data cutoff:  2023-07-14 07:30:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Studium\\Semester_6\\IoT_Project\\utils.py:911: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_train[columns_to_scale] = scaler.fit_transform(df_train[columns_to_scale])\n",
      "c:\\Studium\\Semester_6\\IoT_Project\\utils.py:912: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_test[columns_to_scale] = scaler.transform(df_test[columns_to_scale])\n",
      "c:\\Studium\\Semester_6\\IoT_Project\\utils.py:916: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_train.drop(['date_time_rounded'], axis=1, inplace=True)\n",
      "c:\\Studium\\Semester_6\\IoT_Project\\utils.py:917: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_test.drop(['date_time_rounded'], axis=1, inplace=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tmp                         float64\n",
      "hum                         float64\n",
      "CO2                         float64\n",
      "VOC                         float64\n",
      "vis                         float64\n",
      "IR                          float64\n",
      "WIFI                        float64\n",
      "BLE                         float64\n",
      "rssi                        float64\n",
      "channel_rssi                float64\n",
      "channel_index               float64\n",
      "spreading_factor            float64\n",
      "bandwidth                   float64\n",
      "f_cnt                       float64\n",
      "isHoliday                   float64\n",
      "isExamTime                  float64\n",
      "weekday                     float64\n",
      "month                       float64\n",
      "hour_sin                    float64\n",
      "semester_SS23               float64\n",
      "semester_WS22/23            float64\n",
      "semester_WS23/24            float64\n",
      "group                       float64\n",
      "device_id_hka-aqm-am001     float64\n",
      "device_id_hka-aqm-am002     float64\n",
      "device_id_hka-aqm-am003a    float64\n",
      "device_id_hka-aqm-am003b    float64\n",
      "device_id_hka-aqm-am004     float64\n",
      "device_id_hka-aqm-am005     float64\n",
      "device_id_hka-aqm-am107     float64\n",
      "device_id_hka-aqm-am109     float64\n",
      "device_id_hka-aqm-am110     float64\n",
      "device_id_hka-aqm-am111     float64\n",
      "device_id_hka-aqm-am115     float64\n",
      "device_id_hka-aqm-am116     float64\n",
      "device_id_hka-aqm-am117     float64\n",
      "device_id_hka-aqm-am123     float64\n",
      "device_id_hka-aqm-am124     float64\n",
      "device_id_hka-aqm-am126     float64\n",
      "device_id_hka-aqm-am201a    float64\n",
      "device_id_hka-aqm-am201b    float64\n",
      "device_id_hka-aqm-am204     float64\n",
      "device_id_hka-aqm-am205     float64\n",
      "device_id_hka-aqm-am209     float64\n",
      "device_id_hka-aqm-am210     float64\n",
      "device_id_hka-aqm-am211     float64\n",
      "device_id_hka-aqm-am301     float64\n",
      "device_id_hka-aqm-am307     float64\n",
      "device_id_hka-aqm-am308     float64\n",
      "dtype: object\n",
      "feature count:  49\n",
      "feature count:  49\n",
      "Training data shape: torch.Size([152512, 20, 49]) torch.Size([152512, 1])\n",
      "Testing data shape: torch.Size([38893, 20, 49]) torch.Size([38893, 1])\n",
      "same columns\n",
      "date_time_rounded           datetime64[ns]\n",
      "tmp                                float64\n",
      "hum                                float64\n",
      "CO2                                float64\n",
      "VOC                                float64\n",
      "vis                                float64\n",
      "IR                                 float64\n",
      "WIFI                               float64\n",
      "BLE                                float64\n",
      "rssi                               float64\n",
      "channel_rssi                       float64\n",
      "channel_index                      float64\n",
      "spreading_factor                   float64\n",
      "bandwidth                          float64\n",
      "f_cnt                              float64\n",
      "isHoliday                          float64\n",
      "isExamTime                         float64\n",
      "weekday                            float64\n",
      "month                              float64\n",
      "hour_sin                           float64\n",
      "semester_SS23                      float64\n",
      "semester_WS22/23                   float64\n",
      "semester_WS23/24                   float64\n",
      "group                                int32\n",
      "device_id_hka-aqm-am001              uint8\n",
      "device_id_hka-aqm-am002              uint8\n",
      "device_id_hka-aqm-am003a             uint8\n",
      "device_id_hka-aqm-am003b             uint8\n",
      "device_id_hka-aqm-am004              uint8\n",
      "device_id_hka-aqm-am005              uint8\n",
      "device_id_hka-aqm-am107              uint8\n",
      "device_id_hka-aqm-am109              uint8\n",
      "device_id_hka-aqm-am110              uint8\n",
      "device_id_hka-aqm-am111              uint8\n",
      "device_id_hka-aqm-am115              uint8\n",
      "device_id_hka-aqm-am116              uint8\n",
      "device_id_hka-aqm-am117              uint8\n",
      "device_id_hka-aqm-am123              uint8\n",
      "device_id_hka-aqm-am124              uint8\n",
      "device_id_hka-aqm-am126              uint8\n",
      "device_id_hka-aqm-am201a             uint8\n",
      "device_id_hka-aqm-am201b             uint8\n",
      "device_id_hka-aqm-am204              uint8\n",
      "device_id_hka-aqm-am205              uint8\n",
      "device_id_hka-aqm-am209              uint8\n",
      "device_id_hka-aqm-am210              uint8\n",
      "device_id_hka-aqm-am211              uint8\n",
      "device_id_hka-aqm-am301              uint8\n",
      "device_id_hka-aqm-am307              uint8\n",
      "device_id_hka-aqm-am308              uint8\n",
      "dtype: object\n",
      "date_time_rounded           datetime64[ns]\n",
      "tmp                                float64\n",
      "hum                                float64\n",
      "CO2                                float64\n",
      "VOC                                float64\n",
      "vis                                float64\n",
      "IR                                 float64\n",
      "WIFI                               float64\n",
      "BLE                                float64\n",
      "rssi                               float64\n",
      "channel_rssi                       float64\n",
      "channel_index                      float64\n",
      "spreading_factor                   float64\n",
      "bandwidth                          float64\n",
      "f_cnt                              float64\n",
      "isHoliday                          float64\n",
      "isExamTime                         float64\n",
      "weekday                            float64\n",
      "month                              float64\n",
      "hour_sin                           float64\n",
      "semester_SS23                      float64\n",
      "semester_WS22/23                   float64\n",
      "semester_WS23/24                   float64\n",
      "group                                int32\n",
      "device_id_hka-aqm-am001              uint8\n",
      "device_id_hka-aqm-am002              uint8\n",
      "device_id_hka-aqm-am003a             uint8\n",
      "device_id_hka-aqm-am003b             uint8\n",
      "device_id_hka-aqm-am004              uint8\n",
      "device_id_hka-aqm-am005              uint8\n",
      "device_id_hka-aqm-am107              uint8\n",
      "device_id_hka-aqm-am109              uint8\n",
      "device_id_hka-aqm-am110              uint8\n",
      "device_id_hka-aqm-am111              uint8\n",
      "device_id_hka-aqm-am115              uint8\n",
      "device_id_hka-aqm-am116              uint8\n",
      "device_id_hka-aqm-am117              uint8\n",
      "device_id_hka-aqm-am123              uint8\n",
      "device_id_hka-aqm-am124              uint8\n",
      "device_id_hka-aqm-am126              uint8\n",
      "device_id_hka-aqm-am201a             uint8\n",
      "device_id_hka-aqm-am201b             uint8\n",
      "device_id_hka-aqm-am204              uint8\n",
      "device_id_hka-aqm-am205              uint8\n",
      "device_id_hka-aqm-am209              uint8\n",
      "device_id_hka-aqm-am210              uint8\n",
      "device_id_hka-aqm-am211              uint8\n",
      "device_id_hka-aqm-am301              uint8\n",
      "device_id_hka-aqm-am307              uint8\n",
      "device_id_hka-aqm-am308              uint8\n",
      "dtype: object\n",
      "         date_time_rounded        tmp        hum         CO2         VOC  \\\n",
      "199592 2022-10-10 14:30:00  23.435455  51.505000  917.954545  459.636364   \n",
      "199593 2022-10-10 16:30:00  25.360000  44.336667  563.666667  555.000000   \n",
      "199594 2022-10-10 17:00:00  25.486667  45.230000  612.333333  607.333333   \n",
      "199595 2022-10-10 18:30:00  25.510000  48.355000  596.000000  657.000000   \n",
      "199596 2022-10-10 19:30:00  25.240000  49.470000  603.000000  599.000000   \n",
      "...                    ...        ...        ...         ...         ...   \n",
      "308834 2023-09-26 19:00:00  27.620000  36.770000  513.000000  919.000000   \n",
      "308835 2023-09-26 22:00:00  27.435000  37.415000  522.500000  957.500000   \n",
      "308836 2023-09-26 22:30:00  27.380000  37.510000  527.500000  958.500000   \n",
      "308837 2023-09-26 23:00:00  27.370000  37.580000  524.500000  949.000000   \n",
      "308838 2023-09-26 23:30:00  27.345000  37.630000  527.000000  955.000000   \n",
      "\n",
      "               vis         IR      WIFI        BLE       rssi  ...  \\\n",
      "199592  249.136364  30.272727  0.954545   1.272727 -72.136364  ...   \n",
      "199593  115.000000  12.666667  1.000000   2.000000 -59.000000  ...   \n",
      "199594  151.333333  16.000000  0.333333   0.000000 -56.333333  ...   \n",
      "199595  153.500000  16.000000  1.000000   0.000000 -61.000000  ...   \n",
      "199596    9.000000   1.000000  0.000000   0.000000 -62.500000  ...   \n",
      "...            ...        ...       ...        ...        ...  ...   \n",
      "308834    5.000000   0.000000  3.500000  13.500000 -74.000000  ...   \n",
      "308835    4.000000   1.000000  3.500000  13.500000 -74.000000  ...   \n",
      "308836    5.500000   2.000000  1.000000   0.000000 -73.000000  ...   \n",
      "308837    5.500000   2.500000  1.500000   0.000000 -72.500000  ...   \n",
      "308838    4.000000   0.000000  3.000000  13.500000 -75.000000  ...   \n",
      "\n",
      "        device_id_hka-aqm-am201a  device_id_hka-aqm-am201b  \\\n",
      "199592                         0                         0   \n",
      "199593                         0                         0   \n",
      "199594                         0                         0   \n",
      "199595                         0                         0   \n",
      "199596                         0                         0   \n",
      "...                          ...                       ...   \n",
      "308834                         0                         0   \n",
      "308835                         0                         0   \n",
      "308836                         0                         0   \n",
      "308837                         0                         0   \n",
      "308838                         0                         0   \n",
      "\n",
      "        device_id_hka-aqm-am204  device_id_hka-aqm-am205  \\\n",
      "199592                        0                        0   \n",
      "199593                        0                        0   \n",
      "199594                        0                        0   \n",
      "199595                        0                        0   \n",
      "199596                        0                        0   \n",
      "...                         ...                      ...   \n",
      "308834                        0                        0   \n",
      "308835                        0                        0   \n",
      "308836                        0                        0   \n",
      "308837                        0                        0   \n",
      "308838                        0                        0   \n",
      "\n",
      "        device_id_hka-aqm-am209  device_id_hka-aqm-am210  \\\n",
      "199592                        0                        0   \n",
      "199593                        0                        0   \n",
      "199594                        0                        0   \n",
      "199595                        0                        0   \n",
      "199596                        0                        0   \n",
      "...                         ...                      ...   \n",
      "308834                        0                        0   \n",
      "308835                        0                        0   \n",
      "308836                        0                        0   \n",
      "308837                        0                        0   \n",
      "308838                        0                        0   \n",
      "\n",
      "        device_id_hka-aqm-am211  device_id_hka-aqm-am301  \\\n",
      "199592                        0                        0   \n",
      "199593                        0                        0   \n",
      "199594                        0                        0   \n",
      "199595                        0                        0   \n",
      "199596                        0                        0   \n",
      "...                         ...                      ...   \n",
      "308834                        0                        0   \n",
      "308835                        0                        0   \n",
      "308836                        0                        0   \n",
      "308837                        0                        0   \n",
      "308838                        0                        0   \n",
      "\n",
      "        device_id_hka-aqm-am307  device_id_hka-aqm-am308  \n",
      "199592                        0                        0  \n",
      "199593                        0                        0  \n",
      "199594                        0                        0  \n",
      "199595                        0                        0  \n",
      "199596                        0                        0  \n",
      "...                         ...                      ...  \n",
      "308834                        0                        1  \n",
      "308835                        0                        1  \n",
      "308836                        0                        1  \n",
      "308837                        0                        1  \n",
      "308838                        0                        1  \n",
      "\n",
      "[109247 rows x 50 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\t-ehm\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\transformer.py:286: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
      "c:\\Users\\t-ehm\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\optim\\lr_scheduler.py:28: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\"The verbose parameter is deprecated. Please use get_last_lr() \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     actual  predicted\n",
      "0    43.935  37.042848\n",
      "1    44.490  39.005450\n",
      "2    43.010  39.941952\n",
      "3    42.895  38.370813\n",
      "4    45.020  38.245013\n",
      "..      ...        ...\n",
      "507  50.855  46.035520\n",
      "508  50.890  44.328452\n",
      "509  50.805  44.677313\n",
      "510  51.095  44.734043\n",
      "511  51.290  44.597208\n",
      "\n",
      "[512 rows x 2 columns]\n",
      "Epoch 1/25, Training Loss: 0.1775\n",
      "Epoch 1/25, Validation Loss: 0.6409\n",
      "     actual  predicted\n",
      "0    43.935  35.786735\n",
      "1    44.490  37.443915\n",
      "2    43.010  38.025155\n",
      "3    42.895  36.163637\n",
      "4    45.020  36.069849\n",
      "..      ...        ...\n",
      "507  50.855  45.921313\n",
      "508  50.890  44.971820\n",
      "509  50.805  45.158592\n",
      "510  51.095  45.268008\n",
      "511  51.290  45.395625\n",
      "\n",
      "[512 rows x 2 columns]\n",
      "Epoch 2/25, Training Loss: 0.0415\n",
      "Epoch 2/25, Validation Loss: 0.5599\n",
      "     actual  predicted\n",
      "0    43.935  39.045968\n",
      "1    44.490  40.676958\n",
      "2    43.010  41.089041\n",
      "3    42.895  39.347129\n",
      "4    45.020  39.239970\n",
      "..      ...        ...\n",
      "507  50.855  49.019702\n",
      "508  50.890  47.648519\n",
      "509  50.805  47.820340\n",
      "510  51.095  47.994392\n",
      "511  51.290  47.995634\n",
      "\n",
      "[512 rows x 2 columns]\n",
      "Epoch 3/25, Training Loss: 0.0282\n",
      "Epoch 3/25, Validation Loss: 0.2389\n",
      "     actual  predicted\n",
      "0    43.935  40.323293\n",
      "1    44.490  42.185933\n",
      "2    43.010  42.766607\n",
      "3    42.895  41.074128\n",
      "4    45.020  40.848798\n",
      "..      ...        ...\n",
      "507  50.855  49.811419\n",
      "508  50.890  48.307561\n",
      "509  50.805  48.442673\n",
      "510  51.095  48.456119\n",
      "511  51.290  48.315390\n",
      "\n",
      "[512 rows x 2 columns]\n",
      "Epoch 4/25, Training Loss: 0.0223\n",
      "Epoch 4/25, Validation Loss: 0.2062\n",
      "     actual  predicted\n",
      "0    43.935  42.456142\n",
      "1    44.490  44.162516\n",
      "2    43.010  44.820612\n",
      "3    42.895  42.933136\n",
      "4    45.020  42.813049\n",
      "..      ...        ...\n",
      "507  50.855  52.029609\n",
      "508  50.890  50.423645\n",
      "509  50.805  50.515609\n",
      "510  51.095  50.544326\n",
      "511  51.290  50.635021\n",
      "\n",
      "[512 rows x 2 columns]\n",
      "Epoch 5/25, Training Loss: 0.0183\n",
      "Epoch 5/25, Validation Loss: 0.0607\n",
      "     actual  predicted\n",
      "0    43.935  42.340655\n",
      "1    44.490  44.072355\n",
      "2    43.010  44.698651\n",
      "3    42.895  42.755705\n",
      "4    45.020  42.524410\n",
      "..      ...        ...\n",
      "507  50.855  50.740240\n",
      "508  50.890  49.813184\n",
      "509  50.805  50.059879\n",
      "510  51.095  50.093556\n",
      "511  51.290  50.289723\n",
      "\n",
      "[512 rows x 2 columns]\n",
      "Epoch 6/25, Training Loss: 0.0154\n",
      "Epoch 6/25, Validation Loss: 0.0424\n",
      "     actual  predicted\n",
      "0    43.935  42.690108\n",
      "1    44.490  44.179443\n",
      "2    43.010  44.659598\n",
      "3    42.895  43.150686\n",
      "4    45.020  42.873224\n",
      "..      ...        ...\n",
      "507  50.855  50.416528\n",
      "508  50.890  49.178769\n",
      "509  50.805  49.224176\n",
      "510  51.095  49.058268\n",
      "511  51.290  49.230768\n",
      "\n",
      "[512 rows x 2 columns]\n",
      "Epoch 7/25, Training Loss: 0.0138\n",
      "Epoch 7/25, Validation Loss: 0.0485\n",
      "     actual  predicted\n",
      "0    43.935  42.298001\n",
      "1    44.490  43.738451\n",
      "2    43.010  44.196869\n",
      "3    42.895  42.767159\n",
      "4    45.020  42.337125\n",
      "..      ...        ...\n",
      "507  50.855  49.329434\n",
      "508  50.890  48.162996\n",
      "509  50.805  48.468390\n",
      "510  51.095  48.602322\n",
      "511  51.290  48.860065\n",
      "\n",
      "[512 rows x 2 columns]\n",
      "Epoch 8/25, Training Loss: 0.0124\n",
      "Epoch 8/25, Validation Loss: 0.0660\n",
      "     actual  predicted\n",
      "0    43.935  40.625382\n",
      "1    44.490  41.906749\n",
      "2    43.010  42.162419\n",
      "3    42.895  40.680974\n",
      "4    45.020  40.264737\n",
      "..      ...        ...\n",
      "507  50.855  48.828577\n",
      "508  50.890  47.629158\n",
      "509  50.805  47.745107\n",
      "510  51.095  47.718742\n",
      "511  51.290  48.019410\n",
      "\n",
      "[512 rows x 2 columns]\n",
      "Epoch 9/25, Training Loss: 0.0117\n",
      "Epoch 9/25, Validation Loss: 0.1401\n",
      "     actual  predicted\n",
      "0    43.935  42.092129\n",
      "1    44.490  43.586784\n",
      "2    43.010  43.777452\n",
      "3    42.895  42.285115\n",
      "4    45.020  41.651431\n",
      "..      ...        ...\n",
      "507  50.855  49.815734\n",
      "508  50.890  48.584090\n",
      "509  50.805  48.730615\n",
      "510  51.095  48.769698\n",
      "511  51.290  49.045412\n",
      "\n",
      "[512 rows x 2 columns]\n",
      "Epoch 10/25, Training Loss: 0.0109\n",
      "Epoch 10/25, Validation Loss: 0.0750\n",
      "     actual  predicted\n",
      "0    43.935  43.579885\n",
      "1    44.490  44.979995\n",
      "2    43.010  45.327540\n",
      "3    42.895  43.688836\n",
      "4    45.020  43.221533\n",
      "..      ...        ...\n",
      "507  50.855  50.254073\n",
      "508  50.890  49.212173\n",
      "509  50.805  49.372225\n",
      "510  51.095  49.373632\n",
      "511  51.290  49.578931\n",
      "\n",
      "[512 rows x 2 columns]\n",
      "Epoch 11/25, Training Loss: 0.0095\n",
      "Epoch 11/25, Validation Loss: 0.0357\n",
      "     actual  predicted\n",
      "0    43.935  42.905279\n",
      "1    44.490  44.363503\n",
      "2    43.010  44.635542\n",
      "3    42.895  43.037416\n",
      "4    45.020  42.543379\n",
      "..      ...        ...\n",
      "507  50.855  50.222396\n",
      "508  50.890  49.070286\n",
      "509  50.805  49.296012\n",
      "510  51.095  49.324661\n",
      "511  51.290  49.582938\n",
      "\n",
      "[512 rows x 2 columns]\n",
      "Epoch 12/25, Training Loss: 0.0094\n",
      "Epoch 12/25, Validation Loss: 0.0477\n",
      "     actual  predicted\n",
      "0    43.935  42.183951\n",
      "1    44.490  43.511541\n",
      "2    43.010  43.862560\n",
      "3    42.895  42.286686\n",
      "4    45.020  41.826228\n",
      "..      ...        ...\n",
      "507  50.855  48.954619\n",
      "508  50.890  47.937865\n",
      "509  50.805  48.175530\n",
      "510  51.095  48.213032\n",
      "511  51.290  48.543584\n",
      "\n",
      "[512 rows x 2 columns]\n",
      "Epoch 13/25, Training Loss: 0.0091\n",
      "Epoch 13/25, Validation Loss: 0.0977\n",
      "     actual  predicted\n",
      "0    43.935  42.793475\n",
      "1    44.490  44.107349\n",
      "2    43.010  44.370295\n",
      "3    42.895  42.856385\n",
      "4    45.020  42.426104\n",
      "..      ...        ...\n",
      "507  50.855  49.524575\n",
      "508  50.890  48.433522\n",
      "509  50.805  48.561154\n",
      "510  51.095  48.556590\n",
      "511  51.290  48.837310\n",
      "\n",
      "[512 rows x 2 columns]\n",
      "Epoch 14/25, Training Loss: 0.0089\n",
      "Epoch 14/25, Validation Loss: 0.0572\n",
      "     actual  predicted\n",
      "0    43.935  43.294003\n",
      "1    44.490  44.568048\n",
      "2    43.010  44.995937\n",
      "3    42.895  43.301940\n",
      "4    45.020  42.958855\n",
      "..      ...        ...\n",
      "507  50.855  50.337680\n",
      "508  50.890  49.438413\n",
      "509  50.805  49.635844\n",
      "510  51.095  49.619928\n",
      "511  51.290  49.901622\n",
      "\n",
      "[512 rows x 2 columns]\n",
      "Epoch 15/25, Training Loss: 0.0088\n",
      "Epoch 15/25, Validation Loss: 0.0413\n",
      "     actual  predicted\n",
      "0    43.935  43.469440\n",
      "1    44.490  44.722195\n",
      "2    43.010  45.010060\n",
      "3    42.895  43.327207\n",
      "4    45.020  42.870979\n",
      "..      ...        ...\n",
      "507  50.855  50.357658\n",
      "508  50.890  49.406159\n",
      "509  50.805  49.554648\n",
      "510  51.095  49.511036\n",
      "511  51.290  49.718936\n",
      "\n",
      "[512 rows x 2 columns]\n",
      "Early stopping!\n",
      "       actual  predicted\n",
      "0      43.935  43.469440\n",
      "1      44.490  44.722195\n",
      "2      43.010  45.010060\n",
      "3      42.895  43.327207\n",
      "4      45.020  42.870979\n",
      "...       ...        ...\n",
      "38888  37.415  36.224526\n",
      "38889  37.510  36.165615\n",
      "38890  37.580  35.924057\n",
      "38891  37.630  36.041211\n",
      "38892  37.650  36.432072\n",
      "\n",
      "[38893 rows x 2 columns]\n",
      "Score (RMSE): 1.8654\n",
      "Score (MAE): 1.5983\n",
      "Score (MAPE): 3.5919%\n",
      "training data cutoff:  2023-07-14 07:30:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Studium\\Semester_6\\IoT_Project\\utils.py:911: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_train[columns_to_scale] = scaler.fit_transform(df_train[columns_to_scale])\n",
      "c:\\Studium\\Semester_6\\IoT_Project\\utils.py:912: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_test[columns_to_scale] = scaler.transform(df_test[columns_to_scale])\n",
      "c:\\Studium\\Semester_6\\IoT_Project\\utils.py:916: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_train.drop(['date_time_rounded'], axis=1, inplace=True)\n",
      "c:\\Studium\\Semester_6\\IoT_Project\\utils.py:917: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_test.drop(['date_time_rounded'], axis=1, inplace=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tmp                         float64\n",
      "hum                         float64\n",
      "CO2                         float64\n",
      "VOC                         float64\n",
      "vis                         float64\n",
      "IR                          float64\n",
      "WIFI                        float64\n",
      "BLE                         float64\n",
      "rssi                        float64\n",
      "channel_rssi                float64\n",
      "channel_index               float64\n",
      "spreading_factor            float64\n",
      "bandwidth                   float64\n",
      "f_cnt                       float64\n",
      "isHoliday                   float64\n",
      "isExamTime                  float64\n",
      "weekday                     float64\n",
      "month                       float64\n",
      "hour_sin                    float64\n",
      "semester_SS23               float64\n",
      "semester_WS22/23            float64\n",
      "semester_WS23/24            float64\n",
      "group                       float64\n",
      "device_id_hka-aqm-am001     float64\n",
      "device_id_hka-aqm-am002     float64\n",
      "device_id_hka-aqm-am003a    float64\n",
      "device_id_hka-aqm-am003b    float64\n",
      "device_id_hka-aqm-am004     float64\n",
      "device_id_hka-aqm-am005     float64\n",
      "device_id_hka-aqm-am107     float64\n",
      "device_id_hka-aqm-am109     float64\n",
      "device_id_hka-aqm-am110     float64\n",
      "device_id_hka-aqm-am111     float64\n",
      "device_id_hka-aqm-am115     float64\n",
      "device_id_hka-aqm-am116     float64\n",
      "device_id_hka-aqm-am117     float64\n",
      "device_id_hka-aqm-am123     float64\n",
      "device_id_hka-aqm-am124     float64\n",
      "device_id_hka-aqm-am126     float64\n",
      "device_id_hka-aqm-am201a    float64\n",
      "device_id_hka-aqm-am201b    float64\n",
      "device_id_hka-aqm-am204     float64\n",
      "device_id_hka-aqm-am205     float64\n",
      "device_id_hka-aqm-am209     float64\n",
      "device_id_hka-aqm-am210     float64\n",
      "device_id_hka-aqm-am211     float64\n",
      "device_id_hka-aqm-am301     float64\n",
      "device_id_hka-aqm-am307     float64\n",
      "device_id_hka-aqm-am308     float64\n",
      "dtype: object\n",
      "feature count:  49\n",
      "feature count:  49\n",
      "Training data shape: torch.Size([152512, 20, 49]) torch.Size([152512, 1])\n",
      "Testing data shape: torch.Size([38893, 20, 49]) torch.Size([38893, 1])\n",
      "same columns\n",
      "date_time_rounded           datetime64[ns]\n",
      "tmp                                float64\n",
      "hum                                float64\n",
      "CO2                                float64\n",
      "VOC                                float64\n",
      "vis                                float64\n",
      "IR                                 float64\n",
      "WIFI                               float64\n",
      "BLE                                float64\n",
      "rssi                               float64\n",
      "channel_rssi                       float64\n",
      "channel_index                      float64\n",
      "spreading_factor                   float64\n",
      "bandwidth                          float64\n",
      "f_cnt                              float64\n",
      "isHoliday                          float64\n",
      "isExamTime                         float64\n",
      "weekday                            float64\n",
      "month                              float64\n",
      "hour_sin                           float64\n",
      "semester_SS23                      float64\n",
      "semester_WS22/23                   float64\n",
      "semester_WS23/24                   float64\n",
      "group                                int32\n",
      "device_id_hka-aqm-am001              uint8\n",
      "device_id_hka-aqm-am002              uint8\n",
      "device_id_hka-aqm-am003a             uint8\n",
      "device_id_hka-aqm-am003b             uint8\n",
      "device_id_hka-aqm-am004              uint8\n",
      "device_id_hka-aqm-am005              uint8\n",
      "device_id_hka-aqm-am107              uint8\n",
      "device_id_hka-aqm-am109              uint8\n",
      "device_id_hka-aqm-am110              uint8\n",
      "device_id_hka-aqm-am111              uint8\n",
      "device_id_hka-aqm-am115              uint8\n",
      "device_id_hka-aqm-am116              uint8\n",
      "device_id_hka-aqm-am117              uint8\n",
      "device_id_hka-aqm-am123              uint8\n",
      "device_id_hka-aqm-am124              uint8\n",
      "device_id_hka-aqm-am126              uint8\n",
      "device_id_hka-aqm-am201a             uint8\n",
      "device_id_hka-aqm-am201b             uint8\n",
      "device_id_hka-aqm-am204              uint8\n",
      "device_id_hka-aqm-am205              uint8\n",
      "device_id_hka-aqm-am209              uint8\n",
      "device_id_hka-aqm-am210              uint8\n",
      "device_id_hka-aqm-am211              uint8\n",
      "device_id_hka-aqm-am301              uint8\n",
      "device_id_hka-aqm-am307              uint8\n",
      "device_id_hka-aqm-am308              uint8\n",
      "dtype: object\n",
      "date_time_rounded           datetime64[ns]\n",
      "tmp                                float64\n",
      "hum                                float64\n",
      "CO2                                float64\n",
      "VOC                                float64\n",
      "vis                                float64\n",
      "IR                                 float64\n",
      "WIFI                               float64\n",
      "BLE                                float64\n",
      "rssi                               float64\n",
      "channel_rssi                       float64\n",
      "channel_index                      float64\n",
      "spreading_factor                   float64\n",
      "bandwidth                          float64\n",
      "f_cnt                              float64\n",
      "isHoliday                          float64\n",
      "isExamTime                         float64\n",
      "weekday                            float64\n",
      "month                              float64\n",
      "hour_sin                           float64\n",
      "semester_SS23                      float64\n",
      "semester_WS22/23                   float64\n",
      "semester_WS23/24                   float64\n",
      "group                                int32\n",
      "device_id_hka-aqm-am001              uint8\n",
      "device_id_hka-aqm-am002              uint8\n",
      "device_id_hka-aqm-am003a             uint8\n",
      "device_id_hka-aqm-am003b             uint8\n",
      "device_id_hka-aqm-am004              uint8\n",
      "device_id_hka-aqm-am005              uint8\n",
      "device_id_hka-aqm-am107              uint8\n",
      "device_id_hka-aqm-am109              uint8\n",
      "device_id_hka-aqm-am110              uint8\n",
      "device_id_hka-aqm-am111              uint8\n",
      "device_id_hka-aqm-am115              uint8\n",
      "device_id_hka-aqm-am116              uint8\n",
      "device_id_hka-aqm-am117              uint8\n",
      "device_id_hka-aqm-am123              uint8\n",
      "device_id_hka-aqm-am124              uint8\n",
      "device_id_hka-aqm-am126              uint8\n",
      "device_id_hka-aqm-am201a             uint8\n",
      "device_id_hka-aqm-am201b             uint8\n",
      "device_id_hka-aqm-am204              uint8\n",
      "device_id_hka-aqm-am205              uint8\n",
      "device_id_hka-aqm-am209              uint8\n",
      "device_id_hka-aqm-am210              uint8\n",
      "device_id_hka-aqm-am211              uint8\n",
      "device_id_hka-aqm-am301              uint8\n",
      "device_id_hka-aqm-am307              uint8\n",
      "device_id_hka-aqm-am308              uint8\n",
      "dtype: object\n",
      "         date_time_rounded        tmp        hum         CO2         VOC  \\\n",
      "199592 2022-10-10 14:30:00  23.435455  51.505000  917.954545  459.636364   \n",
      "199593 2022-10-10 16:30:00  25.360000  44.336667  563.666667  555.000000   \n",
      "199594 2022-10-10 17:00:00  25.486667  45.230000  612.333333  607.333333   \n",
      "199595 2022-10-10 18:30:00  25.510000  48.355000  596.000000  657.000000   \n",
      "199596 2022-10-10 19:30:00  25.240000  49.470000  603.000000  599.000000   \n",
      "...                    ...        ...        ...         ...         ...   \n",
      "308834 2023-09-26 19:00:00  27.620000  36.770000  513.000000  919.000000   \n",
      "308835 2023-09-26 22:00:00  27.435000  37.415000  522.500000  957.500000   \n",
      "308836 2023-09-26 22:30:00  27.380000  37.510000  527.500000  958.500000   \n",
      "308837 2023-09-26 23:00:00  27.370000  37.580000  524.500000  949.000000   \n",
      "308838 2023-09-26 23:30:00  27.345000  37.630000  527.000000  955.000000   \n",
      "\n",
      "               vis         IR      WIFI        BLE       rssi  ...  \\\n",
      "199592  249.136364  30.272727  0.954545   1.272727 -72.136364  ...   \n",
      "199593  115.000000  12.666667  1.000000   2.000000 -59.000000  ...   \n",
      "199594  151.333333  16.000000  0.333333   0.000000 -56.333333  ...   \n",
      "199595  153.500000  16.000000  1.000000   0.000000 -61.000000  ...   \n",
      "199596    9.000000   1.000000  0.000000   0.000000 -62.500000  ...   \n",
      "...            ...        ...       ...        ...        ...  ...   \n",
      "308834    5.000000   0.000000  3.500000  13.500000 -74.000000  ...   \n",
      "308835    4.000000   1.000000  3.500000  13.500000 -74.000000  ...   \n",
      "308836    5.500000   2.000000  1.000000   0.000000 -73.000000  ...   \n",
      "308837    5.500000   2.500000  1.500000   0.000000 -72.500000  ...   \n",
      "308838    4.000000   0.000000  3.000000  13.500000 -75.000000  ...   \n",
      "\n",
      "        device_id_hka-aqm-am201a  device_id_hka-aqm-am201b  \\\n",
      "199592                         0                         0   \n",
      "199593                         0                         0   \n",
      "199594                         0                         0   \n",
      "199595                         0                         0   \n",
      "199596                         0                         0   \n",
      "...                          ...                       ...   \n",
      "308834                         0                         0   \n",
      "308835                         0                         0   \n",
      "308836                         0                         0   \n",
      "308837                         0                         0   \n",
      "308838                         0                         0   \n",
      "\n",
      "        device_id_hka-aqm-am204  device_id_hka-aqm-am205  \\\n",
      "199592                        0                        0   \n",
      "199593                        0                        0   \n",
      "199594                        0                        0   \n",
      "199595                        0                        0   \n",
      "199596                        0                        0   \n",
      "...                         ...                      ...   \n",
      "308834                        0                        0   \n",
      "308835                        0                        0   \n",
      "308836                        0                        0   \n",
      "308837                        0                        0   \n",
      "308838                        0                        0   \n",
      "\n",
      "        device_id_hka-aqm-am209  device_id_hka-aqm-am210  \\\n",
      "199592                        0                        0   \n",
      "199593                        0                        0   \n",
      "199594                        0                        0   \n",
      "199595                        0                        0   \n",
      "199596                        0                        0   \n",
      "...                         ...                      ...   \n",
      "308834                        0                        0   \n",
      "308835                        0                        0   \n",
      "308836                        0                        0   \n",
      "308837                        0                        0   \n",
      "308838                        0                        0   \n",
      "\n",
      "        device_id_hka-aqm-am211  device_id_hka-aqm-am301  \\\n",
      "199592                        0                        0   \n",
      "199593                        0                        0   \n",
      "199594                        0                        0   \n",
      "199595                        0                        0   \n",
      "199596                        0                        0   \n",
      "...                         ...                      ...   \n",
      "308834                        0                        0   \n",
      "308835                        0                        0   \n",
      "308836                        0                        0   \n",
      "308837                        0                        0   \n",
      "308838                        0                        0   \n",
      "\n",
      "        device_id_hka-aqm-am307  device_id_hka-aqm-am308  \n",
      "199592                        0                        0  \n",
      "199593                        0                        0  \n",
      "199594                        0                        0  \n",
      "199595                        0                        0  \n",
      "199596                        0                        0  \n",
      "...                         ...                      ...  \n",
      "308834                        0                        1  \n",
      "308835                        0                        1  \n",
      "308836                        0                        1  \n",
      "308837                        0                        1  \n",
      "308838                        0                        1  \n",
      "\n",
      "[109247 rows x 50 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\t-ehm\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\transformer.py:286: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
      "c:\\Users\\t-ehm\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\optim\\lr_scheduler.py:28: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\"The verbose parameter is deprecated. Please use get_last_lr() \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     actual  predicted\n",
      "0    26.665  26.188100\n",
      "1    26.430  26.042386\n",
      "2    26.230  25.670529\n",
      "3    26.105  25.649787\n",
      "4    26.090  25.465757\n",
      "..      ...        ...\n",
      "507  23.270  23.859038\n",
      "508  23.335  23.724657\n",
      "509  23.290  23.832491\n",
      "510  23.175  23.974150\n",
      "511  23.155  24.110270\n",
      "\n",
      "[512 rows x 2 columns]\n",
      "Epoch 1/25, Training Loss: 0.1209\n",
      "Epoch 1/25, Validation Loss: 0.4167\n",
      "     actual  predicted\n",
      "0    26.665  26.018537\n",
      "1    26.430  25.872729\n",
      "2    26.230  25.491731\n",
      "3    26.105  25.460168\n",
      "4    26.090  25.345935\n",
      "..      ...        ...\n",
      "507  23.270  23.242348\n",
      "508  23.335  23.099526\n",
      "509  23.290  23.135250\n",
      "510  23.175  23.220917\n",
      "511  23.155  23.333697\n",
      "\n",
      "[512 rows x 2 columns]\n",
      "Epoch 2/25, Training Loss: 0.0389\n",
      "Epoch 2/25, Validation Loss: 0.2638\n",
      "     actual  predicted\n",
      "0    26.665  25.934410\n",
      "1    26.430  25.913987\n",
      "2    26.230  25.738930\n",
      "3    26.105  25.559311\n",
      "4    26.090  25.402843\n",
      "..      ...        ...\n",
      "507  23.270  23.253755\n",
      "508  23.335  23.107015\n",
      "509  23.290  23.162811\n",
      "510  23.175  23.222295\n",
      "511  23.155  23.336981\n",
      "\n",
      "[512 rows x 2 columns]\n",
      "Epoch 3/25, Training Loss: 0.0259\n",
      "Epoch 3/25, Validation Loss: 0.2202\n",
      "     actual  predicted\n",
      "0    26.665  26.434022\n",
      "1    26.430  26.348895\n",
      "2    26.230  26.144064\n",
      "3    26.105  25.950028\n",
      "4    26.090  25.779460\n",
      "..      ...        ...\n",
      "507  23.270  23.784545\n",
      "508  23.335  23.598842\n",
      "509  23.290  23.679419\n",
      "510  23.175  23.679983\n",
      "511  23.155  23.667173\n",
      "\n",
      "[512 rows x 2 columns]\n",
      "Epoch 4/25, Training Loss: 0.0200\n",
      "Epoch 4/25, Validation Loss: 0.1352\n",
      "     actual  predicted\n",
      "0    26.665  26.239073\n",
      "1    26.430  26.197084\n",
      "2    26.230  25.982365\n",
      "3    26.105  25.724617\n",
      "4    26.090  25.569480\n",
      "..      ...        ...\n",
      "507  23.270  23.463002\n",
      "508  23.335  23.236490\n",
      "509  23.290  23.261569\n",
      "510  23.175  23.240368\n",
      "511  23.155  23.249024\n",
      "\n",
      "[512 rows x 2 columns]\n",
      "Epoch 5/25, Training Loss: 0.0165\n",
      "Epoch 5/25, Validation Loss: 0.1293\n",
      "     actual  predicted\n",
      "0    26.665  26.685231\n",
      "1    26.430  26.507405\n",
      "2    26.230  26.214230\n",
      "3    26.105  26.026683\n",
      "4    26.090  25.872125\n",
      "..      ...        ...\n",
      "507  23.270  23.625128\n",
      "508  23.335  23.403788\n",
      "509  23.290  23.427672\n",
      "510  23.175  23.372873\n",
      "511  23.155  23.353142\n",
      "\n",
      "[512 rows x 2 columns]\n",
      "Epoch 6/25, Training Loss: 0.0147\n",
      "Epoch 6/25, Validation Loss: 0.0795\n",
      "     actual  predicted\n",
      "0    26.665  26.391179\n",
      "1    26.430  26.262116\n",
      "2    26.230  26.043501\n",
      "3    26.105  25.811116\n",
      "4    26.090  25.663352\n",
      "..      ...        ...\n",
      "507  23.270  23.726165\n",
      "508  23.335  23.501298\n",
      "509  23.290  23.548608\n",
      "510  23.175  23.496857\n",
      "511  23.155  23.513143\n",
      "\n",
      "[512 rows x 2 columns]\n",
      "Epoch 7/25, Training Loss: 0.0128\n",
      "Epoch 7/25, Validation Loss: 0.1322\n",
      "     actual  predicted\n",
      "0    26.665  26.530531\n",
      "1    26.430  26.419099\n",
      "2    26.230  26.176574\n",
      "3    26.105  25.830542\n",
      "4    26.090  25.657525\n",
      "..      ...        ...\n",
      "507  23.270  23.592327\n",
      "508  23.335  23.425084\n",
      "509  23.290  23.469478\n",
      "510  23.175  23.421947\n",
      "511  23.155  23.435765\n",
      "\n",
      "[512 rows x 2 columns]\n",
      "Epoch 8/25, Training Loss: 0.0118\n",
      "Epoch 8/25, Validation Loss: 0.0983\n",
      "     actual  predicted\n",
      "0    26.665  26.646853\n",
      "1    26.430  26.547729\n",
      "2    26.230  26.237763\n",
      "3    26.105  25.967918\n",
      "4    26.090  25.800056\n",
      "..      ...        ...\n",
      "507  23.270  23.714150\n",
      "508  23.335  23.547441\n",
      "509  23.290  23.560506\n",
      "510  23.175  23.475592\n",
      "511  23.155  23.442295\n",
      "\n",
      "[512 rows x 2 columns]\n",
      "Epoch 9/25, Training Loss: 0.0106\n",
      "Epoch 9/25, Validation Loss: 0.0566\n",
      "     actual  predicted\n",
      "0    26.665  26.649464\n",
      "1    26.430  26.565597\n",
      "2    26.230  26.261896\n",
      "3    26.105  26.011595\n",
      "4    26.090  25.840493\n",
      "..      ...        ...\n",
      "507  23.270  23.684423\n",
      "508  23.335  23.500026\n",
      "509  23.290  23.497412\n",
      "510  23.175  23.421895\n",
      "511  23.155  23.427024\n",
      "\n",
      "[512 rows x 2 columns]\n",
      "Epoch 10/25, Training Loss: 0.0102\n",
      "Epoch 10/25, Validation Loss: 0.0754\n",
      "     actual  predicted\n",
      "0    26.665  26.543036\n",
      "1    26.430  26.432819\n",
      "2    26.230  26.151198\n",
      "3    26.105  25.871414\n",
      "4    26.090  25.742286\n",
      "..      ...        ...\n",
      "507  23.270  23.607138\n",
      "508  23.335  23.436299\n",
      "509  23.290  23.469138\n",
      "510  23.175  23.400144\n",
      "511  23.155  23.371104\n",
      "\n",
      "[512 rows x 2 columns]\n",
      "Epoch 11/25, Training Loss: 0.0097\n",
      "Epoch 11/25, Validation Loss: 0.0446\n",
      "     actual  predicted\n",
      "0    26.665  26.586542\n",
      "1    26.430  26.544235\n",
      "2    26.230  26.245075\n",
      "3    26.105  25.983503\n",
      "4    26.090  25.818566\n",
      "..      ...        ...\n",
      "507  23.270  23.716585\n",
      "508  23.335  23.527375\n",
      "509  23.290  23.532224\n",
      "510  23.175  23.499353\n",
      "511  23.155  23.476777\n",
      "\n",
      "[512 rows x 2 columns]\n",
      "Epoch 12/25, Training Loss: 0.0086\n",
      "Epoch 12/25, Validation Loss: 0.0505\n",
      "     actual  predicted\n",
      "0    26.665  26.618327\n",
      "1    26.430  26.567742\n",
      "2    26.230  26.331831\n",
      "3    26.105  26.069253\n",
      "4    26.090  25.895307\n",
      "..      ...        ...\n",
      "507  23.270  23.608854\n",
      "508  23.335  23.414634\n",
      "509  23.290  23.480669\n",
      "510  23.175  23.449604\n",
      "511  23.155  23.450138\n",
      "\n",
      "[512 rows x 2 columns]\n",
      "Epoch 13/25, Training Loss: 0.0083\n",
      "Epoch 13/25, Validation Loss: 0.0665\n",
      "     actual  predicted\n",
      "0    26.665  26.379061\n",
      "1    26.430  26.323704\n",
      "2    26.230  26.085798\n",
      "3    26.105  25.745320\n",
      "4    26.090  25.673098\n",
      "..      ...        ...\n",
      "507  23.270  23.611556\n",
      "508  23.335  23.488233\n",
      "509  23.290  23.503072\n",
      "510  23.175  23.449044\n",
      "511  23.155  23.465276\n",
      "\n",
      "[512 rows x 2 columns]\n",
      "Epoch 14/25, Training Loss: 0.0080\n",
      "Epoch 14/25, Validation Loss: 0.0686\n",
      "     actual  predicted\n",
      "0    26.665  26.659306\n",
      "1    26.430  26.582704\n",
      "2    26.230  26.289794\n",
      "3    26.105  26.006293\n",
      "4    26.090  25.845672\n",
      "..      ...        ...\n",
      "507  23.270  23.554152\n",
      "508  23.335  23.345373\n",
      "509  23.290  23.408924\n",
      "510  23.175  23.407109\n",
      "511  23.155  23.406783\n",
      "\n",
      "[512 rows x 2 columns]\n",
      "Epoch 15/25, Training Loss: 0.0077\n",
      "Epoch 15/25, Validation Loss: 0.0792\n",
      "     actual  predicted\n",
      "0    26.665  26.586487\n",
      "1    26.430  26.487826\n",
      "2    26.230  26.194153\n",
      "3    26.105  25.918658\n",
      "4    26.090  25.788582\n",
      "..      ...        ...\n",
      "507  23.270  23.641367\n",
      "508  23.335  23.450094\n",
      "509  23.290  23.510489\n",
      "510  23.175  23.470671\n",
      "511  23.155  23.428130\n",
      "\n",
      "[512 rows x 2 columns]\n",
      "Early stopping!\n",
      "       actual  predicted\n",
      "0      26.665  26.586487\n",
      "1      26.430  26.487826\n",
      "2      26.230  26.194153\n",
      "3      26.105  25.918658\n",
      "4      26.090  25.788582\n",
      "...       ...        ...\n",
      "38888  27.435  26.826895\n",
      "38889  27.380  26.851242\n",
      "38890  27.370  26.892426\n",
      "38891  27.345  26.987878\n",
      "38892  27.330  27.018924\n",
      "\n",
      "[38893 rows x 2 columns]\n",
      "Score (RMSE): 0.7703\n",
      "Score (MAE): 0.5912\n",
      "Score (MAPE): 2.1370%\n",
      "training data cutoff:  2023-07-14 07:30:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Studium\\Semester_6\\IoT_Project\\utils.py:911: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_train[columns_to_scale] = scaler.fit_transform(df_train[columns_to_scale])\n",
      "c:\\Studium\\Semester_6\\IoT_Project\\utils.py:912: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_test[columns_to_scale] = scaler.transform(df_test[columns_to_scale])\n",
      "c:\\Studium\\Semester_6\\IoT_Project\\utils.py:916: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_train.drop(['date_time_rounded'], axis=1, inplace=True)\n",
      "c:\\Studium\\Semester_6\\IoT_Project\\utils.py:917: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_test.drop(['date_time_rounded'], axis=1, inplace=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tmp                         float64\n",
      "hum                         float64\n",
      "CO2                         float64\n",
      "VOC                         float64\n",
      "vis                         float64\n",
      "IR                          float64\n",
      "WIFI                        float64\n",
      "BLE                         float64\n",
      "rssi                        float64\n",
      "channel_rssi                float64\n",
      "channel_index               float64\n",
      "spreading_factor            float64\n",
      "bandwidth                   float64\n",
      "f_cnt                       float64\n",
      "isHoliday                   float64\n",
      "isExamTime                  float64\n",
      "weekday                     float64\n",
      "month                       float64\n",
      "hour_sin                    float64\n",
      "semester_SS23               float64\n",
      "semester_WS22/23            float64\n",
      "semester_WS23/24            float64\n",
      "group                       float64\n",
      "device_id_hka-aqm-am001     float64\n",
      "device_id_hka-aqm-am002     float64\n",
      "device_id_hka-aqm-am003a    float64\n",
      "device_id_hka-aqm-am003b    float64\n",
      "device_id_hka-aqm-am004     float64\n",
      "device_id_hka-aqm-am005     float64\n",
      "device_id_hka-aqm-am107     float64\n",
      "device_id_hka-aqm-am109     float64\n",
      "device_id_hka-aqm-am110     float64\n",
      "device_id_hka-aqm-am111     float64\n",
      "device_id_hka-aqm-am115     float64\n",
      "device_id_hka-aqm-am116     float64\n",
      "device_id_hka-aqm-am117     float64\n",
      "device_id_hka-aqm-am123     float64\n",
      "device_id_hka-aqm-am124     float64\n",
      "device_id_hka-aqm-am126     float64\n",
      "device_id_hka-aqm-am201a    float64\n",
      "device_id_hka-aqm-am201b    float64\n",
      "device_id_hka-aqm-am204     float64\n",
      "device_id_hka-aqm-am205     float64\n",
      "device_id_hka-aqm-am209     float64\n",
      "device_id_hka-aqm-am210     float64\n",
      "device_id_hka-aqm-am211     float64\n",
      "device_id_hka-aqm-am301     float64\n",
      "device_id_hka-aqm-am307     float64\n",
      "device_id_hka-aqm-am308     float64\n",
      "dtype: object\n",
      "feature count:  49\n",
      "feature count:  49\n",
      "Training data shape: torch.Size([152512, 20, 49]) torch.Size([152512, 1])\n",
      "Testing data shape: torch.Size([38893, 20, 49]) torch.Size([38893, 1])\n",
      "same columns\n",
      "date_time_rounded           datetime64[ns]\n",
      "tmp                                float64\n",
      "hum                                float64\n",
      "CO2                                float64\n",
      "VOC                                float64\n",
      "vis                                float64\n",
      "IR                                 float64\n",
      "WIFI                               float64\n",
      "BLE                                float64\n",
      "rssi                               float64\n",
      "channel_rssi                       float64\n",
      "channel_index                      float64\n",
      "spreading_factor                   float64\n",
      "bandwidth                          float64\n",
      "f_cnt                              float64\n",
      "isHoliday                          float64\n",
      "isExamTime                         float64\n",
      "weekday                            float64\n",
      "month                              float64\n",
      "hour_sin                           float64\n",
      "semester_SS23                      float64\n",
      "semester_WS22/23                   float64\n",
      "semester_WS23/24                   float64\n",
      "group                                int32\n",
      "device_id_hka-aqm-am001              uint8\n",
      "device_id_hka-aqm-am002              uint8\n",
      "device_id_hka-aqm-am003a             uint8\n",
      "device_id_hka-aqm-am003b             uint8\n",
      "device_id_hka-aqm-am004              uint8\n",
      "device_id_hka-aqm-am005              uint8\n",
      "device_id_hka-aqm-am107              uint8\n",
      "device_id_hka-aqm-am109              uint8\n",
      "device_id_hka-aqm-am110              uint8\n",
      "device_id_hka-aqm-am111              uint8\n",
      "device_id_hka-aqm-am115              uint8\n",
      "device_id_hka-aqm-am116              uint8\n",
      "device_id_hka-aqm-am117              uint8\n",
      "device_id_hka-aqm-am123              uint8\n",
      "device_id_hka-aqm-am124              uint8\n",
      "device_id_hka-aqm-am126              uint8\n",
      "device_id_hka-aqm-am201a             uint8\n",
      "device_id_hka-aqm-am201b             uint8\n",
      "device_id_hka-aqm-am204              uint8\n",
      "device_id_hka-aqm-am205              uint8\n",
      "device_id_hka-aqm-am209              uint8\n",
      "device_id_hka-aqm-am210              uint8\n",
      "device_id_hka-aqm-am211              uint8\n",
      "device_id_hka-aqm-am301              uint8\n",
      "device_id_hka-aqm-am307              uint8\n",
      "device_id_hka-aqm-am308              uint8\n",
      "dtype: object\n",
      "date_time_rounded           datetime64[ns]\n",
      "tmp                                float64\n",
      "hum                                float64\n",
      "CO2                                float64\n",
      "VOC                                float64\n",
      "vis                                float64\n",
      "IR                                 float64\n",
      "WIFI                               float64\n",
      "BLE                                float64\n",
      "rssi                               float64\n",
      "channel_rssi                       float64\n",
      "channel_index                      float64\n",
      "spreading_factor                   float64\n",
      "bandwidth                          float64\n",
      "f_cnt                              float64\n",
      "isHoliday                          float64\n",
      "isExamTime                         float64\n",
      "weekday                            float64\n",
      "month                              float64\n",
      "hour_sin                           float64\n",
      "semester_SS23                      float64\n",
      "semester_WS22/23                   float64\n",
      "semester_WS23/24                   float64\n",
      "group                                int32\n",
      "device_id_hka-aqm-am001              uint8\n",
      "device_id_hka-aqm-am002              uint8\n",
      "device_id_hka-aqm-am003a             uint8\n",
      "device_id_hka-aqm-am003b             uint8\n",
      "device_id_hka-aqm-am004              uint8\n",
      "device_id_hka-aqm-am005              uint8\n",
      "device_id_hka-aqm-am107              uint8\n",
      "device_id_hka-aqm-am109              uint8\n",
      "device_id_hka-aqm-am110              uint8\n",
      "device_id_hka-aqm-am111              uint8\n",
      "device_id_hka-aqm-am115              uint8\n",
      "device_id_hka-aqm-am116              uint8\n",
      "device_id_hka-aqm-am117              uint8\n",
      "device_id_hka-aqm-am123              uint8\n",
      "device_id_hka-aqm-am124              uint8\n",
      "device_id_hka-aqm-am126              uint8\n",
      "device_id_hka-aqm-am201a             uint8\n",
      "device_id_hka-aqm-am201b             uint8\n",
      "device_id_hka-aqm-am204              uint8\n",
      "device_id_hka-aqm-am205              uint8\n",
      "device_id_hka-aqm-am209              uint8\n",
      "device_id_hka-aqm-am210              uint8\n",
      "device_id_hka-aqm-am211              uint8\n",
      "device_id_hka-aqm-am301              uint8\n",
      "device_id_hka-aqm-am307              uint8\n",
      "device_id_hka-aqm-am308              uint8\n",
      "dtype: object\n",
      "         date_time_rounded        tmp        hum         CO2         VOC  \\\n",
      "199592 2022-10-10 14:30:00  23.435455  51.505000  917.954545  459.636364   \n",
      "199593 2022-10-10 16:30:00  25.360000  44.336667  563.666667  555.000000   \n",
      "199594 2022-10-10 17:00:00  25.486667  45.230000  612.333333  607.333333   \n",
      "199595 2022-10-10 18:30:00  25.510000  48.355000  596.000000  657.000000   \n",
      "199596 2022-10-10 19:30:00  25.240000  49.470000  603.000000  599.000000   \n",
      "...                    ...        ...        ...         ...         ...   \n",
      "308834 2023-09-26 19:00:00  27.620000  36.770000  513.000000  919.000000   \n",
      "308835 2023-09-26 22:00:00  27.435000  37.415000  522.500000  957.500000   \n",
      "308836 2023-09-26 22:30:00  27.380000  37.510000  527.500000  958.500000   \n",
      "308837 2023-09-26 23:00:00  27.370000  37.580000  524.500000  949.000000   \n",
      "308838 2023-09-26 23:30:00  27.345000  37.630000  527.000000  955.000000   \n",
      "\n",
      "               vis         IR      WIFI        BLE       rssi  ...  \\\n",
      "199592  249.136364  30.272727  0.954545   1.272727 -72.136364  ...   \n",
      "199593  115.000000  12.666667  1.000000   2.000000 -59.000000  ...   \n",
      "199594  151.333333  16.000000  0.333333   0.000000 -56.333333  ...   \n",
      "199595  153.500000  16.000000  1.000000   0.000000 -61.000000  ...   \n",
      "199596    9.000000   1.000000  0.000000   0.000000 -62.500000  ...   \n",
      "...            ...        ...       ...        ...        ...  ...   \n",
      "308834    5.000000   0.000000  3.500000  13.500000 -74.000000  ...   \n",
      "308835    4.000000   1.000000  3.500000  13.500000 -74.000000  ...   \n",
      "308836    5.500000   2.000000  1.000000   0.000000 -73.000000  ...   \n",
      "308837    5.500000   2.500000  1.500000   0.000000 -72.500000  ...   \n",
      "308838    4.000000   0.000000  3.000000  13.500000 -75.000000  ...   \n",
      "\n",
      "        device_id_hka-aqm-am201a  device_id_hka-aqm-am201b  \\\n",
      "199592                         0                         0   \n",
      "199593                         0                         0   \n",
      "199594                         0                         0   \n",
      "199595                         0                         0   \n",
      "199596                         0                         0   \n",
      "...                          ...                       ...   \n",
      "308834                         0                         0   \n",
      "308835                         0                         0   \n",
      "308836                         0                         0   \n",
      "308837                         0                         0   \n",
      "308838                         0                         0   \n",
      "\n",
      "        device_id_hka-aqm-am204  device_id_hka-aqm-am205  \\\n",
      "199592                        0                        0   \n",
      "199593                        0                        0   \n",
      "199594                        0                        0   \n",
      "199595                        0                        0   \n",
      "199596                        0                        0   \n",
      "...                         ...                      ...   \n",
      "308834                        0                        0   \n",
      "308835                        0                        0   \n",
      "308836                        0                        0   \n",
      "308837                        0                        0   \n",
      "308838                        0                        0   \n",
      "\n",
      "        device_id_hka-aqm-am209  device_id_hka-aqm-am210  \\\n",
      "199592                        0                        0   \n",
      "199593                        0                        0   \n",
      "199594                        0                        0   \n",
      "199595                        0                        0   \n",
      "199596                        0                        0   \n",
      "...                         ...                      ...   \n",
      "308834                        0                        0   \n",
      "308835                        0                        0   \n",
      "308836                        0                        0   \n",
      "308837                        0                        0   \n",
      "308838                        0                        0   \n",
      "\n",
      "        device_id_hka-aqm-am211  device_id_hka-aqm-am301  \\\n",
      "199592                        0                        0   \n",
      "199593                        0                        0   \n",
      "199594                        0                        0   \n",
      "199595                        0                        0   \n",
      "199596                        0                        0   \n",
      "...                         ...                      ...   \n",
      "308834                        0                        0   \n",
      "308835                        0                        0   \n",
      "308836                        0                        0   \n",
      "308837                        0                        0   \n",
      "308838                        0                        0   \n",
      "\n",
      "        device_id_hka-aqm-am307  device_id_hka-aqm-am308  \n",
      "199592                        0                        0  \n",
      "199593                        0                        0  \n",
      "199594                        0                        0  \n",
      "199595                        0                        0  \n",
      "199596                        0                        0  \n",
      "...                         ...                      ...  \n",
      "308834                        0                        1  \n",
      "308835                        0                        1  \n",
      "308836                        0                        1  \n",
      "308837                        0                        1  \n",
      "308838                        0                        1  \n",
      "\n",
      "[109247 rows x 50 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\t-ehm\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\transformer.py:286: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
      "c:\\Users\\t-ehm\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\optim\\lr_scheduler.py:28: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\"The verbose parameter is deprecated. Please use get_last_lr() \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        actual  predicted\n",
      "0     9.499996  33.253821\n",
      "1    10.999995  -0.101166\n",
      "2    11.999998   6.496131\n",
      "3    11.999998  -5.633182\n",
      "4    16.499996  -1.633453\n",
      "..         ...        ...\n",
      "507  64.500003  57.566597\n",
      "508  63.999996  80.440866\n",
      "509  38.000003  83.319729\n",
      "510  11.999998  49.660386\n",
      "511  13.499998  29.708787\n",
      "\n",
      "[512 rows x 2 columns]\n",
      "Epoch 1/25, Training Loss: 0.7855\n",
      "Epoch 1/25, Validation Loss: 0.2997\n",
      "        actual   predicted\n",
      "0     9.499996   44.532711\n",
      "1    10.999995   -2.061636\n",
      "2    11.999998    0.438663\n",
      "3    11.999998   11.546822\n",
      "4    16.499996    2.963445\n",
      "..         ...         ...\n",
      "507  64.500003  119.914279\n",
      "508  63.999996  158.846581\n",
      "509  38.000003  164.442403\n",
      "510  11.999998  102.396801\n",
      "511  13.499998   60.087666\n",
      "\n",
      "[512 rows x 2 columns]\n",
      "Epoch 2/25, Training Loss: 0.6610\n",
      "Epoch 2/25, Validation Loss: 0.2737\n",
      "        actual   predicted\n",
      "0     9.499996  -15.673938\n",
      "1    10.999995  -38.976627\n",
      "2    11.999998  -23.991487\n",
      "3    11.999998  -29.382867\n",
      "4    16.499996  -28.875553\n",
      "..         ...         ...\n",
      "507  64.500003   85.119967\n",
      "508  63.999996  101.095384\n",
      "509  38.000003  105.661417\n",
      "510  11.999998   58.220063\n",
      "511  13.499998   27.402361\n",
      "\n",
      "[512 rows x 2 columns]\n",
      "Epoch 3/25, Training Loss: 0.6516\n",
      "Epoch 3/25, Validation Loss: 0.2994\n",
      "        actual   predicted\n",
      "0     9.499996   70.782007\n",
      "1    10.999995   36.053185\n",
      "2    11.999998   56.658737\n",
      "3    11.999998   90.604785\n",
      "4    16.499996  110.404254\n",
      "..         ...         ...\n",
      "507  64.500003  189.980880\n",
      "508  63.999996  197.241779\n",
      "509  38.000003  212.091277\n",
      "510  11.999998  142.212072\n",
      "511  13.499998   81.978515\n",
      "\n",
      "[512 rows x 2 columns]\n",
      "Epoch 4/25, Training Loss: 0.6457\n",
      "Epoch 4/25, Validation Loss: 0.2658\n",
      "        actual   predicted\n",
      "0     9.499996   54.606894\n",
      "1    10.999995   32.809103\n",
      "2    11.999998   50.560891\n",
      "3    11.999998   49.212785\n",
      "4    16.499996   53.766648\n",
      "..         ...         ...\n",
      "507  64.500003  148.859041\n",
      "508  63.999996  135.663321\n",
      "509  38.000003  118.213599\n",
      "510  11.999998   72.633988\n",
      "511  13.499998   44.768029\n",
      "\n",
      "[512 rows x 2 columns]\n",
      "Epoch 5/25, Training Loss: 0.6366\n",
      "Epoch 5/25, Validation Loss: 0.2953\n",
      "        actual   predicted\n",
      "0     9.499996   42.992215\n",
      "1    10.999995   21.173392\n",
      "2    11.999998   45.725555\n",
      "3    11.999998   36.364101\n",
      "4    16.499996   50.566253\n",
      "..         ...         ...\n",
      "507  64.500003  107.942299\n",
      "508  63.999996  114.135171\n",
      "509  38.000003  112.987166\n",
      "510  11.999998   71.182315\n",
      "511  13.499998   50.312263\n",
      "\n",
      "[512 rows x 2 columns]\n",
      "Epoch 6/25, Training Loss: 0.6293\n",
      "Epoch 6/25, Validation Loss: 0.2784\n",
      "        actual   predicted\n",
      "0     9.499996  111.480963\n",
      "1    10.999995   71.048985\n",
      "2    11.999998  107.384535\n",
      "3    11.999998  116.560431\n",
      "4    16.499996  103.340608\n",
      "..         ...         ...\n",
      "507  64.500003  224.480204\n",
      "508  63.999996  181.567483\n",
      "509  38.000003  178.372378\n",
      "510  11.999998  149.403157\n",
      "511  13.499998  111.531293\n",
      "\n",
      "[512 rows x 2 columns]\n",
      "Epoch 7/25, Training Loss: 0.6278\n",
      "Epoch 7/25, Validation Loss: 0.3072\n",
      "        actual   predicted\n",
      "0     9.499996   61.150621\n",
      "1    10.999995   46.573558\n",
      "2    11.999998   63.772707\n",
      "3    11.999998   60.707682\n",
      "4    16.499996   61.273298\n",
      "..         ...         ...\n",
      "507  64.500003  112.203235\n",
      "508  63.999996  103.531972\n",
      "509  38.000003  111.008849\n",
      "510  11.999998   86.739595\n",
      "511  13.499998   65.393070\n",
      "\n",
      "[512 rows x 2 columns]\n",
      "Epoch 8/25, Training Loss: 0.6211\n",
      "Epoch 8/25, Validation Loss: 0.2690\n",
      "        actual   predicted\n",
      "0     9.499996   31.329103\n",
      "1    10.999995   19.017518\n",
      "2    11.999998   33.820956\n",
      "3    11.999998   36.005559\n",
      "4    16.499996   32.383944\n",
      "..         ...         ...\n",
      "507  64.500003  114.894453\n",
      "508  63.999996  102.427880\n",
      "509  38.000003  120.069660\n",
      "510  11.999998   91.758306\n",
      "511  13.499998   58.535083\n",
      "\n",
      "[512 rows x 2 columns]\n",
      "Early stopping!\n",
      "          actual  predicted\n",
      "0       9.499996  31.329103\n",
      "1      10.999995  19.017518\n",
      "2      11.999998  33.820956\n",
      "3      11.999998  36.005559\n",
      "4      16.499996  32.383944\n",
      "...          ...        ...\n",
      "38888   3.999995   1.430612\n",
      "38889   5.499994  -1.392287\n",
      "38890   5.499994   0.651942\n",
      "38891   3.999995   1.289905\n",
      "38892   3.999995   3.211219\n",
      "\n",
      "[38893 rows x 2 columns]\n",
      "Score (RMSE): 415.1336\n",
      "Score (MAE): 91.3632\n",
      "Score (MAPE): 212.4210%\n",
      "training data cutoff:  2023-07-14 07:30:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Studium\\Semester_6\\IoT_Project\\utils.py:911: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_train[columns_to_scale] = scaler.fit_transform(df_train[columns_to_scale])\n",
      "c:\\Studium\\Semester_6\\IoT_Project\\utils.py:912: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_test[columns_to_scale] = scaler.transform(df_test[columns_to_scale])\n",
      "c:\\Studium\\Semester_6\\IoT_Project\\utils.py:916: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_train.drop(['date_time_rounded'], axis=1, inplace=True)\n",
      "c:\\Studium\\Semester_6\\IoT_Project\\utils.py:917: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_test.drop(['date_time_rounded'], axis=1, inplace=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tmp                         float64\n",
      "hum                         float64\n",
      "CO2                         float64\n",
      "VOC                         float64\n",
      "vis                         float64\n",
      "IR                          float64\n",
      "WIFI                        float64\n",
      "BLE                         float64\n",
      "rssi                        float64\n",
      "channel_rssi                float64\n",
      "channel_index               float64\n",
      "spreading_factor            float64\n",
      "bandwidth                   float64\n",
      "f_cnt                       float64\n",
      "isHoliday                   float64\n",
      "isExamTime                  float64\n",
      "weekday                     float64\n",
      "month                       float64\n",
      "hour_sin                    float64\n",
      "semester_SS23               float64\n",
      "semester_WS22/23            float64\n",
      "semester_WS23/24            float64\n",
      "group                       float64\n",
      "device_id_hka-aqm-am001     float64\n",
      "device_id_hka-aqm-am002     float64\n",
      "device_id_hka-aqm-am003a    float64\n",
      "device_id_hka-aqm-am003b    float64\n",
      "device_id_hka-aqm-am004     float64\n",
      "device_id_hka-aqm-am005     float64\n",
      "device_id_hka-aqm-am107     float64\n",
      "device_id_hka-aqm-am109     float64\n",
      "device_id_hka-aqm-am110     float64\n",
      "device_id_hka-aqm-am111     float64\n",
      "device_id_hka-aqm-am115     float64\n",
      "device_id_hka-aqm-am116     float64\n",
      "device_id_hka-aqm-am117     float64\n",
      "device_id_hka-aqm-am123     float64\n",
      "device_id_hka-aqm-am124     float64\n",
      "device_id_hka-aqm-am126     float64\n",
      "device_id_hka-aqm-am201a    float64\n",
      "device_id_hka-aqm-am201b    float64\n",
      "device_id_hka-aqm-am204     float64\n",
      "device_id_hka-aqm-am205     float64\n",
      "device_id_hka-aqm-am209     float64\n",
      "device_id_hka-aqm-am210     float64\n",
      "device_id_hka-aqm-am211     float64\n",
      "device_id_hka-aqm-am301     float64\n",
      "device_id_hka-aqm-am307     float64\n",
      "device_id_hka-aqm-am308     float64\n",
      "dtype: object\n",
      "feature count:  49\n",
      "feature count:  49\n",
      "Training data shape: torch.Size([152512, 20, 49]) torch.Size([152512, 1])\n",
      "Testing data shape: torch.Size([38893, 20, 49]) torch.Size([38893, 1])\n",
      "same columns\n",
      "date_time_rounded           datetime64[ns]\n",
      "tmp                                float64\n",
      "hum                                float64\n",
      "CO2                                float64\n",
      "VOC                                float64\n",
      "vis                                float64\n",
      "IR                                 float64\n",
      "WIFI                               float64\n",
      "BLE                                float64\n",
      "rssi                               float64\n",
      "channel_rssi                       float64\n",
      "channel_index                      float64\n",
      "spreading_factor                   float64\n",
      "bandwidth                          float64\n",
      "f_cnt                              float64\n",
      "isHoliday                          float64\n",
      "isExamTime                         float64\n",
      "weekday                            float64\n",
      "month                              float64\n",
      "hour_sin                           float64\n",
      "semester_SS23                      float64\n",
      "semester_WS22/23                   float64\n",
      "semester_WS23/24                   float64\n",
      "group                                int32\n",
      "device_id_hka-aqm-am001              uint8\n",
      "device_id_hka-aqm-am002              uint8\n",
      "device_id_hka-aqm-am003a             uint8\n",
      "device_id_hka-aqm-am003b             uint8\n",
      "device_id_hka-aqm-am004              uint8\n",
      "device_id_hka-aqm-am005              uint8\n",
      "device_id_hka-aqm-am107              uint8\n",
      "device_id_hka-aqm-am109              uint8\n",
      "device_id_hka-aqm-am110              uint8\n",
      "device_id_hka-aqm-am111              uint8\n",
      "device_id_hka-aqm-am115              uint8\n",
      "device_id_hka-aqm-am116              uint8\n",
      "device_id_hka-aqm-am117              uint8\n",
      "device_id_hka-aqm-am123              uint8\n",
      "device_id_hka-aqm-am124              uint8\n",
      "device_id_hka-aqm-am126              uint8\n",
      "device_id_hka-aqm-am201a             uint8\n",
      "device_id_hka-aqm-am201b             uint8\n",
      "device_id_hka-aqm-am204              uint8\n",
      "device_id_hka-aqm-am205              uint8\n",
      "device_id_hka-aqm-am209              uint8\n",
      "device_id_hka-aqm-am210              uint8\n",
      "device_id_hka-aqm-am211              uint8\n",
      "device_id_hka-aqm-am301              uint8\n",
      "device_id_hka-aqm-am307              uint8\n",
      "device_id_hka-aqm-am308              uint8\n",
      "dtype: object\n",
      "date_time_rounded           datetime64[ns]\n",
      "tmp                                float64\n",
      "hum                                float64\n",
      "CO2                                float64\n",
      "VOC                                float64\n",
      "vis                                float64\n",
      "IR                                 float64\n",
      "WIFI                               float64\n",
      "BLE                                float64\n",
      "rssi                               float64\n",
      "channel_rssi                       float64\n",
      "channel_index                      float64\n",
      "spreading_factor                   float64\n",
      "bandwidth                          float64\n",
      "f_cnt                              float64\n",
      "isHoliday                          float64\n",
      "isExamTime                         float64\n",
      "weekday                            float64\n",
      "month                              float64\n",
      "hour_sin                           float64\n",
      "semester_SS23                      float64\n",
      "semester_WS22/23                   float64\n",
      "semester_WS23/24                   float64\n",
      "group                                int32\n",
      "device_id_hka-aqm-am001              uint8\n",
      "device_id_hka-aqm-am002              uint8\n",
      "device_id_hka-aqm-am003a             uint8\n",
      "device_id_hka-aqm-am003b             uint8\n",
      "device_id_hka-aqm-am004              uint8\n",
      "device_id_hka-aqm-am005              uint8\n",
      "device_id_hka-aqm-am107              uint8\n",
      "device_id_hka-aqm-am109              uint8\n",
      "device_id_hka-aqm-am110              uint8\n",
      "device_id_hka-aqm-am111              uint8\n",
      "device_id_hka-aqm-am115              uint8\n",
      "device_id_hka-aqm-am116              uint8\n",
      "device_id_hka-aqm-am117              uint8\n",
      "device_id_hka-aqm-am123              uint8\n",
      "device_id_hka-aqm-am124              uint8\n",
      "device_id_hka-aqm-am126              uint8\n",
      "device_id_hka-aqm-am201a             uint8\n",
      "device_id_hka-aqm-am201b             uint8\n",
      "device_id_hka-aqm-am204              uint8\n",
      "device_id_hka-aqm-am205              uint8\n",
      "device_id_hka-aqm-am209              uint8\n",
      "device_id_hka-aqm-am210              uint8\n",
      "device_id_hka-aqm-am211              uint8\n",
      "device_id_hka-aqm-am301              uint8\n",
      "device_id_hka-aqm-am307              uint8\n",
      "device_id_hka-aqm-am308              uint8\n",
      "dtype: object\n",
      "         date_time_rounded        tmp        hum         CO2         VOC  \\\n",
      "199592 2022-10-10 14:30:00  23.435455  51.505000  917.954545  459.636364   \n",
      "199593 2022-10-10 16:30:00  25.360000  44.336667  563.666667  555.000000   \n",
      "199594 2022-10-10 17:00:00  25.486667  45.230000  612.333333  607.333333   \n",
      "199595 2022-10-10 18:30:00  25.510000  48.355000  596.000000  657.000000   \n",
      "199596 2022-10-10 19:30:00  25.240000  49.470000  603.000000  599.000000   \n",
      "...                    ...        ...        ...         ...         ...   \n",
      "308834 2023-09-26 19:00:00  27.620000  36.770000  513.000000  919.000000   \n",
      "308835 2023-09-26 22:00:00  27.435000  37.415000  522.500000  957.500000   \n",
      "308836 2023-09-26 22:30:00  27.380000  37.510000  527.500000  958.500000   \n",
      "308837 2023-09-26 23:00:00  27.370000  37.580000  524.500000  949.000000   \n",
      "308838 2023-09-26 23:30:00  27.345000  37.630000  527.000000  955.000000   \n",
      "\n",
      "               vis         IR      WIFI        BLE       rssi  ...  \\\n",
      "199592  249.136364  30.272727  0.954545   1.272727 -72.136364  ...   \n",
      "199593  115.000000  12.666667  1.000000   2.000000 -59.000000  ...   \n",
      "199594  151.333333  16.000000  0.333333   0.000000 -56.333333  ...   \n",
      "199595  153.500000  16.000000  1.000000   0.000000 -61.000000  ...   \n",
      "199596    9.000000   1.000000  0.000000   0.000000 -62.500000  ...   \n",
      "...            ...        ...       ...        ...        ...  ...   \n",
      "308834    5.000000   0.000000  3.500000  13.500000 -74.000000  ...   \n",
      "308835    4.000000   1.000000  3.500000  13.500000 -74.000000  ...   \n",
      "308836    5.500000   2.000000  1.000000   0.000000 -73.000000  ...   \n",
      "308837    5.500000   2.500000  1.500000   0.000000 -72.500000  ...   \n",
      "308838    4.000000   0.000000  3.000000  13.500000 -75.000000  ...   \n",
      "\n",
      "        device_id_hka-aqm-am201a  device_id_hka-aqm-am201b  \\\n",
      "199592                         0                         0   \n",
      "199593                         0                         0   \n",
      "199594                         0                         0   \n",
      "199595                         0                         0   \n",
      "199596                         0                         0   \n",
      "...                          ...                       ...   \n",
      "308834                         0                         0   \n",
      "308835                         0                         0   \n",
      "308836                         0                         0   \n",
      "308837                         0                         0   \n",
      "308838                         0                         0   \n",
      "\n",
      "        device_id_hka-aqm-am204  device_id_hka-aqm-am205  \\\n",
      "199592                        0                        0   \n",
      "199593                        0                        0   \n",
      "199594                        0                        0   \n",
      "199595                        0                        0   \n",
      "199596                        0                        0   \n",
      "...                         ...                      ...   \n",
      "308834                        0                        0   \n",
      "308835                        0                        0   \n",
      "308836                        0                        0   \n",
      "308837                        0                        0   \n",
      "308838                        0                        0   \n",
      "\n",
      "        device_id_hka-aqm-am209  device_id_hka-aqm-am210  \\\n",
      "199592                        0                        0   \n",
      "199593                        0                        0   \n",
      "199594                        0                        0   \n",
      "199595                        0                        0   \n",
      "199596                        0                        0   \n",
      "...                         ...                      ...   \n",
      "308834                        0                        0   \n",
      "308835                        0                        0   \n",
      "308836                        0                        0   \n",
      "308837                        0                        0   \n",
      "308838                        0                        0   \n",
      "\n",
      "        device_id_hka-aqm-am211  device_id_hka-aqm-am301  \\\n",
      "199592                        0                        0   \n",
      "199593                        0                        0   \n",
      "199594                        0                        0   \n",
      "199595                        0                        0   \n",
      "199596                        0                        0   \n",
      "...                         ...                      ...   \n",
      "308834                        0                        0   \n",
      "308835                        0                        0   \n",
      "308836                        0                        0   \n",
      "308837                        0                        0   \n",
      "308838                        0                        0   \n",
      "\n",
      "        device_id_hka-aqm-am307  device_id_hka-aqm-am308  \n",
      "199592                        0                        0  \n",
      "199593                        0                        0  \n",
      "199594                        0                        0  \n",
      "199595                        0                        0  \n",
      "199596                        0                        0  \n",
      "...                         ...                      ...  \n",
      "308834                        0                        1  \n",
      "308835                        0                        1  \n",
      "308836                        0                        1  \n",
      "308837                        0                        1  \n",
      "308838                        0                        1  \n",
      "\n",
      "[109247 rows x 50 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\t-ehm\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\transformer.py:286: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
      "c:\\Users\\t-ehm\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\optim\\lr_scheduler.py:28: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\"The verbose parameter is deprecated. Please use get_last_lr() \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          actual    predicted\n",
      "0    1143.500014  1025.778814\n",
      "1    1090.999987   924.835442\n",
      "2     896.000002   838.697884\n",
      "3     919.000000   677.811856\n",
      "4    1114.500006   685.822918\n",
      "..           ...          ...\n",
      "507   657.499996   632.289880\n",
      "508   704.499999   579.751937\n",
      "509   791.500000   594.960782\n",
      "510   780.000000   626.297782\n",
      "511   732.999999   620.102918\n",
      "\n",
      "[512 rows x 2 columns]\n",
      "Epoch 1/25, Training Loss: 0.2245\n",
      "Epoch 1/25, Validation Loss: 0.1496\n",
      "          actual    predicted\n",
      "0    1143.500014  1029.374072\n",
      "1    1090.999987   945.669928\n",
      "2     896.000002   881.983124\n",
      "3     919.000000   704.313916\n",
      "4    1114.500006   721.947369\n",
      "..           ...          ...\n",
      "507   657.499996   621.895706\n",
      "508   704.499999   568.092345\n",
      "509   791.500000   585.061922\n",
      "510   780.000000   629.690841\n",
      "511   732.999999   625.041586\n",
      "\n",
      "[512 rows x 2 columns]\n",
      "Epoch 2/25, Training Loss: 0.1078\n",
      "Epoch 2/25, Validation Loss: 0.1256\n",
      "          actual    predicted\n",
      "0    1143.500014  1049.591346\n",
      "1    1090.999987   970.914199\n",
      "2     896.000002   913.018071\n",
      "3     919.000000   724.587612\n",
      "4    1114.500006   744.739242\n",
      "..           ...          ...\n",
      "507   657.499996   595.811994\n",
      "508   704.499999   536.444354\n",
      "509   791.500000   559.366927\n",
      "510   780.000000   611.122020\n",
      "511   732.999999   605.592683\n",
      "\n",
      "[512 rows x 2 columns]\n",
      "Epoch 3/25, Training Loss: 0.0994\n",
      "Epoch 3/25, Validation Loss: 0.1050\n",
      "          actual    predicted\n",
      "0    1143.500014  1072.567412\n",
      "1    1090.999987   992.642087\n",
      "2     896.000002   926.772309\n",
      "3     919.000000   734.458045\n",
      "4    1114.500006   748.030793\n",
      "..           ...          ...\n",
      "507   657.499996   626.252007\n",
      "508   704.499999   560.659800\n",
      "509   791.500000   582.864981\n",
      "510   780.000000   639.354914\n",
      "511   732.999999   637.368635\n",
      "\n",
      "[512 rows x 2 columns]\n",
      "Epoch 4/25, Training Loss: 0.0908\n",
      "Epoch 4/25, Validation Loss: 0.0814\n",
      "          actual    predicted\n",
      "0    1143.500014  1150.482189\n",
      "1    1090.999987  1073.354227\n",
      "2     896.000002   992.531225\n",
      "3     919.000000   790.650022\n",
      "4    1114.500006   800.589380\n",
      "..           ...          ...\n",
      "507   657.499996   649.692187\n",
      "508   704.499999   565.548763\n",
      "509   791.500000   591.490883\n",
      "510   780.000000   661.819656\n",
      "511   732.999999   654.289861\n",
      "\n",
      "[512 rows x 2 columns]\n",
      "Epoch 5/25, Training Loss: 0.0880\n",
      "Epoch 5/25, Validation Loss: 0.0724\n",
      "          actual    predicted\n",
      "0    1143.500014  1137.312584\n",
      "1    1090.999987  1059.425049\n",
      "2     896.000002   998.364491\n",
      "3     919.000000   793.376724\n",
      "4    1114.500006   809.178428\n",
      "..           ...          ...\n",
      "507   657.499996   662.308216\n",
      "508   704.499999   574.492825\n",
      "509   791.500000   605.172670\n",
      "510   780.000000   675.690765\n",
      "511   732.999999   676.609011\n",
      "\n",
      "[512 rows x 2 columns]\n",
      "Epoch 6/25, Training Loss: 0.0861\n",
      "Epoch 6/25, Validation Loss: 0.0897\n",
      "          actual    predicted\n",
      "0    1143.500014  1176.037841\n",
      "1    1090.999987  1089.526970\n",
      "2     896.000002  1019.992155\n",
      "3     919.000000   816.862893\n",
      "4    1114.500006   831.122943\n",
      "..           ...          ...\n",
      "507   657.499996   662.398881\n",
      "508   704.499999   573.310319\n",
      "509   791.500000   608.933948\n",
      "510   780.000000   681.767200\n",
      "511   732.999999   672.581464\n",
      "\n",
      "[512 rows x 2 columns]\n",
      "Epoch 7/25, Training Loss: 0.0829\n",
      "Epoch 7/25, Validation Loss: 0.0798\n",
      "          actual    predicted\n",
      "0    1143.500014  1137.779788\n",
      "1    1090.999987  1054.685890\n",
      "2     896.000002   994.240181\n",
      "3     919.000000   768.940106\n",
      "4    1114.500006   790.049073\n",
      "..           ...          ...\n",
      "507   657.499996   665.329453\n",
      "508   704.499999   585.558934\n",
      "509   791.500000   615.084134\n",
      "510   780.000000   682.770075\n",
      "511   732.999999   673.059351\n",
      "\n",
      "[512 rows x 2 columns]\n",
      "Epoch 8/25, Training Loss: 0.0830\n",
      "Epoch 8/25, Validation Loss: 0.0709\n",
      "          actual    predicted\n",
      "0    1143.500014  1106.278009\n",
      "1    1090.999987  1030.374328\n",
      "2     896.000002   979.115982\n",
      "3     919.000000   786.725002\n",
      "4    1114.500006   809.663922\n",
      "..           ...          ...\n",
      "507   657.499996   678.333260\n",
      "508   704.499999   589.169380\n",
      "509   791.500000   622.231939\n",
      "510   780.000000   699.414119\n",
      "511   732.999999   692.844806\n",
      "\n",
      "[512 rows x 2 columns]\n",
      "Epoch 9/25, Training Loss: 0.0804\n",
      "Epoch 9/25, Validation Loss: 0.0652\n",
      "          actual    predicted\n",
      "0    1143.500014  1256.178181\n",
      "1    1090.999987  1183.515329\n",
      "2     896.000002  1126.134392\n",
      "3     919.000000   882.712304\n",
      "4    1114.500006   905.075300\n",
      "..           ...          ...\n",
      "507   657.499996   729.413958\n",
      "508   704.499999   623.194809\n",
      "509   791.500000   665.675183\n",
      "510   780.000000   743.749191\n",
      "511   732.999999   733.769604\n",
      "\n",
      "[512 rows x 2 columns]\n",
      "Epoch 10/25, Training Loss: 0.0791\n",
      "Epoch 10/25, Validation Loss: 0.0742\n",
      "          actual    predicted\n",
      "0    1143.500014  1048.782865\n",
      "1    1090.999987   983.281075\n",
      "2     896.000002   943.605534\n",
      "3     919.000000   744.335921\n",
      "4    1114.500006   763.574230\n",
      "..           ...          ...\n",
      "507   657.499996   664.511546\n",
      "508   704.499999   587.218025\n",
      "509   791.500000   615.774868\n",
      "510   780.000000   680.876674\n",
      "511   732.999999   674.436631\n",
      "\n",
      "[512 rows x 2 columns]\n",
      "Epoch 11/25, Training Loss: 0.0789\n",
      "Epoch 11/25, Validation Loss: 0.0649\n",
      "          actual    predicted\n",
      "0    1143.500014  1154.221376\n",
      "1    1090.999987  1069.530075\n",
      "2     896.000002  1019.647939\n",
      "3     919.000000   789.315409\n",
      "4    1114.500006   813.515742\n",
      "..           ...          ...\n",
      "507   657.499996   668.104840\n",
      "508   704.499999   585.148675\n",
      "509   791.500000   612.796246\n",
      "510   780.000000   675.159333\n",
      "511   732.999999   662.541897\n",
      "\n",
      "[512 rows x 2 columns]\n",
      "Epoch 12/25, Training Loss: 0.0775\n",
      "Epoch 12/25, Validation Loss: 0.0598\n",
      "          actual    predicted\n",
      "0    1143.500014  1202.215687\n",
      "1    1090.999987  1125.774741\n",
      "2     896.000002  1054.230334\n",
      "3     919.000000   819.827861\n",
      "4    1114.500006   840.901728\n",
      "..           ...          ...\n",
      "507   657.499996   685.608717\n",
      "508   704.499999   602.934734\n",
      "509   791.500000   632.262673\n",
      "510   780.000000   697.483271\n",
      "511   732.999999   686.771345\n",
      "\n",
      "[512 rows x 2 columns]\n",
      "Epoch 13/25, Training Loss: 0.0774\n",
      "Epoch 13/25, Validation Loss: 0.0528\n",
      "          actual    predicted\n",
      "0    1143.500014  1183.122505\n",
      "1    1090.999987  1110.792894\n",
      "2     896.000002  1054.628521\n",
      "3     919.000000   823.365445\n",
      "4    1114.500006   845.933216\n",
      "..           ...          ...\n",
      "507   657.499996   698.893742\n",
      "508   704.499999   616.928769\n",
      "509   791.500000   649.892281\n",
      "510   780.000000   709.014831\n",
      "511   732.999999   701.227326\n",
      "\n",
      "[512 rows x 2 columns]\n",
      "Epoch 14/25, Training Loss: 0.0757\n",
      "Epoch 14/25, Validation Loss: 0.0566\n",
      "          actual    predicted\n",
      "0    1143.500014  1159.699557\n",
      "1    1090.999987  1087.463638\n",
      "2     896.000002  1034.040320\n",
      "3     919.000000   830.278758\n",
      "4    1114.500006   848.589058\n",
      "..           ...          ...\n",
      "507   657.499996   699.492951\n",
      "508   704.499999   604.880070\n",
      "509   791.500000   643.895085\n",
      "510   780.000000   714.804853\n",
      "511   732.999999   700.874055\n",
      "\n",
      "[512 rows x 2 columns]\n",
      "Epoch 15/25, Training Loss: 0.0761\n",
      "Epoch 15/25, Validation Loss: 0.0517\n",
      "          actual    predicted\n",
      "0    1143.500014  1138.272906\n",
      "1    1090.999987  1070.979337\n",
      "2     896.000002  1019.344294\n",
      "3     919.000000   812.871901\n",
      "4    1114.500006   834.791143\n",
      "..           ...          ...\n",
      "507   657.499996   694.141847\n",
      "508   704.499999   604.352276\n",
      "509   791.500000   636.039439\n",
      "510   780.000000   711.691986\n",
      "511   732.999999   703.938555\n",
      "\n",
      "[512 rows x 2 columns]\n",
      "Epoch 16/25, Training Loss: 0.0756\n",
      "Epoch 16/25, Validation Loss: 0.0560\n",
      "          actual    predicted\n",
      "0    1143.500014  1157.893156\n",
      "1    1090.999987  1088.917626\n",
      "2     896.000002  1044.481119\n",
      "3     919.000000   823.887604\n",
      "4    1114.500006   847.556021\n",
      "..           ...          ...\n",
      "507   657.499996   710.439595\n",
      "508   704.499999   607.167623\n",
      "509   791.500000   644.972659\n",
      "510   780.000000   730.667260\n",
      "511   732.999999   715.313769\n",
      "\n",
      "[512 rows x 2 columns]\n",
      "Epoch 17/25, Training Loss: 0.0755\n",
      "Epoch 17/25, Validation Loss: 0.0579\n",
      "          actual    predicted\n",
      "0    1143.500014  1212.501636\n",
      "1    1090.999987  1145.709646\n",
      "2     896.000002  1087.870569\n",
      "3     919.000000   840.643194\n",
      "4    1114.500006   865.564455\n",
      "..           ...          ...\n",
      "507   657.499996   691.366221\n",
      "508   704.499999   601.285077\n",
      "509   791.500000   636.773186\n",
      "510   780.000000   707.138954\n",
      "511   732.999999   695.371111\n",
      "\n",
      "[512 rows x 2 columns]\n",
      "Epoch 18/25, Training Loss: 0.0750\n",
      "Epoch 18/25, Validation Loss: 0.0504\n",
      "          actual    predicted\n",
      "0    1143.500014  1190.525188\n",
      "1    1090.999987  1122.964580\n",
      "2     896.000002  1077.147915\n",
      "3     919.000000   838.478395\n",
      "4    1114.500006   867.518673\n",
      "..           ...          ...\n",
      "507   657.499996   726.480199\n",
      "508   704.499999   619.288542\n",
      "509   791.500000   659.522536\n",
      "510   780.000000   747.127832\n",
      "511   732.999999   730.423869\n",
      "\n",
      "[512 rows x 2 columns]\n",
      "Epoch 19/25, Training Loss: 0.0743\n",
      "Epoch 19/25, Validation Loss: 0.0503\n",
      "          actual    predicted\n",
      "0    1143.500014  1153.131659\n",
      "1    1090.999987  1085.146153\n",
      "2     896.000002  1032.484904\n",
      "3     919.000000   818.019056\n",
      "4    1114.500006   837.331459\n",
      "..           ...          ...\n",
      "507   657.499996   697.138807\n",
      "508   704.499999   610.493771\n",
      "509   791.500000   645.783813\n",
      "510   780.000000   717.233988\n",
      "511   732.999999   706.306408\n",
      "\n",
      "[512 rows x 2 columns]\n",
      "Epoch 20/25, Training Loss: 0.0740\n",
      "Epoch 20/25, Validation Loss: 0.0580\n",
      "          actual    predicted\n",
      "0    1143.500014  1157.852373\n",
      "1    1090.999987  1078.234942\n",
      "2     896.000002  1029.099351\n",
      "3     919.000000   786.119123\n",
      "4    1114.500006   810.200181\n",
      "..           ...          ...\n",
      "507   657.499996   680.026604\n",
      "508   704.499999   605.970973\n",
      "509   791.500000   634.312216\n",
      "510   780.000000   694.230273\n",
      "511   732.999999   686.573012\n",
      "\n",
      "[512 rows x 2 columns]\n",
      "Epoch 21/25, Training Loss: 0.0733\n",
      "Epoch 21/25, Validation Loss: 0.0528\n",
      "          actual    predicted\n",
      "0    1143.500014  1227.226072\n",
      "1    1090.999987  1165.338110\n",
      "2     896.000002  1109.396665\n",
      "3     919.000000   887.153447\n",
      "4    1114.500006   911.028916\n",
      "..           ...          ...\n",
      "507   657.499996   743.936212\n",
      "508   704.499999   640.238625\n",
      "509   791.500000   679.835936\n",
      "510   780.000000   762.469270\n",
      "511   732.999999   749.243798\n",
      "\n",
      "[512 rows x 2 columns]\n",
      "Epoch 22/25, Training Loss: 0.0737\n",
      "Epoch 22/25, Validation Loss: 0.0512\n",
      "          actual    predicted\n",
      "0    1143.500014  1191.255076\n",
      "1    1090.999987  1121.073852\n",
      "2     896.000002  1070.060295\n",
      "3     919.000000   841.133029\n",
      "4    1114.500006   869.336596\n",
      "..           ...          ...\n",
      "507   657.499996   737.944982\n",
      "508   704.499999   638.227759\n",
      "509   791.500000   676.020360\n",
      "510   780.000000   755.669034\n",
      "511   732.999999   746.906860\n",
      "\n",
      "[512 rows x 2 columns]\n",
      "Epoch 23/25, Training Loss: 0.0734\n",
      "Epoch 23/25, Validation Loss: 0.0529\n",
      "          actual    predicted\n",
      "0    1143.500014  1161.263735\n",
      "1    1090.999987  1099.399669\n",
      "2     896.000002  1041.983914\n",
      "3     919.000000   845.467509\n",
      "4    1114.500006   869.351881\n",
      "..           ...          ...\n",
      "507   657.499996   704.816309\n",
      "508   704.499999   612.833241\n",
      "509   791.500000   647.057118\n",
      "510   780.000000   721.154823\n",
      "511   732.999999   711.283948\n",
      "\n",
      "[512 rows x 2 columns]\n",
      "Epoch 24/25, Training Loss: 0.0710\n",
      "Epoch 24/25, Validation Loss: 0.0480\n",
      "          actual    predicted\n",
      "0    1143.500014  1201.093718\n",
      "1    1090.999987  1139.255106\n",
      "2     896.000002  1081.149238\n",
      "3     919.000000   857.540688\n",
      "4    1114.500006   878.781149\n",
      "..           ...          ...\n",
      "507   657.499996   735.381256\n",
      "508   704.499999   640.521949\n",
      "509   791.500000   675.926456\n",
      "510   780.000000   751.063594\n",
      "511   732.999999   743.223706\n",
      "\n",
      "[512 rows x 2 columns]\n",
      "Epoch 25/25, Training Loss: 0.0708\n",
      "Epoch 25/25, Validation Loss: 0.0450\n",
      "            actual    predicted\n",
      "0      1143.500014  1201.093718\n",
      "1      1090.999987  1139.255106\n",
      "2       896.000002  1081.149238\n",
      "3       919.000000   857.540688\n",
      "4      1114.500006   878.781149\n",
      "...            ...          ...\n",
      "38888   957.500000   963.811656\n",
      "38889   958.500008   964.762879\n",
      "38890   949.000006   959.032599\n",
      "38891   954.999999   948.823048\n",
      "38892   951.000004   966.900078\n",
      "\n",
      "[38893 rows x 2 columns]\n",
      "Score (RMSE): 63.0100\n",
      "Score (MAE): 33.9577\n",
      "Score (MAPE): 4.4430%\n"
     ]
    }
   ],
   "source": [
    "importlib.reload(utils)\n",
    "performance_df = pd.read_csv('model_performances.csv')\n",
    "d_model=128\n",
    "nhead=8\n",
    "num_layers=4\n",
    "dropout=0.1\n",
    "batch_size=512\n",
    "learning_rate=0.00031\n",
    "epochs=25\n",
    "for aggregation_level in ['hour', 'half_hour']:\n",
    "    for y_feature in ['CO2', 'hum', 'tmp', 'vis', 'VOC']:\n",
    "        model, scaler, rmse, mae, mape = utils.create_multivariate_transformer_model_for_feature(df, d_model=d_model, nhead=nhead, num_layers=num_layers, dropout=dropout, batch_size=batch_size, learning_rate=learning_rate, epochs=epochs, y_feature=y_feature, aggregation_level=aggregation_level)\n",
    "        performance_df = performance_df.append({'model_name': 'multivariate_transformer','aggregation_level': aggregation_level, 'y_feature': y_feature, 'rmse': rmse, 'mae': mae, 'mape': mape, 'd_model': d_model, 'nhead': nhead, 'num_layers': num_layers, 'dropout': dropout, 'batch_size': batch_size, 'learning_rate': learning_rate, 'epochs': epochs, 'note': ''}, ignore_index=True)\n",
    "\n",
    "performance_df.to_csv('model_performances.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "transformer_multivariate_quarter_hour_vis_columns_v1.csv\n",
      "transformer_multivariate_quarter_hour_tmp_model_v1.pth\n",
      "transformer_multivariate_half_hour_tmp_columns_v1.csv\n",
      "transformer_multivariate_hour_vis_columns_v1.csv\n",
      "transformer_model_tmp_v1.pth\n",
      "transformer_multivariate_hour_hum_model_v1.pth\n",
      ".DS_v1\n",
      "renaming .DS_v1 to .DS_v1.DS_v1\n",
      "transformer_multivariate_hour_vis_scaler_v1.pth\n",
      "transformer_multivariate_hour_vis_model_v1.pth\n",
      "transformer_multivariate_hour_tmp_columns_v1.csv\n",
      "transformer_scaler_tmp_v1.pth\n",
      "transformer_multivariate_half_hour_CO2_model_v1.pth\n",
      "transformer_multivariate_half_hour_hum_scaler_v1.pth\n",
      "transformer_multivariate_quarter_hour_CO2_model_v1.pth\n",
      "transformer_multivariate_quarter_hour_hum_columns_v1.csv\n",
      "transformer_multivariate_hour_hum_columns_v1.csv\n",
      "transformer_multivariate_quarter_hour_CO2_scaler_v1.pth\n",
      "transformer_multivariate_quarter_hour_vis_model_v1.pth\n",
      "transformer_multivariate_hour_tmp_scaler_v1.pth\n",
      "transformer_multivariate_half_hour_VOC_columns_v1.csv\n",
      "transformer_multivariate_quarter_hour_tmp_columns_v1.csv\n",
      "transformer_multivariate_quarter_hour_vis_scaler_v1.pth\n",
      "transformer_multivariate_quarter_hour_VOC_model_v1.pth\n",
      "transformer_model_VOC_v1.pth\n",
      "transformer_multivariate_half_hour_vis_columns_v1.csv\n",
      "transformer_multivariate_hour_VOC_model_v1.pth\n",
      "transformer_scaler_v1.pth\n",
      "deleting transformer_scaler_tmp_v1.pth\n",
      "transformer_multivariate_hour_VOC_scaler_v2.pth\n",
      "deleting transformer_multivariate_hour_VOC_scaler_v1.pth\n",
      "renaming transformer_multivariate_hour_VOC_scaler_v2.pth to transformer_multivariate_hour_VOC_scaler_v1.pth\n",
      "transformer_multivariate_hour_CO2_model_v3.pth\n",
      "deleting transformer_multivariate_hour_CO2_model_v1.pth\n",
      "deleting transformer_multivariate_hour_CO2_model_v2.pth\n",
      "renaming transformer_multivariate_hour_CO2_model_v3.pth to transformer_multivariate_hour_CO2_model_v1.pth\n",
      "transformer_multivariate_quarter_hour_VOC_scaler_v2.pth\n",
      "deleting transformer_multivariate_quarter_hour_VOC_scaler_v1.pth\n",
      "renaming transformer_multivariate_quarter_hour_VOC_scaler_v2.pth to transformer_multivariate_quarter_hour_VOC_scaler_v1.pth\n",
      "transformer_multivariate_half_hour_tmp_scaler_v2.pth\n",
      "deleting transformer_multivariate_half_hour_tmp_scaler_v1.pth\n",
      "renaming transformer_multivariate_half_hour_tmp_scaler_v2.pth to transformer_multivariate_half_hour_tmp_scaler_v1.pth\n",
      "transformer_multivariate_quarter_hour_hum_model_v2.pth\n",
      "deleting transformer_multivariate_quarter_hour_hum_model_v1.pth\n",
      "renaming transformer_multivariate_quarter_hour_hum_model_v2.pth to transformer_multivariate_quarter_hour_hum_model_v1.pth\n",
      "transformer_model_hum_v1.pth\n",
      "transformer_model_v1.pth\n",
      "deleting transformer_model_CO2_v1.pth\n",
      "deleting transformer_model_VOC_v1.pth\n",
      "deleting transformer_model_hum_v1.pth\n",
      "deleting transformer_model_tmp_v1.pth\n",
      "transformer_multivariate_hour_VOC_columns_v1.csv\n",
      "transformer_multivariate_half_hour_CO2_columns_v1.csv\n",
      "transformer_multivariate_half_hour_CO2_scaler_v3.pth\n",
      "deleting transformer_multivariate_half_hour_CO2_scaler_v1.pth\n",
      "deleting transformer_multivariate_half_hour_CO2_scaler_v2.pth\n",
      "renaming transformer_multivariate_half_hour_CO2_scaler_v3.pth to transformer_multivariate_half_hour_CO2_scaler_v1.pth\n",
      "transformer_multivariate_quarter_hour_hum_scaler_v2.pth\n",
      "deleting transformer_multivariate_quarter_hour_hum_scaler_v1.pth\n",
      "renaming transformer_multivariate_quarter_hour_hum_scaler_v2.pth to transformer_multivariate_quarter_hour_hum_scaler_v1.pth\n",
      "transformer_multivariate_half_hour_hum_model_v2.pth\n",
      "deleting transformer_multivariate_half_hour_hum_model_v1.pth\n",
      "renaming transformer_multivariate_half_hour_hum_model_v2.pth to transformer_multivariate_half_hour_hum_model_v1.pth\n",
      "transformer_multivariate_half_hour_tmp_model_v2.pth\n",
      "deleting transformer_multivariate_half_hour_tmp_model_v1.pth\n",
      "renaming transformer_multivariate_half_hour_tmp_model_v2.pth to transformer_multivariate_half_hour_tmp_model_v1.pth\n",
      "transformer_multivariate_hour_hum_scaler_v2.pth\n",
      "deleting transformer_multivariate_hour_hum_scaler_v1.pth\n",
      "renaming transformer_multivariate_hour_hum_scaler_v2.pth to transformer_multivariate_hour_hum_scaler_v1.pth\n",
      "transformer_multivariate_half_hour_vis_model_v2.pth\n",
      "deleting transformer_multivariate_half_hour_vis_model_v1.pth\n",
      "renaming transformer_multivariate_half_hour_vis_model_v2.pth to transformer_multivariate_half_hour_vis_model_v1.pth\n",
      "transformer_multivariate_half_hour_vis_scaler_v2.pth\n",
      "deleting transformer_multivariate_half_hour_vis_scaler_v1.pth\n",
      "renaming transformer_multivariate_half_hour_vis_scaler_v2.pth to transformer_multivariate_half_hour_vis_scaler_v1.pth\n",
      "transformer_multivariate_quarter_hour_VOC_columns_v1.csv\n",
      "transformer_multivariate_half_hour_hum_columns_v1.csv\n",
      "transformer_multivariate_hour_tmp_model_v2.pth\n",
      "deleting transformer_multivariate_hour_tmp_model_v1.pth\n",
      "renaming transformer_multivariate_hour_tmp_model_v2.pth to transformer_multivariate_hour_tmp_model_v1.pth\n",
      "transformer_multivariate_quarter_hour_CO2_columns_v2.csv\n",
      "deleting transformer_multivariate_quarter_hour_CO2_columns_v1.pkl\n",
      "renaming transformer_multivariate_quarter_hour_CO2_columns_v2.csv to transformer_multivariate_quarter_hour_CO2_columns_v1.csv\n",
      "transformer_multivariate_quarter_hour_tmp_scaler_v2.pth\n",
      "deleting transformer_multivariate_quarter_hour_tmp_scaler_v1.pth\n",
      "renaming transformer_multivariate_quarter_hour_tmp_scaler_v2.pth to transformer_multivariate_quarter_hour_tmp_scaler_v1.pth\n",
      "transformer_model_CO2_v1.pth\n",
      "transformer_multivariate_half_hour_VOC_model_v2.pth\n",
      "deleting transformer_multivariate_half_hour_VOC_model_v1.pth\n",
      "renaming transformer_multivariate_half_hour_VOC_model_v2.pth to transformer_multivariate_half_hour_VOC_model_v1.pth\n",
      "transformer_multivariate_half_hour_VOC_scaler_v2.pth\n",
      "deleting transformer_multivariate_half_hour_VOC_scaler_v1.pth\n",
      "renaming transformer_multivariate_half_hour_VOC_scaler_v2.pth to transformer_multivariate_half_hour_VOC_scaler_v1.pth\n",
      "transformer_multivariate_hour_CO2_columns_v1.csv\n",
      "transformer_multivariate_hour_CO2_scaler_v3.pth\n",
      "deleting transformer_multivariate_hour_CO2_scaler_v1.pth\n",
      "deleting transformer_multivariate_hour_CO2_scaler_v2.pth\n",
      "renaming transformer_multivariate_hour_CO2_scaler_v3.pth to transformer_multivariate_hour_CO2_scaler_v1.pth\n"
     ]
    }
   ],
   "source": [
    "all_model_files = [f for f in os.listdir('models/')]\n",
    "all_model_files_no_version = [f.rsplit('_', 1)[0] for f in all_model_files]\n",
    "all_model_files_no_version_unique = list(set(all_model_files_no_version))\n",
    "all_model_files_no_version_unique\n",
    "for model_file in all_model_files_no_version_unique:\n",
    "    model_files = [f for f in all_model_files if f.startswith(model_file)]\n",
    "    model_files.sort()\n",
    "    latest_model_file = model_files[-1]\n",
    "    print(latest_model_file)\n",
    "    # delete all other versions\n",
    "    for model_file_to_delete in model_files[:-1]:\n",
    "        print('deleting ' + model_file_to_delete)\n",
    "        os.remove('models/' + model_file_to_delete)\n",
    "    # rename latest model file to v1\n",
    "    file_ending = latest_model_file.rsplit('.', 1)[1]\n",
    "    latest_model_file_rename = latest_model_file.rsplit('_', 1)[0] + '_v1' + '.' + file_ending\n",
    "    if latest_model_file != latest_model_file_rename:\n",
    "        print('renaming ' + latest_model_file + ' to ' + latest_model_file_rename)\n",
    "        os.rename('models/' + latest_model_file, 'models/' + model_file + '_v1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training data cutoff:  2023-07-15 02:45:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/timehmann/Library/Mobile Documents/com~apple~CloudDocs/Studium/Data_Science_Karlsruhe/Data_Science_Semester6/Internet_Of_Things/IoT_Project/utils.py:868: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  feature_count = x[0].shape[1]\n",
      "/Users/timehmann/Library/Mobile Documents/com~apple~CloudDocs/Studium/Data_Science_Karlsruhe/Data_Science_Semester6/Internet_Of_Things/IoT_Project/utils.py:869: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  print(\"feature count: \", feature_count)\n",
      "/Users/timehmann/Library/Mobile Documents/com~apple~CloudDocs/Studium/Data_Science_Karlsruhe/Data_Science_Semester6/Internet_Of_Things/IoT_Project/utils.py:873: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  x_test, y_test = to_sequences(window_size, df_test)\n",
      "/Users/timehmann/Library/Mobile Documents/com~apple~CloudDocs/Studium/Data_Science_Karlsruhe/Data_Science_Semester6/Internet_Of_Things/IoT_Project/utils.py:874: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tmp                         float64\n",
      "hum                         float64\n",
      "CO2                         float64\n",
      "VOC                         float64\n",
      "vis                         float64\n",
      "IR                          float64\n",
      "WIFI                        float64\n",
      "BLE                         float64\n",
      "rssi                        float64\n",
      "channel_rssi                float64\n",
      "channel_index               float64\n",
      "spreading_factor            float64\n",
      "bandwidth                   float64\n",
      "f_cnt                       float64\n",
      "isHoliday                   float64\n",
      "isExamTime                  float64\n",
      "weekday                     float64\n",
      "month                       float64\n",
      "hour_sin                    float64\n",
      "semester_SS23               float64\n",
      "semester_WS22/23            float64\n",
      "semester_WS23/24            float64\n",
      "group                       float64\n",
      "device_id_hka-aqm-am001     float64\n",
      "device_id_hka-aqm-am002     float64\n",
      "device_id_hka-aqm-am003a    float64\n",
      "device_id_hka-aqm-am003b    float64\n",
      "device_id_hka-aqm-am004     float64\n",
      "device_id_hka-aqm-am005     float64\n",
      "device_id_hka-aqm-am107     float64\n",
      "device_id_hka-aqm-am109     float64\n",
      "device_id_hka-aqm-am110     float64\n",
      "device_id_hka-aqm-am111     float64\n",
      "device_id_hka-aqm-am115     float64\n",
      "device_id_hka-aqm-am116     float64\n",
      "device_id_hka-aqm-am117     float64\n",
      "device_id_hka-aqm-am123     float64\n",
      "device_id_hka-aqm-am124     float64\n",
      "device_id_hka-aqm-am126     float64\n",
      "device_id_hka-aqm-am201a    float64\n",
      "device_id_hka-aqm-am201b    float64\n",
      "device_id_hka-aqm-am204     float64\n",
      "device_id_hka-aqm-am205     float64\n",
      "device_id_hka-aqm-am209     float64\n",
      "device_id_hka-aqm-am210     float64\n",
      "device_id_hka-aqm-am211     float64\n",
      "device_id_hka-aqm-am301     float64\n",
      "device_id_hka-aqm-am307     float64\n",
      "device_id_hka-aqm-am308     float64\n",
      "dtype: object\n",
      "feature count:  49\n",
      "feature count:  49\n",
      "Training data shape: torch.Size([244176, 20, 49]) torch.Size([244176, 1])\n",
      "Testing data shape: torch.Size([62745, 20, 49]) torch.Size([62745, 1])\n",
      "         actual   predicted\n",
      "0    466.999999  487.585348\n",
      "1    455.999999  489.097007\n",
      "2    455.999999  484.258748\n",
      "3    437.999999  482.026215\n",
      "4    435.000001  467.013061\n",
      "..          ...         ...\n",
      "123  446.999999  460.052533\n",
      "124  436.999998  470.577530\n",
      "125  446.999999  458.449503\n",
      "126  450.000002  472.874027\n",
      "127  445.000002  472.476152\n",
      "\n",
      "[128 rows x 2 columns]\n",
      "Epoch 1/2, Validation Loss: 0.0735\n",
      "         actual   predicted\n",
      "0    466.999999  529.322873\n",
      "1    455.999999  531.530266\n",
      "2    455.999999  510.827987\n",
      "3    437.999999  503.703505\n",
      "4    435.000001  472.199065\n",
      "..          ...         ...\n",
      "123  446.999999  479.487189\n",
      "124  436.999998  498.077639\n",
      "125  446.999999  475.978976\n",
      "126  450.000002  494.600295\n",
      "127  445.000002  495.114179\n",
      "\n",
      "[128 rows x 2 columns]\n",
      "Epoch 2/2, Validation Loss: 0.0770\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'NoneType' object cannot be interpreted as an integer",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m importlib\u001b[38;5;241m.\u001b[39mreload(utils)\n\u001b[0;32m----> 2\u001b[0m model, scaler, rmse, mae, mape \u001b[38;5;241m=\u001b[39m utils\u001b[38;5;241m.\u001b[39mcreate_multivariate_transformer_model_for_feature(df, d_model\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m128\u001b[39m, nhead\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m8\u001b[39m, num_layers\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m4\u001b[39m, dropout\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.1\u001b[39m, batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m128\u001b[39m, learning_rate\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.00025\u001b[39m, epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)\n",
      "File \u001b[0;32m~/Library/Mobile Documents/com~apple~CloudDocs/Studium/Data_Science_Karlsruhe/Data_Science_Semester6/Internet_Of_Things/IoT_Project/utils.py:954\u001b[0m, in \u001b[0;36mcreate_multivariate_transformer_model_for_feature\u001b[0;34m(df, y_feature, aggregation_level, device, window_size, batch_size, epochs, clean_data, input_dim, d_model, nhead, num_layers, dropout, learning_rate, drop_columns)\u001b[0m\n\u001b[1;32m    951\u001b[0m save_columns(full_preprocessed_df_unscaled, y_feature\u001b[38;5;241m=\u001b[39my_feature, model_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtransformer_multivariate_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00maggregation_level\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    953\u001b[0m \u001b[38;5;66;03m# Evaluate the model\u001b[39;00m\n\u001b[0;32m--> 954\u001b[0m rmse, mae, mape \u001b[38;5;241m=\u001b[39m evaluate_transformer_model(device, test_loader, model, scaler, y_test, y_feature_scaler_index\u001b[38;5;241m=\u001b[39my_feature_scaler_index, input_dim\u001b[38;5;241m=\u001b[39minput_dim)\n\u001b[1;32m    956\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m model, scaler, rmse, mae, mape\n",
      "File \u001b[0;32m~/Library/Mobile Documents/com~apple~CloudDocs/Studium/Data_Science_Karlsruhe/Data_Science_Semester6/Internet_Of_Things/IoT_Project/utils.py:464\u001b[0m, in \u001b[0;36mevaluate_transformer_model\u001b[0;34m(device, test_loader, model, scaler, y_test, y_feature_scaler_index, input_dim)\u001b[0m\n\u001b[1;32m    462\u001b[0m actual_batch \u001b[38;5;241m=\u001b[39m y_batch\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mnumpy()\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m    463\u001b[0m predicted_batch \u001b[38;5;241m=\u001b[39m outputs\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mnumpy()\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m--> 464\u001b[0m zeroes_for_scaler \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mzeros((actual_batch\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m], input_dim))\n\u001b[1;32m    466\u001b[0m zeroes_for_scaler[:, y_feature_scaler_index] \u001b[38;5;241m=\u001b[39m actual_batch\u001b[38;5;241m.\u001b[39mflatten()  \u001b[38;5;66;03m# Insert CO2 values into the correct column\u001b[39;00m\n\u001b[1;32m    467\u001b[0m inverse_transformed \u001b[38;5;241m=\u001b[39m scaler\u001b[38;5;241m.\u001b[39minverse_transform(zeroes_for_scaler)\n",
      "\u001b[0;31mTypeError\u001b[0m: 'NoneType' object cannot be interpreted as an integer"
     ]
    }
   ],
   "source": [
    "importlib.reload(utils)\n",
    "model, scaler, rmse, mae, mape = utils.create_multivariate_transformer_model_for_feature(df, d_model=128, nhead=8, num_layers=4, dropout=0.1, batch_size=128, learning_rate=0.00025, epochs=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data shape: torch.Size([150050, 47]) torch.Size([150050])\n",
      "Testing data shape: torch.Size([50023, 47]) torch.Size([50023])\n",
      "     actual  predicted\n",
      "0     408.0  477.67099\n",
      "1     410.0  477.67099\n",
      "2     406.5  477.67099\n",
      "3     410.5  477.67099\n",
      "4     413.5  477.67099\n",
      "..      ...        ...\n",
      "123   460.0  477.67099\n",
      "124   440.0  477.67099\n",
      "125   432.0  477.67099\n",
      "126   432.5  477.67099\n",
      "127   423.5  477.67099\n",
      "\n",
      "[128 rows x 2 columns]\n",
      "Epoch 1/1000, Validation Loss: 1.3423\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m importlib\u001b[38;5;241m.\u001b[39mreload(utils)\n\u001b[0;32m----> 2\u001b[0m model, scaler \u001b[38;5;241m=\u001b[39m utils\u001b[38;5;241m.\u001b[39mcreate_multivariate_model_for_feature(df, aggregation_level\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhalf_hour\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m~/Library/Mobile Documents/com~apple~CloudDocs/Studium/Data_Science_Karlsruhe/Data_Science_Semester6/Internet_Of_Things/IoT_Project/utils.py:725\u001b[0m, in \u001b[0;36mcreate_multivariate_model_for_feature\u001b[0;34m(df, y_feature, aggregation_level, device, window_size, epochs, clean_data, drop_columns)\u001b[0m\n\u001b[1;32m    723\u001b[0m train_dataset, test_dataset, train_loader, test_loader, scaler, y_test \u001b[38;5;241m=\u001b[39m get_data_for_multivariate_forecast(df, y_feature, window_size, aggregation_level, clean_data\u001b[38;5;241m=\u001b[39mclean_data, drop_columns\u001b[38;5;241m=\u001b[39mdrop_columns)\n\u001b[1;32m    724\u001b[0m \u001b[38;5;66;03m# Train the model\u001b[39;00m\n\u001b[0;32m--> 725\u001b[0m model \u001b[38;5;241m=\u001b[39m train_fcn_model(device, train_loader, test_loader, scaler, epochs)\n\u001b[1;32m    726\u001b[0m \u001b[38;5;66;03m# Evaluate the model\u001b[39;00m\n\u001b[1;32m    727\u001b[0m \u001b[38;5;66;03m#evaluate_transformer_model(device, test_loader, model, scaler, y_test)\u001b[39;00m\n\u001b[1;32m    728\u001b[0m \u001b[38;5;66;03m# Save the model and the scaler\u001b[39;00m\n\u001b[1;32m    729\u001b[0m \u001b[38;5;66;03m#save_model(model, y_feature=y_feature)\u001b[39;00m\n\u001b[1;32m    730\u001b[0m \u001b[38;5;66;03m#save_scaler(scaler, y_feature=y_feature)\u001b[39;00m\n\u001b[1;32m    732\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m model, scaler\n",
      "File \u001b[0;32m~/Library/Mobile Documents/com~apple~CloudDocs/Studium/Data_Science_Karlsruhe/Data_Science_Semester6/Internet_Of_Things/IoT_Project/utils.py:372\u001b[0m, in \u001b[0;36mtrain_fcn_model\u001b[0;34m(device, train_loader, test_loader, scaler, epochs)\u001b[0m\n\u001b[1;32m    370\u001b[0m     loss \u001b[38;5;241m=\u001b[39m criterion(outputs, y_batch\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m1\u001b[39m))  \u001b[38;5;66;03m# Add unsqueeze to match target size\u001b[39;00m\n\u001b[1;32m    371\u001b[0m     loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[0;32m--> 372\u001b[0m     optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m    374\u001b[0m \u001b[38;5;66;03m# Validation\u001b[39;00m\n\u001b[1;32m    375\u001b[0m model\u001b[38;5;241m.\u001b[39meval()\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/torch/optim/optimizer.py:280\u001b[0m, in \u001b[0;36mOptimizer.profile_hook_step.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    276\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    277\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must return None or a tuple of (new_args, new_kwargs),\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    278\u001b[0m                                \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbut got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresult\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 280\u001b[0m out \u001b[38;5;241m=\u001b[39m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    281\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_optimizer_step_code()\n\u001b[1;32m    283\u001b[0m \u001b[38;5;66;03m# call optimizer step post hooks\u001b[39;00m\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/torch/optim/optimizer.py:33\u001b[0m, in \u001b[0;36m_use_grad_for_differentiable.<locals>._use_grad\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     32\u001b[0m     torch\u001b[38;5;241m.\u001b[39mset_grad_enabled(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdefaults[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdifferentiable\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m---> 33\u001b[0m     ret \u001b[38;5;241m=\u001b[39m func(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m     34\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     35\u001b[0m     torch\u001b[38;5;241m.\u001b[39mset_grad_enabled(prev_grad)\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/torch/optim/adam.py:141\u001b[0m, in \u001b[0;36mAdam.step\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m    130\u001b[0m     beta1, beta2 \u001b[38;5;241m=\u001b[39m group[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbetas\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m    132\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_init_group(\n\u001b[1;32m    133\u001b[0m         group,\n\u001b[1;32m    134\u001b[0m         params_with_grad,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    138\u001b[0m         max_exp_avg_sqs,\n\u001b[1;32m    139\u001b[0m         state_steps)\n\u001b[0;32m--> 141\u001b[0m     adam(\n\u001b[1;32m    142\u001b[0m         params_with_grad,\n\u001b[1;32m    143\u001b[0m         grads,\n\u001b[1;32m    144\u001b[0m         exp_avgs,\n\u001b[1;32m    145\u001b[0m         exp_avg_sqs,\n\u001b[1;32m    146\u001b[0m         max_exp_avg_sqs,\n\u001b[1;32m    147\u001b[0m         state_steps,\n\u001b[1;32m    148\u001b[0m         amsgrad\u001b[38;5;241m=\u001b[39mgroup[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mamsgrad\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[1;32m    149\u001b[0m         beta1\u001b[38;5;241m=\u001b[39mbeta1,\n\u001b[1;32m    150\u001b[0m         beta2\u001b[38;5;241m=\u001b[39mbeta2,\n\u001b[1;32m    151\u001b[0m         lr\u001b[38;5;241m=\u001b[39mgroup[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlr\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[1;32m    152\u001b[0m         weight_decay\u001b[38;5;241m=\u001b[39mgroup[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mweight_decay\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[1;32m    153\u001b[0m         eps\u001b[38;5;241m=\u001b[39mgroup[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124meps\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[1;32m    154\u001b[0m         maximize\u001b[38;5;241m=\u001b[39mgroup[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmaximize\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[1;32m    155\u001b[0m         foreach\u001b[38;5;241m=\u001b[39mgroup[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mforeach\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[1;32m    156\u001b[0m         capturable\u001b[38;5;241m=\u001b[39mgroup[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcapturable\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[1;32m    157\u001b[0m         differentiable\u001b[38;5;241m=\u001b[39mgroup[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdifferentiable\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[1;32m    158\u001b[0m         fused\u001b[38;5;241m=\u001b[39mgroup[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfused\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[1;32m    159\u001b[0m         grad_scale\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgrad_scale\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[1;32m    160\u001b[0m         found_inf\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfound_inf\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[1;32m    161\u001b[0m     )\n\u001b[1;32m    163\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m loss\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/torch/optim/adam.py:281\u001b[0m, in \u001b[0;36madam\u001b[0;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, foreach, capturable, differentiable, fused, grad_scale, found_inf, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize)\u001b[0m\n\u001b[1;32m    278\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    279\u001b[0m     func \u001b[38;5;241m=\u001b[39m _single_tensor_adam\n\u001b[0;32m--> 281\u001b[0m func(params,\n\u001b[1;32m    282\u001b[0m      grads,\n\u001b[1;32m    283\u001b[0m      exp_avgs,\n\u001b[1;32m    284\u001b[0m      exp_avg_sqs,\n\u001b[1;32m    285\u001b[0m      max_exp_avg_sqs,\n\u001b[1;32m    286\u001b[0m      state_steps,\n\u001b[1;32m    287\u001b[0m      amsgrad\u001b[38;5;241m=\u001b[39mamsgrad,\n\u001b[1;32m    288\u001b[0m      beta1\u001b[38;5;241m=\u001b[39mbeta1,\n\u001b[1;32m    289\u001b[0m      beta2\u001b[38;5;241m=\u001b[39mbeta2,\n\u001b[1;32m    290\u001b[0m      lr\u001b[38;5;241m=\u001b[39mlr,\n\u001b[1;32m    291\u001b[0m      weight_decay\u001b[38;5;241m=\u001b[39mweight_decay,\n\u001b[1;32m    292\u001b[0m      eps\u001b[38;5;241m=\u001b[39meps,\n\u001b[1;32m    293\u001b[0m      maximize\u001b[38;5;241m=\u001b[39mmaximize,\n\u001b[1;32m    294\u001b[0m      capturable\u001b[38;5;241m=\u001b[39mcapturable,\n\u001b[1;32m    295\u001b[0m      differentiable\u001b[38;5;241m=\u001b[39mdifferentiable,\n\u001b[1;32m    296\u001b[0m      grad_scale\u001b[38;5;241m=\u001b[39mgrad_scale,\n\u001b[1;32m    297\u001b[0m      found_inf\u001b[38;5;241m=\u001b[39mfound_inf)\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/torch/optim/adam.py:391\u001b[0m, in \u001b[0;36m_single_tensor_adam\u001b[0;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, grad_scale, found_inf, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize, capturable, differentiable)\u001b[0m\n\u001b[1;32m    389\u001b[0m     denom \u001b[38;5;241m=\u001b[39m (max_exp_avg_sqs[i]\u001b[38;5;241m.\u001b[39msqrt() \u001b[38;5;241m/\u001b[39m bias_correction2_sqrt)\u001b[38;5;241m.\u001b[39madd_(eps)\n\u001b[1;32m    390\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 391\u001b[0m     denom \u001b[38;5;241m=\u001b[39m (exp_avg_sq\u001b[38;5;241m.\u001b[39msqrt() \u001b[38;5;241m/\u001b[39m bias_correction2_sqrt)\u001b[38;5;241m.\u001b[39madd_(eps)\n\u001b[1;32m    393\u001b[0m param\u001b[38;5;241m.\u001b[39maddcdiv_(exp_avg, denom, value\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39mstep_size)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "importlib.reload(utils)\n",
    "model, scaler = utils.create_multivariate_model_for_feature(df, aggregation_level='half_hour')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['tmp', 'hum', 'CO2', 'VOC', 'vis', 'IR', 'WIFI', 'BLE', 'rssi',\n",
       "       'channel_rssi', 'channel_index', 'spreading_factor', 'bandwidth',\n",
       "       'f_cnt', 'isHoliday', 'isExamTime', 'weekday', 'month', 'hour_sin',\n",
       "       'semester_SS23', 'semester_WS22/23', 'semester_WS23/24', 'tmp_lag_1',\n",
       "       'tmp_lag_2', 'tmp_lag_3', 'tmp_lag_4', 'tmp_lag_5', 'hum_lag_1',\n",
       "       'hum_lag_2', 'hum_lag_3', 'hum_lag_4', 'hum_lag_5', 'CO2_lag_1',\n",
       "       'CO2_lag_2', 'CO2_lag_3', 'CO2_lag_4', 'CO2_lag_5', 'CO2_next',\n",
       "       'VOC_lag_1', 'VOC_lag_2', 'VOC_lag_3', 'VOC_lag_4', 'VOC_lag_5',\n",
       "       'vis_lag_1', 'vis_lag_2', 'vis_lag_3', 'vis_lag_4', 'vis_lag_5',\n",
       "       'CO2_next_scaled'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading latest scaler: models/transformer_multivariate_quarter_hour_CO2_scaler_v1.pth\n",
      "loading latest model: models/transformer_multivariate_quarter_hour_CO2_model_v1.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date_time_rounded</th>\n",
       "      <th>CO2_pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2022-11-03 00:00:00</td>\n",
       "      <td>458.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2022-11-03 00:15:00</td>\n",
       "      <td>457.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2022-11-03 00:30:00</td>\n",
       "      <td>463.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2022-11-03 00:45:00</td>\n",
       "      <td>462.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2022-11-03 01:00:00</td>\n",
       "      <td>459.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>2022-11-03 22:45:00</td>\n",
       "      <td>461.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>2022-11-03 23:00:00</td>\n",
       "      <td>461.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>2022-11-03 23:15:00</td>\n",
       "      <td>461.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>2022-11-03 23:30:00</td>\n",
       "      <td>461.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>2022-11-03 23:45:00</td>\n",
       "      <td>461.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>96 rows  2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     date_time_rounded  CO2_pred\n",
       "0  2022-11-03 00:00:00     458.0\n",
       "1  2022-11-03 00:15:00     457.0\n",
       "2  2022-11-03 00:30:00     463.0\n",
       "3  2022-11-03 00:45:00     462.0\n",
       "4  2022-11-03 01:00:00     459.0\n",
       "..                 ...       ...\n",
       "91 2022-11-03 22:45:00     461.0\n",
       "92 2022-11-03 23:00:00     461.0\n",
       "93 2022-11-03 23:15:00     461.0\n",
       "94 2022-11-03 23:30:00     461.0\n",
       "95 2022-11-03 23:45:00     461.0\n",
       "\n",
       "[96 rows x 2 columns]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "importlib.reload(utils)\n",
    "start_time = datetime.strptime('2022-11-03 10:00:00', '%Y-%m-%d %H:%M:%S')\n",
    "predictions = utils.predict_data_multivariate_transformer(start_time=start_time, selected_room='am001', prediction_count=5)\n",
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['date_time_rounded', 'tmp', 'hum', 'CO2', 'VOC', 'vis', 'IR', 'WIFI',\n",
       "       'BLE', 'rssi', 'channel_rssi', 'channel_index', 'spreading_factor',\n",
       "       'bandwidth', 'f_cnt', 'isHoliday', 'isExamTime', 'weekday', 'month',\n",
       "       'hour_sin', 'semester_SS23', 'semester_WS22/23', 'semester_WS23/24',\n",
       "       'group', 'device_id_hka-aqm-am001', 'device_id_hka-aqm-am002',\n",
       "       'device_id_hka-aqm-am003a', 'device_id_hka-aqm-am003b',\n",
       "       'device_id_hka-aqm-am004', 'device_id_hka-aqm-am005',\n",
       "       'device_id_hka-aqm-am107', 'device_id_hka-aqm-am109',\n",
       "       'device_id_hka-aqm-am110', 'device_id_hka-aqm-am111',\n",
       "       'device_id_hka-aqm-am115', 'device_id_hka-aqm-am116',\n",
       "       'device_id_hka-aqm-am117', 'device_id_hka-aqm-am123',\n",
       "       'device_id_hka-aqm-am124', 'device_id_hka-aqm-am126',\n",
       "       'device_id_hka-aqm-am201a', 'device_id_hka-aqm-am201b',\n",
       "       'device_id_hka-aqm-am204', 'device_id_hka-aqm-am205',\n",
       "       'device_id_hka-aqm-am209', 'device_id_hka-aqm-am210',\n",
       "       'device_id_hka-aqm-am211', 'device_id_hka-aqm-am301',\n",
       "       'device_id_hka-aqm-am307', 'device_id_hka-aqm-am308'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions.columns"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
